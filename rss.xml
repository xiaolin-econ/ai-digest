<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
<channel>
  <title>AI Research Digest</title>
  <link>https://xiaolin-econ.github.io/ai-digest/</link>
  <description>Curated AI research + releases</description>
  <lastBuildDate>Wed, 04 Feb 2026 18:36:27 +0000</lastBuildDate>
  <atom:link href="https://xiaolin-econ.github.io/ai-digest/rss.xml" rel="self" type="application/rss+xml" xmlns:atom="http://www.w3.org/2005/Atom"/>
  
<item>
  <title>AI Digest — Daily Summary</title>
  <link>https://xiaolin-econ.github.io/ai-digest/rss.xml</link>
  <guid>https://xiaolin-econ.github.io/ai-digest/rss.xml#summary</guid>
  <pubDate>Wed, 04 Feb 2026 18:36:27 +0000</pubDate>
  <description>Reinforcement learning (RL) is a critical component for post-training large language models (LLMs). However, in bandwidth-constrained distributed RL, scalability is often bottlenecked by the synchronization of policy weights from trainers to inference workers, particularly over commodity networks or in decentralized settings. While recent studies suggest that RL updates modify only a small fraction of model parameters, these observations are typically based on coarse checkpoint differences. We present a systematic empirical study of weight-update sparsity at both step-level and multi-step granularities, examining its evolution across training dynamics, off-policy delay, and model scale. We find that update sparsity is consistently high, frequently exceeding 99% across practically…</description>
</item>

<item>
  <title>Understanding and Exploiting Weight Update Sparsity for Communication-Efficient Distributed RL</title>
  <link>https://arxiv.org/abs/2602.03839v1</link>
  <guid>https://arxiv.org/abs/2602.03839v1</guid>
  <pubDate>Tue, 03 Feb 2026 18:56:48 +0000</pubDate>
  <description>arXiv cs.LG - Reinforcement learning (RL) is a critical component for post-training large language models (LLMs). However, in bandwidth-constrained distributed RL, scalability is often bottlenecked by the synchronization of policy weights from trainers to inference workers, particularly over commodity networks or in decentralized settings. While recent studies suggest that RL updates modify only a small fractio</description>
</item>

<item>
  <title>PrevizWhiz: Combining Rough 3D Scenes and 2D Video to Guide Generative Video Previsualization</title>
  <link>https://arxiv.org/abs/2602.03838v1</link>
  <guid>https://arxiv.org/abs/2602.03838v1</guid>
  <pubDate>Tue, 03 Feb 2026 18:56:40 +0000</pubDate>
  <description>arXiv cs.AI - In pre-production, filmmakers and 3D animation experts must rapidly prototype ideas to explore a film&apos;s possibilities before fullscale production, yet conventional approaches involve trade-offs in efficiency and expressiveness. Hand-drawn storyboards often lack spatial precision needed for complex cinematography, while 3D previsualization demands expertise and high-quality rigged assets. To addres</description>
</item>

<item>
  <title>Accelerating Scientific Research with Gemini: Case Studies and Common Techniques</title>
  <link>https://arxiv.org/abs/2602.03837v1</link>
  <guid>https://arxiv.org/abs/2602.03837v1</guid>
  <pubDate>Tue, 03 Feb 2026 18:56:17 +0000</pubDate>
  <description>arXiv cs.AI - Recent advances in large language models (LLMs) have opened new avenues for accelerating scientific research. While models are increasingly capable of assisting with routine tasks, their ability to contribute to novel, expert-level mathematical discovery is less understood. We present a collection of case studies demonstrating how researchers have successfully collaborated with advanced AI models,</description>
</item>

<item>
  <title>AutoFigure: Generating and Refining Publication-Ready Scientific Illustrations</title>
  <link>https://arxiv.org/abs/2602.03828v1</link>
  <guid>https://arxiv.org/abs/2602.03828v1</guid>
  <pubDate>Tue, 03 Feb 2026 18:41:43 +0000</pubDate>
  <description>arXiv cs.AI - High-quality scientific illustrations are crucial for effectively communicating complex scientific and technical concepts, yet their manual creation remains a well-recognized bottleneck in both academia and industry. We present FigureBench, the first large-scale benchmark for generating scientific illustrations from long-form scientific texts. It contains 3,300 high-quality scientific text-figure </description>
</item>

<item>
  <title>SymPlex: A Structure-Aware Transformer for Symbolic PDE Solving</title>
  <link>https://arxiv.org/abs/2602.03816v1</link>
  <guid>https://arxiv.org/abs/2602.03816v1</guid>
  <pubDate>Tue, 03 Feb 2026 18:18:30 +0000</pubDate>
  <description>arXiv cs.LG - We propose SymPlex, a reinforcement learning framework for discovering analytical symbolic solutions to partial differential equations (PDEs) without access to ground-truth expressions. SymPlex formulates symbolic PDE solving as tree-structured decision-making and optimizes candidate solutions using only the PDE and its boundary conditions. At its core is SymFormer, a structure-aware Transformer t</description>
</item>

<item>
  <title>Understanding Agent Scaling in LLM-Based Multi-Agent Systems via Diversity</title>
  <link>https://arxiv.org/abs/2602.03794v1</link>
  <guid>https://arxiv.org/abs/2602.03794v1</guid>
  <pubDate>Tue, 03 Feb 2026 17:58:10 +0000</pubDate>
  <description>arXiv cs.AI - LLM-based multi-agent systems (MAS) have emerged as a promising approach to tackle complex tasks that are difficult for individual LLMs. A natural strategy is to scale performance by increasing the number of agents; however, we find that such scaling exhibits strong diminishing returns in homogeneous settings, while introducing heterogeneity (e.g., different models, prompts, or tools) continues to</description>
</item>

<item>
  <title>Understanding Agent Scaling in LLM-Based Multi-Agent Systems via Diversity</title>
  <link>https://arxiv.org/abs/2602.03794v1</link>
  <guid>https://arxiv.org/abs/2602.03794v1</guid>
  <pubDate>Tue, 03 Feb 2026 17:58:10 +0000</pubDate>
  <description>arXiv cs.LG - LLM-based multi-agent systems (MAS) have emerged as a promising approach to tackle complex tasks that are difficult for individual LLMs. A natural strategy is to scale performance by increasing the number of agents; however, we find that such scaling exhibits strong diminishing returns in homogeneous settings, while introducing heterogeneity (e.g., different models, prompts, or tools) continues to</description>
</item>

<item>
  <title>WebSentinel: Detecting and Localizing Prompt Injection Attacks for Web Agents</title>
  <link>https://arxiv.org/abs/2602.03792v1</link>
  <guid>https://arxiv.org/abs/2602.03792v1</guid>
  <pubDate>Tue, 03 Feb 2026 17:55:04 +0000</pubDate>
  <description>arXiv cs.AI - Prompt injection attacks manipulate webpage content to cause web agents to execute attacker-specified tasks instead of the user&apos;s intended ones. Existing methods for detecting and localizing such attacks achieve limited effectiveness, as their underlying assumptions often do not hold in the web-agent setting. In this work, we propose WebSentinel, a two-step approach for detecting and localizing pr</description>
</item>

<item>
  <title>AOrchestra: Automating Sub-Agent Creation for Agentic Orchestration</title>
  <link>https://arxiv.org/abs/2602.03786v1</link>
  <guid>https://arxiv.org/abs/2602.03786v1</guid>
  <pubDate>Tue, 03 Feb 2026 17:46:16 +0000</pubDate>
  <description>arXiv cs.AI - Language agents have shown strong promise for task automation. Realizing this promise for increasingly complex, long-horizon tasks has driven the rise of a sub-agent-as-tools paradigm for multi-turn task solving. However, existing designs still lack a dynamic abstraction view of sub-agents, thereby hurting adaptability. We address this challenge with a unified, framework-agnostic agent abstraction</description>
</item>

<item>
  <title>Efficient Estimation of Kernel Surrogate Models for Task Attribution</title>
  <link>https://arxiv.org/abs/2602.03783v1</link>
  <guid>https://arxiv.org/abs/2602.03783v1</guid>
  <pubDate>Tue, 03 Feb 2026 17:43:48 +0000</pubDate>
  <description>arXiv cs.AI - Modern AI agents such as large language models are trained on diverse tasks -- translation, code generation, mathematical reasoning, and text prediction -- simultaneously. A key question is to quantify how each individual training task influences performance on a target task, a problem we refer to as task attribution. The direct approach, leave-one-out retraining, measures the effect of removing e</description>
</item>

<item>
  <title>Efficient Estimation of Kernel Surrogate Models for Task Attribution</title>
  <link>https://arxiv.org/abs/2602.03783v1</link>
  <guid>https://arxiv.org/abs/2602.03783v1</guid>
  <pubDate>Tue, 03 Feb 2026 17:43:48 +0000</pubDate>
  <description>arXiv cs.LG - Modern AI agents such as large language models are trained on diverse tasks -- translation, code generation, mathematical reasoning, and text prediction -- simultaneously. A key question is to quantify how each individual training task influences performance on a target task, a problem we refer to as task attribution. The direct approach, leave-one-out retraining, measures the effect of removing e</description>
</item>

<item>
  <title>DiffLOB: Diffusion Models for Counterfactual Generation in Limit Order Books</title>
  <link>https://arxiv.org/abs/2602.03776v1</link>
  <guid>https://arxiv.org/abs/2602.03776v1</guid>
  <pubDate>Tue, 03 Feb 2026 17:34:56 +0000</pubDate>
  <description>arXiv cs.AI - Modern generative models for limit order books (LOBs) can reproduce realistic market dynamics, but remain fundamentally passive: they either model what typically happens without accounting for hypothetical future market conditions, or they require interaction with another agent to explore alternative outcomes. This limits their usefulness for stress testing, scenario analysis, and decision-making.</description>
</item>

<item>
  <title>An Empirical Study of Collective Behaviors and Social Dynamics in Large Language Model Agents</title>
  <link>https://arxiv.org/abs/2602.03775v1</link>
  <guid>https://arxiv.org/abs/2602.03775v1</guid>
  <pubDate>Tue, 03 Feb 2026 17:34:32 +0000</pubDate>
  <description>arXiv cs.AI - Large Language Models (LLMs) increasingly mediate our social, cultural, and political interactions. While they can simulate some aspects of human behavior and decision-making, it is still underexplored whether repeated interactions with other agents amplify their biases or lead to exclusionary behaviors. To this end, we study Chirper.ai-an LLM-driven social media platform-analyzing 7M posts and in</description>
</item>

<item>
  <title>Reasoning Cache: Continual Improvement Over Long Horizons via Short-Horizon RL</title>
  <link>https://arxiv.org/abs/2602.03773v1</link>
  <guid>https://arxiv.org/abs/2602.03773v1</guid>
  <pubDate>Tue, 03 Feb 2026 17:34:04 +0000</pubDate>
  <description>arXiv cs.LG - Large Language Models (LLMs) that can continually improve beyond their training budgets are able to solve increasingly difficult problems by adapting at test time, a property we refer to as extrapolation. However, standard reinforcement learning (RL) operates over fixed problem distributions and training budgets, which limits extrapolation amidst distribution shift at test time. To address this, w</description>
</item>

<item>
  <title>Zero-shot large vision-language model prompting for automated bone identification in paleoradiology x-ray archives</title>
  <link>https://arxiv.org/abs/2602.03750v1</link>
  <guid>https://arxiv.org/abs/2602.03750v1</guid>
  <pubDate>Tue, 03 Feb 2026 17:14:23 +0000</pubDate>
  <description>arXiv cs.AI - Paleoradiology, the use of modern imaging technologies to study archaeological and anthropological remains, offers new windows on millennial scale patterns of human health. Unfortunately, the radiographs collected during field campaigns are heterogeneous: bones are disarticulated, positioning is ad hoc, and laterality markers are often absent. Additionally, factors such as age at death, age of bon</description>
</item>

<item>
  <title>Cognitively Diverse Multiple-Choice Question Generation: A Hybrid Multi-Agent Framework with Large Language Models</title>
  <link>https://arxiv.org/abs/2602.03704v1</link>
  <guid>https://arxiv.org/abs/2602.03704v1</guid>
  <pubDate>Tue, 03 Feb 2026 16:26:47 +0000</pubDate>
  <description>arXiv cs.AI - Recent advances in large language models (LLMs) have made automated multiple-choice question (MCQ) generation increasingly feasible; however, reliably producing items that satisfy controlled cognitive demands remains a challenge. To address this gap, we introduce ReQUESTA, a hybrid, multi-agent framework for generating cognitively diverse MCQs that systematically target text-based, inferential, an</description>
</item>

<item>
  <title>Agent Primitives: Reusable Latent Building Blocks for Multi-Agent Systems</title>
  <link>https://arxiv.org/abs/2602.03695v1</link>
  <guid>https://arxiv.org/abs/2602.03695v1</guid>
  <pubDate>Tue, 03 Feb 2026 16:17:53 +0000</pubDate>
  <description>arXiv cs.AI - While existing multi-agent systems (MAS) can handle complex problems by enabling collaboration among multiple agents, they are often highly task-specific, relying on manually crafted agent roles and interaction prompts, which leads to increased architectural complexity and limited reusability across tasks. Moreover, most MAS communicate primarily through natural language, making them vulnerable to</description>
</item>

<item>
  <title>MEG-XL: Data-Efficient Brain-to-Text via Long-Context Pre-Training</title>
  <link>https://arxiv.org/abs/2602.02494v1</link>
  <guid>https://arxiv.org/abs/2602.02494v1</guid>
  <pubDate>Mon, 02 Feb 2026 18:59:50 +0000</pubDate>
  <description>arXiv cs.LG - Clinical brain-to-text interfaces are designed for paralysed patients who cannot provide extensive training recordings. Pre-training improves data-efficient generalisation by learning statistical priors across subjects, but these priors critically depend on context. While natural speech might unfold gradually over minutes, most methods pre-train with only a few seconds of context. Thus, we propose</description>
</item>

<item>
  <title>RLAnything: Forge Environment, Policy, and Reward Model in Completely Dynamic RL System</title>
  <link>https://arxiv.org/abs/2602.02488v1</link>
  <guid>https://arxiv.org/abs/2602.02488v1</guid>
  <pubDate>Mon, 02 Feb 2026 18:59:04 +0000</pubDate>
  <description>arXiv cs.LG - We propose RLAnything, a reinforcement learning framework that dynamically forges environment, policy, and reward models through closed-loop optimization, amplifying learning signals and strengthening the overall RL system for any LLM or agentic scenarios. Specifically, the policy is trained with integrated feedback from step-wise and outcome signals, while the reward model is jointly optimized vi</description>
</item>

<item>
  <title>RE-TRAC: REcursive TRAjectory Compression for Deep Search Agents</title>
  <link>https://arxiv.org/abs/2602.02486v1</link>
  <guid>https://arxiv.org/abs/2602.02486v1</guid>
  <pubDate>Mon, 02 Feb 2026 18:58:07 +0000</pubDate>
  <description>arXiv cs.AI - LLM-based deep research agents are largely built on the ReAct framework. This linear design makes it difficult to revisit earlier states, branch into alternative search directions, or maintain global awareness under long contexts, often leading to local optima, redundant exploration, and inefficient search. We propose Re-TRAC, an agentic framework that performs cross-trajectory exploration by gene</description>
</item>

<item>
  <title>Expanding the Capabilities of Reinforcement Learning via Text Feedback</title>
  <link>https://arxiv.org/abs/2602.02482v1</link>
  <guid>https://arxiv.org/abs/2602.02482v1</guid>
  <pubDate>Mon, 02 Feb 2026 18:56:56 +0000</pubDate>
  <description>arXiv cs.LG - The success of RL for LLM post-training stems from an unreasonably uninformative source: a single bit of information per rollout as binary reward or preference label. At the other extreme, distillation offers dense supervision but requires demonstrations, which are costly and difficult to scale. We study text feedback as an intermediate signal: richer than scalar rewards, yet cheaper than complete</description>
</item>

<item>
  <title>AgentRx: Diagnosing AI Agent Failures from Execution Trajectories</title>
  <link>https://arxiv.org/abs/2602.02475v1</link>
  <guid>https://arxiv.org/abs/2602.02475v1</guid>
  <pubDate>Mon, 02 Feb 2026 18:54:07 +0000</pubDate>
  <description>arXiv cs.AI - AI agents often fail in ways that are difficult to localize because executions are probabilistic, long-horizon, multi-agent, and mediated by noisy tool outputs. We address this gap by manually annotating failed agent runs and release a novel benchmark of 115 failed trajectories spanning structured API workflows, incident management, and open-ended web/file tasks. Each trajectory is annotated with </description>
</item>

<item>
  <title>MemSkill: Learning and Evolving Memory Skills for Self-Evolving Agents</title>
  <link>https://arxiv.org/abs/2602.02474v1</link>
  <guid>https://arxiv.org/abs/2602.02474v1</guid>
  <pubDate>Mon, 02 Feb 2026 18:53:28 +0000</pubDate>
  <description>arXiv cs.AI - Most Large Language Model (LLM) agent memory systems rely on a small set of static, hand-designed operations for extracting memory. These fixed procedures hard-code human priors about what to store and how to revise memory, making them rigid under diverse interaction patterns and inefficient on long histories. To this end, we present \textbf{MemSkill}, which reframes these operations as learnable </description>
</item>

<item>
  <title>MemSkill: Learning and Evolving Memory Skills for Self-Evolving Agents</title>
  <link>https://arxiv.org/abs/2602.02474v1</link>
  <guid>https://arxiv.org/abs/2602.02474v1</guid>
  <pubDate>Mon, 02 Feb 2026 18:53:28 +0000</pubDate>
  <description>arXiv cs.LG - Most Large Language Model (LLM) agent memory systems rely on a small set of static, hand-designed operations for extracting memory. These fixed procedures hard-code human priors about what to store and how to revise memory, making them rigid under diverse interaction patterns and inefficient on long histories. To this end, we present \textbf{MemSkill}, which reframes these operations as learnable </description>
</item>

<item>
  <title>Multi-head automated segmentation by incorporating detection head into the contextual layer neural network</title>
  <link>https://arxiv.org/abs/2602.02471v1</link>
  <guid>https://arxiv.org/abs/2602.02471v1</guid>
  <pubDate>Mon, 02 Feb 2026 18:51:25 +0000</pubDate>
  <description>arXiv cs.AI - Deep learning based auto segmentation is increasingly used in radiotherapy, but conventional models often produce anatomically implausible false positives, or hallucinations, in slices lacking target structures. We propose a gated multi-head Transformer architecture based on Swin U-Net, augmented with inter-slice context integration and a parallel detection head, which jointly performs slice-level</description>
</item>

<item>
  <title>Avenir-Web: Human-Experience-Imitating Multimodal Web Agents with Mixture of Grounding Experts</title>
  <link>https://arxiv.org/abs/2602.02468v1</link>
  <guid>https://arxiv.org/abs/2602.02468v1</guid>
  <pubDate>Mon, 02 Feb 2026 18:50:07 +0000</pubDate>
  <description>arXiv cs.AI - Despite advances in multimodal large language models, autonomous web agents still struggle to reliably execute long-horizon tasks on complex and dynamic web interfaces. Existing agents often suffer from inaccurate element grounding, the absence of site-specific procedural knowledge, and unstable long-term task tracking and memory, particularly when operating over complex Document Object Model stru</description>
</item>

<item>
  <title>Drift-Bench: Diagnosing Cooperative Breakdowns in LLM Agents under Input Faults via Multi-Turn Interaction</title>
  <link>https://arxiv.org/abs/2602.02455v1</link>
  <guid>https://arxiv.org/abs/2602.02455v1</guid>
  <pubDate>Mon, 02 Feb 2026 18:46:16 +0000</pubDate>
  <description>arXiv cs.AI - As Large Language Models transition to autonomous agents, user inputs frequently violate cooperative assumptions (e.g., implicit intent, missing parameters, false presuppositions, or ambiguous expressions), creating execution risks that text-only evaluations do not capture. Existing benchmarks typically assume well-specified instructions or restrict evaluation to text-only, single-turn clarificati</description>
</item>

<item>
  <title>Energy-Efficient Neuromorphic Computing for Edge AI: A Framework with Adaptive Spiking Neural Networks and Hardware-Aware Optimization</title>
  <link>https://arxiv.org/abs/2602.02439v1</link>
  <guid>https://arxiv.org/abs/2602.02439v1</guid>
  <pubDate>Mon, 02 Feb 2026 18:34:48 +0000</pubDate>
  <description>arXiv cs.LG - Edge AI applications increasingly require ultra-low-power, low-latency inference. Neuromorphic computing based on event-driven spiking neural networks (SNNs) offers an attractive path, but practical deployment on resource-constrained devices is limited by training difficulty, hardware-mapping overheads, and sensitivity to temporal dynamics. We present NeuEdge, a framework that combines adaptive SN</description>
</item>

<item>
  <title>UniReason 1.0: A Unified Reasoning Framework for World Knowledge Aligned Image Generation and Editing</title>
  <link>https://arxiv.org/abs/2602.02437v1</link>
  <guid>https://arxiv.org/abs/2602.02437v1</guid>
  <pubDate>Mon, 02 Feb 2026 18:34:35 +0000</pubDate>
  <description>arXiv cs.AI - Unified multimodal models often struggle with complex synthesis tasks that demand deep reasoning, and typically treat text-to-image generation and image editing as isolated capabilities rather than interconnected reasoning steps. To address this, we propose UniReason, a unified framework that harmonizes these two tasks through a dual reasoning paradigm. We formulate generation as world knowledge-e</description>
</item>

<item>
  <title>David vs. Goliath: Verifiable Agent-to-Agent Jailbreaking via Reinforcement Learning</title>
  <link>https://arxiv.org/abs/2602.02395v1</link>
  <guid>https://arxiv.org/abs/2602.02395v1</guid>
  <pubDate>Mon, 02 Feb 2026 17:56:55 +0000</pubDate>
  <description>arXiv cs.AI - The evolution of large language models into autonomous agents introduces adversarial failures that exploit legitimate tool privileges, transforming safety evaluation in tool-augmented environments from a subjective NLP task into an objective control problem. We formalize this threat model as Tag-Along Attacks: a scenario where a tool-less adversary &quot;tags along&quot; on the trusted privileges of a safet</description>
</item>

<item>
  <title>End-to-end Optimization of Belief and Policy Learning in Shared Autonomy Paradigms</title>
  <link>https://arxiv.org/abs/2601.23285v1</link>
  <guid>https://arxiv.org/abs/2601.23285v1</guid>
  <pubDate>Fri, 30 Jan 2026 18:59:16 +0000</pubDate>
  <description>arXiv cs.AI - Shared autonomy systems require principled methods for inferring user intent and determining appropriate assistance levels. This is a central challenge in human-robot interaction, where systems must be successful while being mindful of user agency. Previous approaches relied on static blending ratios or separated goal inference from assistance arbitration, leading to suboptimal performance in unst</description>
</item>

<item>
  <title>End-to-end Optimization of Belief and Policy Learning in Shared Autonomy Paradigms</title>
  <link>https://arxiv.org/abs/2601.23285v1</link>
  <guid>https://arxiv.org/abs/2601.23285v1</guid>
  <pubDate>Fri, 30 Jan 2026 18:59:16 +0000</pubDate>
  <description>arXiv cs.LG - Shared autonomy systems require principled methods for inferring user intent and determining appropriate assistance levels. This is a central challenge in human-robot interaction, where systems must be successful while being mindful of user agency. Previous approaches relied on static blending ratios or separated goal inference from assistance arbitration, leading to suboptimal performance in unst</description>
</item>

<item>
  <title>FOCUS: DLLMs Know How to Tame Their Compute Bound</title>
  <link>https://arxiv.org/abs/2601.23278v1</link>
  <guid>https://arxiv.org/abs/2601.23278v1</guid>
  <pubDate>Fri, 30 Jan 2026 18:52:06 +0000</pubDate>
  <description>arXiv cs.LG - Diffusion Large Language Models (DLLMs) offer a compelling alternative to Auto-Regressive models, but their deployment is constrained by high decoding cost. In this work, we identify a key inefficiency in DLLM decoding: while computation is parallelized over token blocks, only a small subset of tokens is decodable at each diffusion step, causing most compute to be wasted on non-decodable tokens. W</description>
</item>

<item>
  <title>Denoising the Deep Sky: Physics-Based CCD Noise Formation for Astronomical Imaging</title>
  <link>https://arxiv.org/abs/2601.23276v1</link>
  <guid>https://arxiv.org/abs/2601.23276v1</guid>
  <pubDate>Fri, 30 Jan 2026 18:47:54 +0000</pubDate>
  <description>arXiv cs.LG - Astronomical imaging remains noise-limited under practical observing constraints, while standard calibration pipelines mainly remove structured artifacts and leave stochastic noise largely unresolved. Learning-based denoising is promising, yet progress is hindered by scarce paired training data and the need for physically interpretable and reproducible models in scientific workflows. We propose a </description>
</item>

<item>
  <title>IRL-DAL: Safe and Adaptive Trajectory Planning for Autonomous Driving via Energy-Guided Diffusion Models</title>
  <link>https://arxiv.org/abs/2601.23266v1</link>
  <guid>https://arxiv.org/abs/2601.23266v1</guid>
  <pubDate>Fri, 30 Jan 2026 18:34:10 +0000</pubDate>
  <description>arXiv cs.AI - This paper proposes a novel inverse reinforcement learning framework using a diffusion-based adaptive lookahead planner (IRL-DAL) for autonomous vehicles. Training begins with imitation from an expert finite state machine (FSM) controller to provide a stable initialization. Environment terms are combined with an IRL discriminator signal to align with expert goals. Reinforcement learning (RL) is th</description>
</item>

<item>
  <title>Now You Hear Me: Audio Narrative Attacks Against Large Audio-Language Models</title>
  <link>https://arxiv.org/abs/2601.23255v1</link>
  <guid>https://arxiv.org/abs/2601.23255v1</guid>
  <pubDate>Fri, 30 Jan 2026 18:23:02 +0000</pubDate>
  <description>arXiv cs.AI - Large audio-language models increasingly operate on raw speech inputs, enabling more seamless integration across domains such as voice assistants, education, and clinical triage. This transition, however, introduces a distinct class of vulnerabilities that remain largely uncharacterized. We examine the security implications of this modality shift by designing a text-to-audio jailbreak that embeds </description>
</item>

<item>
  <title>ShotFinder: Imagination-Driven Open-Domain Video Shot Retrieval via Web Search</title>
  <link>https://arxiv.org/abs/2601.23232v1</link>
  <guid>https://arxiv.org/abs/2601.23232v1</guid>
  <pubDate>Fri, 30 Jan 2026 18:01:17 +0000</pubDate>
  <description>arXiv cs.AI - In recent years, large language models (LLMs) have made rapid progress in information retrieval, yet existing research has mainly focused on text or static multimodal settings. Open-domain video shot retrieval, which involves richer temporal structure and more complex semantics, still lacks systematic benchmarks and analysis. To fill this gap, we introduce ShotFinder, a benchmark that formalizes e</description>
</item>

<item>
  <title>Scaling Multiagent Systems with Process Rewards</title>
  <link>https://arxiv.org/abs/2601.23228v1</link>
  <guid>https://arxiv.org/abs/2601.23228v1</guid>
  <pubDate>Fri, 30 Jan 2026 17:55:27 +0000</pubDate>
  <description>arXiv cs.AI - While multiagent systems have shown promise for tackling complex tasks via specialization, finetuning multiple agents simultaneously faces two key challenges: (1) credit assignment across agents, and (2) sample efficiency of expensive multiagent rollouts. In this work, we propose finetuning multiagent systems with per-action process rewards from AI feedback (MAPPA) to address both. Through assigni</description>
</item>

<item>
  <title>MonoScale: Scaling Multi-Agent System with Monotonic Improvement</title>
  <link>https://arxiv.org/abs/2601.23219v1</link>
  <guid>https://arxiv.org/abs/2601.23219v1</guid>
  <pubDate>Fri, 30 Jan 2026 17:44:49 +0000</pubDate>
  <description>arXiv cs.AI - In recent years, LLM-based multi-agent systems (MAS) have advanced rapidly, using a router to decompose tasks and delegate subtasks to specialized agents. A natural way to expand capability is to scale up the agent pool by continually integrating new functional agents or tool interfaces, but naive expansion can trigger performance collapse when the router cold-starts on newly added, heterogeneous,</description>
</item>

<item>
  <title>Tackling air quality with SAPIENS</title>
  <link>https://arxiv.org/abs/2601.23215v1</link>
  <guid>https://arxiv.org/abs/2601.23215v1</guid>
  <pubDate>Fri, 30 Jan 2026 17:41:38 +0000</pubDate>
  <description>arXiv cs.LG - Air pollution is a chronic problem in large cities worldwide and awareness is rising as the long-term health implications become clearer. Vehicular traffic has been identified as a major contributor to poor air quality. In a lot of cities the publicly available air quality measurements and forecasts are coarse-grained both in space and time. However, in general, real-time traffic intensity data is</description>
</item>

<item>
  <title>High-quality generation of dynamic game content via small language models: A proof of concept</title>
  <link>https://arxiv.org/abs/2601.23206v1</link>
  <guid>https://arxiv.org/abs/2601.23206v1</guid>
  <pubDate>Fri, 30 Jan 2026 17:30:59 +0000</pubDate>
  <description>arXiv cs.AI - Large language models (LLMs) offer promise for dynamic game content generation, but they face critical barriers, including narrative incoherence and high operational costs. Due to their large size, they are often accessed in the cloud, limiting their application in offline games. Many of these practical issues are solved by pivoting to small language models (SLMs), but existing studies using SLMs </description>
</item>

<item>
  <title>Ensuring Semantics in Weights of Implicit Neural Representations through the Implicit Function Theorem</title>
  <link>https://arxiv.org/abs/2601.23181v1</link>
  <guid>https://arxiv.org/abs/2601.23181v1</guid>
  <pubDate>Fri, 30 Jan 2026 17:05:37 +0000</pubDate>
  <description>arXiv cs.LG - Weight Space Learning (WSL), which frames neural network weights as a data modality, is an emerging field with potential for tasks like meta-learning or transfer learning. Particularly, Implicit Neural Representations (INRs) provide a convenient testbed, where each set of weights determines the corresponding individual data sample as a mapping from coordinates to contextual values. So far, a preci</description>
</item>

<item>
  <title>TriSpec: Ternary Speculative Decoding via Lightweight Proxy Verification</title>
  <link>https://arxiv.org/abs/2601.23180v1</link>
  <guid>https://arxiv.org/abs/2601.23180v1</guid>
  <pubDate>Fri, 30 Jan 2026 17:04:18 +0000</pubDate>
  <description>arXiv cs.LG - Inference efficiency in Large Language Models (LLMs) is fundamentally limited by their serial, autoregressive generation, especially as reasoning becomes a key capability and response sequences grow longer. Speculative decoding (SD) offers a powerful solution, providing significant speed-ups through its lightweight drafting and parallel verification mechanism. While existing work has nearly satura</description>
</item>

<item>
  <title>Beyond Fixed Frames: Dynamic Character-Aligned Speech Tokenization</title>
  <link>https://arxiv.org/abs/2601.23174v1</link>
  <guid>https://arxiv.org/abs/2601.23174v1</guid>
  <pubDate>Fri, 30 Jan 2026 16:58:40 +0000</pubDate>
  <description>arXiv cs.AI - Neural audio codecs are at the core of modern conversational speech technologies, converting continuous speech into sequences of discrete tokens that can be processed by LLMs. However, existing codecs typically operate at fixed frame rates, allocating tokens uniformly in time and producing unnecessarily long sequences. In this work, we introduce DyCAST, a Dynamic Character-Aligned Speech Tokenizer</description>
</item>

<item>
  <title>Beyond Fixed Frames: Dynamic Character-Aligned Speech Tokenization</title>
  <link>https://arxiv.org/abs/2601.23174v1</link>
  <guid>https://arxiv.org/abs/2601.23174v1</guid>
  <pubDate>Fri, 30 Jan 2026 16:58:40 +0000</pubDate>
  <description>arXiv cs.LG - Neural audio codecs are at the core of modern conversational speech technologies, converting continuous speech into sequences of discrete tokens that can be processed by LLMs. However, existing codecs typically operate at fixed frame rates, allocating tokens uniformly in time and producing unnecessarily long sequences. In this work, we introduce DyCAST, a Dynamic Character-Aligned Speech Tokenizer</description>
</item>

<item>
  <title>RedSage: A Cybersecurity Generalist LLM</title>
  <link>https://arxiv.org/abs/2601.22159v1</link>
  <guid>https://arxiv.org/abs/2601.22159v1</guid>
  <pubDate>Thu, 29 Jan 2026 18:59:57 +0000</pubDate>
  <description>arXiv cs.AI - Cybersecurity operations demand assistant LLMs that support diverse workflows without exposing sensitive data. Existing solutions either rely on proprietary APIs with privacy risks or on open models lacking domain adaptation. To bridge this gap, we curate 11.8B tokens of cybersecurity-focused continual pretraining data via large-scale web filtering and manual collection of high-quality resources, </description>
</item>

<item>
  <title>Hybrid Linear Attention Done Right: Efficient Distillation and Effective Architectures for Extremely Long Contexts</title>
  <link>https://arxiv.org/abs/2601.22156v1</link>
  <guid>https://arxiv.org/abs/2601.22156v1</guid>
  <pubDate>Thu, 29 Jan 2026 18:59:53 +0000</pubDate>
  <description>arXiv cs.AI - Hybrid Transformer architectures, which combine softmax attention blocks and recurrent neural networks (RNNs), have shown a desirable performance-throughput tradeoff for long-context modeling, but their adoption and studies are hindered by the prohibitive cost of large-scale pre-training from scratch. Some recent studies have shown that pre-trained softmax attention blocks can be converted into RN</description>
</item>

<item>
  <title>Hybrid Linear Attention Done Right: Efficient Distillation and Effective Architectures for Extremely Long Contexts</title>
  <link>https://arxiv.org/abs/2601.22156v1</link>
  <guid>https://arxiv.org/abs/2601.22156v1</guid>
  <pubDate>Thu, 29 Jan 2026 18:59:53 +0000</pubDate>
  <description>arXiv cs.LG - Hybrid Transformer architectures, which combine softmax attention blocks and recurrent neural networks (RNNs), have shown a desirable performance-throughput tradeoff for long-context modeling, but their adoption and studies are hindered by the prohibitive cost of large-scale pre-training from scratch. Some recent studies have shown that pre-trained softmax attention blocks can be converted into RN</description>
</item>

<item>
  <title>Exploring Reasoning Reward Model for Agents</title>
  <link>https://arxiv.org/abs/2601.22154v1</link>
  <guid>https://arxiv.org/abs/2601.22154v1</guid>
  <pubDate>Thu, 29 Jan 2026 18:59:52 +0000</pubDate>
  <description>arXiv cs.AI - Agentic Reinforcement Learning (Agentic RL) has achieved notable success in enabling agents to perform complex reasoning and tool use. However, most methods still relies on sparse outcome-based reward for training. Such feedback fails to differentiate intermediate reasoning quality, leading to suboptimal training results. In this paper, we introduce Agent Reasoning Reward Model (Agent-RRM), a mult</description>
</item>

<item>
  <title>DynaWeb: Model-Based Reinforcement Learning of Web Agents</title>
  <link>https://arxiv.org/abs/2601.22149v1</link>
  <guid>https://arxiv.org/abs/2601.22149v1</guid>
  <pubDate>Thu, 29 Jan 2026 18:59:07 +0000</pubDate>
  <description>arXiv cs.AI - The development of autonomous web agents, powered by Large Language Models (LLMs) and reinforcement learning (RL), represents a significant step towards general-purpose AI assistants. However, training these agents is severely hampered by the challenges of interacting with the live internet, which is inefficient, costly, and fraught with risks. Model-based reinforcement learning (MBRL) offers a pr</description>
</item>

</channel>
</rss>
