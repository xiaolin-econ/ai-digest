<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
<channel>
  <title>AI Research Digest</title>
  <link>https://xiaolin-econ.github.io/ai-digest/</link>
  <description>Curated AI research + releases</description>
  <lastBuildDate>Tue, 27 Jan 2026 18:26:00 +0000</lastBuildDate>
  <atom:link href="https://xiaolin-econ.github.io/ai-digest/rss.xml" rel="self" type="application/rss+xml" xmlns:atom="http://www.w3.org/2005/Atom"/>
  
<item>
  <title>AI Digest — Daily Summary</title>
  <link>https://xiaolin-econ.github.io/ai-digest/rss.xml</link>
  <guid>https://xiaolin-econ.github.io/ai-digest/rss.xml#summary</guid>
  <pubDate>Tue, 27 Jan 2026 18:26:00 +0000</pubDate>
  <description>Text embeddings have become an essential part of a variety of language applications. However, methods for interpreting, exploring and reversing embedding spaces are limited, reducing transparency and precluding potentially valuable generative use cases. In this work, we align Large Language Models to embeddings of clinical trials using the recently reported Embedding Language Model (ELM) method. We develop an open-source, domain-agnostic ELM architecture and training framework, design training tasks for clinical trials, and introduce an expert-validated synthetic dataset. We then train a series of ELMs exploring the impact of tasks and training regimes. Our final model, ctELM, can accurately describe and compare unseen clinical trials from embeddings alone and produce plausible clinical…</description>
</item>

<item>
  <title>ctELM: Decoding and Manipulating Embeddings of Clinical Trials with Embedding Language Models</title>
  <link>https://arxiv.org/abs/2601.18796v1</link>
  <guid>https://arxiv.org/abs/2601.18796v1</guid>
  <pubDate>Mon, 26 Jan 2026 18:58:46 +0000</pubDate>
  <description>arXiv cs.AI - Text embeddings have become an essential part of a variety of language applications. However, methods for interpreting, exploring and reversing embedding spaces are limited, reducing transparency and precluding potentially valuable generative use cases. In this work, we align Large Language Models to embeddings of clinical trials using the recently reported Embedding Language Model (ELM) method. W</description>
</item>

<item>
  <title>ctELM: Decoding and Manipulating Embeddings of Clinical Trials with Embedding Language Models</title>
  <link>https://arxiv.org/abs/2601.18796v1</link>
  <guid>https://arxiv.org/abs/2601.18796v1</guid>
  <pubDate>Mon, 26 Jan 2026 18:58:46 +0000</pubDate>
  <description>arXiv cs.LG - Text embeddings have become an essential part of a variety of language applications. However, methods for interpreting, exploring and reversing embedding spaces are limited, reducing transparency and precluding potentially valuable generative use cases. In this work, we align Large Language Models to embeddings of clinical trials using the recently reported Embedding Language Model (ELM) method. W</description>
</item>

<item>
  <title>MEGnifying Emotion: Sentiment Analysis from Annotated Brain Data</title>
  <link>https://arxiv.org/abs/2601.18792v1</link>
  <guid>https://arxiv.org/abs/2601.18792v1</guid>
  <pubDate>Mon, 26 Jan 2026 18:55:44 +0000</pubDate>
  <description>arXiv cs.LG - Decoding emotion from brain activity could unlock a deeper understanding of the human experience. While a number of existing datasets align brain data with speech and with speech transcripts, no datasets have annotated brain data with sentiment. To bridge this gap, we explore the use of pre-trained Text-to-Sentiment models to annotate non invasive brain recordings, acquired using magnetoencephalog</description>
</item>

<item>
  <title>Subword-Based Comparative Linguistics across 242 Languages Using Wikipedia Glottosets</title>
  <link>https://arxiv.org/abs/2601.18791v1</link>
  <guid>https://arxiv.org/abs/2601.18791v1</guid>
  <pubDate>Mon, 26 Jan 2026 18:55:28 +0000</pubDate>
  <description>arXiv cs.AI - We present a large-scale comparative study of 242 Latin and Cyrillic-script languages using subword-based methodologies. By constructing &apos;glottosets&apos; from Wikipedia lexicons, we introduce a framework for simultaneous cross-linguistic comparison via Byte-Pair Encoding (BPE). Our approach utilizes rank-based subword vectors to analyze vocabulary overlap, lexical divergence, and language similarity a</description>
</item>

<item>
  <title>Subword-Based Comparative Linguistics across 242 Languages Using Wikipedia Glottosets</title>
  <link>https://arxiv.org/abs/2601.18791v1</link>
  <guid>https://arxiv.org/abs/2601.18791v1</guid>
  <pubDate>Mon, 26 Jan 2026 18:55:28 +0000</pubDate>
  <description>arXiv cs.LG - We present a large-scale comparative study of 242 Latin and Cyrillic-script languages using subword-based methodologies. By constructing &apos;glottosets&apos; from Wikipedia lexicons, we introduce a framework for simultaneous cross-linguistic comparison via Byte-Pair Encoding (BPE). Our approach utilizes rank-based subword vectors to analyze vocabulary overlap, lexical divergence, and language similarity a</description>
</item>

<item>
  <title>$α^3$-SecBench: A Large-Scale Evaluation Suite of Security, Resilience, and Trust for LLM-based UAV Agents over 6G Networks</title>
  <link>https://arxiv.org/abs/2601.18754v1</link>
  <guid>https://arxiv.org/abs/2601.18754v1</guid>
  <pubDate>Mon, 26 Jan 2026 18:25:07 +0000</pubDate>
  <description>arXiv cs.AI - Autonomous unmanned aerial vehicle (UAV) systems are increasingly deployed in safety-critical, networked environments where they must operate reliably in the presence of malicious adversaries. While recent benchmarks have evaluated large language model (LLM)-based UAV agents in reasoning, navigation, and efficiency, systematic assessment of security, resilience, and trust under adversarial conditi</description>
</item>

<item>
  <title>Capturing P: On the Expressive Power and Efficient Evaluation of Boolean Retrieval</title>
  <link>https://arxiv.org/abs/2601.18747v1</link>
  <guid>https://arxiv.org/abs/2601.18747v1</guid>
  <pubDate>Mon, 26 Jan 2026 18:07:40 +0000</pubDate>
  <description>arXiv cs.AI - Modern information retrieval is transitioning from simple document filtering to complex, neuro-symbolic reasoning workflows. However, current retrieval architectures face a fundamental efficiency dilemma when handling the rigorous logical and arithmetic constraints required by this new paradigm. Standard iterator-based engines (Document-at-a-Time) do not natively support complex, nested logic grap</description>
</item>

<item>
  <title>Why Keep Your Doubts to Yourself? Trading Visual Uncertainties in Multi-Agent Bandit Systems</title>
  <link>https://arxiv.org/abs/2601.18735v1</link>
  <guid>https://arxiv.org/abs/2601.18735v1</guid>
  <pubDate>Mon, 26 Jan 2026 17:58:53 +0000</pubDate>
  <description>arXiv cs.AI - Vision-Language Models (VLMs) enable powerful multi-agent systems, but scaling them is economically unsustainable: coordinating heterogeneous agents under information asymmetry often spirals costs. Existing paradigms, such as Mixture-of-Agents and knowledge-based routers, rely on heuristic proxies that ignore costs and collapse uncertainty structure, leading to provably suboptimal coordination. We</description>
</item>

<item>
  <title>Why Keep Your Doubts to Yourself? Trading Visual Uncertainties in Multi-Agent Bandit Systems</title>
  <link>https://arxiv.org/abs/2601.18735v1</link>
  <guid>https://arxiv.org/abs/2601.18735v1</guid>
  <pubDate>Mon, 26 Jan 2026 17:58:53 +0000</pubDate>
  <description>arXiv cs.LG - Vision-Language Models (VLMs) enable powerful multi-agent systems, but scaling them is economically unsustainable: coordinating heterogeneous agents under information asymmetry often spirals costs. Existing paradigms, such as Mixture-of-Agents and knowledge-based routers, rely on heuristic proxies that ignore costs and collapse uncertainty structure, leading to provably suboptimal coordination. We</description>
</item>

<item>
  <title>Advances and Innovations in the Multi-Agent Robotic System (MARS) Challenge</title>
  <link>https://arxiv.org/abs/2601.18733v1</link>
  <guid>https://arxiv.org/abs/2601.18733v1</guid>
  <pubDate>Mon, 26 Jan 2026 17:56:19 +0000</pubDate>
  <description>arXiv cs.AI - Recent advancements in multimodal large language models and vision-languageaction models have significantly driven progress in Embodied AI. As the field transitions toward more complex task scenarios, multi-agent system frameworks are becoming essential for achieving scalable, efficient, and collaborative solutions. This shift is fueled by three primary factors: increasing agent capabilities, enha</description>
</item>

<item>
  <title>Optimal Use of Preferences in Artificial Intelligence Algorithms</title>
  <link>https://arxiv.org/abs/2601.18732v1</link>
  <guid>https://arxiv.org/abs/2601.18732v1</guid>
  <pubDate>Mon, 26 Jan 2026 17:55:56 +0000</pubDate>
  <description>arXiv cs.AI - Machine learning systems embed preferences either in training losses or through post-processing of calibrated predictions. Applying information design methods from Strack and Yang (2024), this paper provides decision problem agnostic conditions under which separation training preference free and applying preferences ex post is optimal. Unlike prior work that requires specifying downstream objectiv</description>
</item>

<item>
  <title>Auto-Regressive Masked Diffusion Models</title>
  <link>https://arxiv.org/abs/2601.16971v1</link>
  <guid>https://arxiv.org/abs/2601.16971v1</guid>
  <pubDate>Fri, 23 Jan 2026 18:42:30 +0000</pubDate>
  <description>arXiv cs.LG - Masked diffusion models (MDMs) have emerged as a promising approach for language modeling, yet they face a performance gap compared to autoregressive models (ARMs) and require more training iterations. In this work, we present the Auto-Regressive Masked Diffusion (ARMD) model, an architecture designed to close this gap by unifying the training efficiency of autoregressive models with the parallel </description>
</item>

<item>
  <title>Spatial-Agent: Agentic Geo-spatial Reasoning with Scientific Core Concepts</title>
  <link>https://arxiv.org/abs/2601.16965v1</link>
  <guid>https://arxiv.org/abs/2601.16965v1</guid>
  <pubDate>Fri, 23 Jan 2026 18:33:45 +0000</pubDate>
  <description>arXiv cs.AI - Geospatial reasoning is essential for real-world applications such as urban analytics, transportation planning, and disaster response. However, existing LLM-based agents often fail at genuine geospatial computation, relying instead on web search or pattern matching while hallucinating spatial relationships. We present Spatial-Agent, an AI agent grounded in foundational theories of spatial informat</description>
</item>

<item>
  <title>AgentDrive: An Open Benchmark Dataset for Agentic AI Reasoning with LLM-Generated Scenarios in Autonomous Systems</title>
  <link>https://arxiv.org/abs/2601.16964v1</link>
  <guid>https://arxiv.org/abs/2601.16964v1</guid>
  <pubDate>Fri, 23 Jan 2026 18:33:41 +0000</pubDate>
  <description>arXiv cs.AI - The rapid advancement of large language models (LLMs) has sparked growing interest in their integration into autonomous systems for reasoning-driven perception, planning, and decision-making. However, evaluating and training such agentic AI models remains challenging due to the lack of large-scale, structured, and safety-critical benchmarks. This paper introduces AgentDrive, an open benchmark data</description>
</item>

<item>
  <title>Evaluating Large Vision-language Models for Surgical Tool Detection</title>
  <link>https://arxiv.org/abs/2601.16895v1</link>
  <guid>https://arxiv.org/abs/2601.16895v1</guid>
  <pubDate>Fri, 23 Jan 2026 17:00:46 +0000</pubDate>
  <description>arXiv cs.AI - Surgery is a highly complex process, and artificial intelligence has emerged as a transformative force in supporting surgical guidance and decision-making. However, the unimodal nature of most current AI systems limits their ability to achieve a holistic understanding of surgical workflows. This highlights the need for general-purpose surgical AI systems capable of comprehensively modeling the int</description>
</item>

<item>
  <title>MAGE-KT: Multi-Agent Graph-Enhanced Knowledge Tracing with Subgraph Retrieval and Asymmetric Fusion</title>
  <link>https://arxiv.org/abs/2601.16886v1</link>
  <guid>https://arxiv.org/abs/2601.16886v1</guid>
  <pubDate>Fri, 23 Jan 2026 16:51:08 +0000</pubDate>
  <description>arXiv cs.AI - Knowledge Tracing (KT) aims to model a student&apos;s learning trajectory and predict performance on the next question. A key challenge is how to better represent the relationships among students, questions, and knowledge concepts (KCs). Recently, graph-based KT paradigms have shown promise for this problem. However, existing methods have not sufficiently explored inter-concept relations, often inferre</description>
</item>

<item>
  <title>Boosting Deep Reinforcement Learning with Semantic Knowledge for Robotic Manipulators</title>
  <link>https://arxiv.org/abs/2601.16866v1</link>
  <guid>https://arxiv.org/abs/2601.16866v1</guid>
  <pubDate>Fri, 23 Jan 2026 16:14:28 +0000</pubDate>
  <description>arXiv cs.AI - Deep Reinforcement Learning (DRL) is a powerful framework for solving complex sequential decision-making problems, particularly in robotic control. However, its practical deployment is often hindered by the substantial amount of experience required for learning, which results in high computational and time costs. In this work, we propose a novel integration of DRL with semantic knowledge in the fo</description>
</item>

<item>
  <title>Mixture-of-Models: Unifying Heterogeneous Agents via N-Way Self-Evaluating Deliberation</title>
  <link>https://arxiv.org/abs/2601.16863v1</link>
  <guid>https://arxiv.org/abs/2601.16863v1</guid>
  <pubDate>Fri, 23 Jan 2026 16:11:54 +0000</pubDate>
  <description>arXiv cs.AI - This paper introduces the N-Way Self-Evaluating Deliberation (NSED) protocol, a Runtime Mixture-of-Models (MoM) architecture that constructs emergent composite models from a plurality of distinct expert agents. Unlike traditional Mixture-of-Experts (MoE) which rely on static gating networks, NSED employs a Dynamic Expertise Broker - a runtime optimization engine that treats model selection as a va</description>
</item>

<item>
  <title>Mixture-of-Models: Unifying Heterogeneous Agents via N-Way Self-Evaluating Deliberation</title>
  <link>https://arxiv.org/abs/2601.16863v1</link>
  <guid>https://arxiv.org/abs/2601.16863v1</guid>
  <pubDate>Fri, 23 Jan 2026 16:11:54 +0000</pubDate>
  <description>arXiv cs.LG - This paper introduces the N-Way Self-Evaluating Deliberation (NSED) protocol, a Runtime Mixture-of-Models (MoM) architecture that constructs emergent composite models from a plurality of distinct expert agents. Unlike traditional Mixture-of-Experts (MoE) which rely on static gating networks, NSED employs a Dynamic Expertise Broker - a runtime optimization engine that treats model selection as a va</description>
</item>

<item>
  <title>Privacy in Human-AI Romantic Relationships: Concerns, Boundaries, and Agency</title>
  <link>https://arxiv.org/abs/2601.16824v1</link>
  <guid>https://arxiv.org/abs/2601.16824v1</guid>
  <pubDate>Fri, 23 Jan 2026 15:23:37 +0000</pubDate>
  <description>arXiv cs.AI - An increasing number of LLM-based applications are being developed to facilitate romantic relationships with AI partners, yet the safety and privacy risks in these partnerships remain largely underexplored. In this work, we investigate privacy in human-AI romantic relationships through an interview study (N=17), examining participants&apos; experiences and privacy perceptions across stages of explorati</description>
</item>

<item>
  <title>Will It Survive? Deciphering the Fate of AI-Generated Code in Open Source</title>
  <link>https://arxiv.org/abs/2601.16809v1</link>
  <guid>https://arxiv.org/abs/2601.16809v1</guid>
  <pubDate>Fri, 23 Jan 2026 15:00:46 +0000</pubDate>
  <description>arXiv cs.AI - The integration of AI agents as coding assistants into software development has raised questions about the long-term viability of AI agent-generated code. A prevailing hypothesis within the software engineering community suggests this code is &quot;disposable&quot;, meaning it is merged quickly but discarded shortly thereafter. If true, organizations risk shifting maintenance burden from generation to post-</description>
</item>

<item>
  <title>An Efficient Insect-inspired Approach for Visual Point-goal Navigation</title>
  <link>https://arxiv.org/abs/2601.16806v1</link>
  <guid>https://arxiv.org/abs/2601.16806v1</guid>
  <pubDate>Fri, 23 Jan 2026 14:57:04 +0000</pubDate>
  <description>arXiv cs.AI - In this work we develop a novel insect-inspired agent for visual point-goal navigation. This combines abstracted models of two insect brain structures that have been implicated, respectively, in associative learning and path integration. We draw an analogy between the formal benchmark of the Habitat point-goal navigation task and the ability of insects to learn and refine visually guided paths aro</description>
</item>

<item>
  <title>Building a Robust Risk-Based Access Control System to Combat Ransomware&apos;s Capability to Encrypt: A Machine Learning Approach</title>
  <link>https://arxiv.org/abs/2601.16795v1</link>
  <guid>https://arxiv.org/abs/2601.16795v1</guid>
  <pubDate>Fri, 23 Jan 2026 14:48:35 +0000</pubDate>
  <description>arXiv cs.LG - Ransomware core capability, unauthorized encryption, demands controls that identify and block malicious cryptographic activity without disrupting legitimate use. We present a probabilistic, risk-based access control architecture that couples machine learning inference with mandatory access control to regulate encryption on Linux in real time. The system builds a specialized dataset from the native</description>
</item>

<item>
  <title>LLM-in-Sandbox Elicits General Agentic Intelligence</title>
  <link>https://arxiv.org/abs/2601.16206v1</link>
  <guid>https://arxiv.org/abs/2601.16206v1</guid>
  <pubDate>Thu, 22 Jan 2026 18:57:09 +0000</pubDate>
  <description>arXiv cs.AI - We introduce LLM-in-Sandbox, enabling LLMs to explore within a code sandbox (i.e., a virtual computer), to elicit general intelligence in non-code domains. We first demonstrate that strong LLMs, without additional training, exhibit generalization capabilities to leverage the code sandbox for non-code tasks. For example, LLMs spontaneously access external resources to acquire new knowledge, leverag</description>
</item>

<item>
  <title>Delayed Assignments in Online Non-Centroid Clustering with Stochastic Arrivals</title>
  <link>https://arxiv.org/abs/2601.16091v1</link>
  <guid>https://arxiv.org/abs/2601.16091v1</guid>
  <pubDate>Thu, 22 Jan 2026 16:42:05 +0000</pubDate>
  <description>arXiv cs.AI - Clustering is a fundamental problem, aiming to partition a set of elements, like agents or data points, into clusters such that elements in the same cluster are closer to each other than to those in other clusters. In this paper, we present a new framework for studying online non-centroid clustering with delays, where elements, that arrive one at a time as points in a finite metric space, should b</description>
</item>

<item>
  <title>Delayed Assignments in Online Non-Centroid Clustering with Stochastic Arrivals</title>
  <link>https://arxiv.org/abs/2601.16091v1</link>
  <guid>https://arxiv.org/abs/2601.16091v1</guid>
  <pubDate>Thu, 22 Jan 2026 16:42:05 +0000</pubDate>
  <description>arXiv cs.LG - Clustering is a fundamental problem, aiming to partition a set of elements, like agents or data points, into clusters such that elements in the same cluster are closer to each other than to those in other clusters. In this paper, we present a new framework for studying online non-centroid clustering with delays, where elements, that arrive one at a time as points in a finite metric space, should b</description>
</item>

<item>
  <title>Controlling Long-Horizon Behavior in Language Model Agents with Explicit State Dynamics</title>
  <link>https://arxiv.org/abs/2601.16087v1</link>
  <guid>https://arxiv.org/abs/2601.16087v1</guid>
  <pubDate>Thu, 22 Jan 2026 16:34:05 +0000</pubDate>
  <description>arXiv cs.AI - Large language model (LLM) agents often exhibit abrupt shifts in tone and persona during extended interaction, reflecting the absence of explicit temporal structure governing agent-level state. While prior work emphasizes turn-local sentiment or static emotion classification, the role of explicit affective dynamics in shaping long-horizon agent behavior remains underexplored. This work investigate</description>
</item>

<item>
  <title>AgriPINN: A Process-Informed Neural Network for Interpretable and Scalable Crop Biomass Prediction Under Water Stress</title>
  <link>https://arxiv.org/abs/2601.16045v1</link>
  <guid>https://arxiv.org/abs/2601.16045v1</guid>
  <pubDate>Thu, 22 Jan 2026 15:20:00 +0000</pubDate>
  <description>arXiv cs.AI - Accurate prediction of crop above-ground biomass (AGB) under water stress is critical for monitoring crop productivity, guiding irrigation, and supporting climate-resilient agriculture. Data-driven models scale well but often lack interpretability and degrade under distribution shift, whereas process-based crop models (e.g. DSSAT, APSIM, LINTUL5) require extensive calibration and are difficult to </description>
</item>

<item>
  <title>RayRoPE: Projective Ray Positional Encoding for Multi-view Attention</title>
  <link>https://arxiv.org/abs/2601.15275v1</link>
  <guid>https://arxiv.org/abs/2601.15275v1</guid>
  <pubDate>Wed, 21 Jan 2026 18:55:51 +0000</pubDate>
  <description>arXiv cs.LG - We study positional encodings for multi-view transformers that process tokens from a set of posed input images, and seek a mechanism that encodes patches uniquely, allows SE(3)-invariant attention with multi-frequency similarity, and can be adaptive to the geometry of the underlying scene. We find that prior (absolute or relative) encoding schemes for multi-view attention do not meet the above des</description>
</item>

<item>
  <title>Evaluation of Large Language Models in Legal Applications: Challenges, Methods, and Future Directions</title>
  <link>https://arxiv.org/abs/2601.15267v1</link>
  <guid>https://arxiv.org/abs/2601.15267v1</guid>
  <pubDate>Wed, 21 Jan 2026 18:51:37 +0000</pubDate>
  <description>arXiv cs.AI - Large language models (LLMs) are being increasingly integrated into legal applications, including judicial decision support, legal practice assistance, and public-facing legal services. While LLMs show strong potential in handling legal knowledge and tasks, their deployment in real-world legal settings raises critical concerns beyond surface-level accuracy, involving the soundness of legal reasoni</description>
</item>

<item>
  <title>Deaf and Hard of Hearing Access to Intelligent Personal Assistants: Comparison of Voice-Based Options with an LLM-Powered Touch Interface</title>
  <link>https://arxiv.org/abs/2601.15209v1</link>
  <guid>https://arxiv.org/abs/2601.15209v1</guid>
  <pubDate>Wed, 21 Jan 2026 17:33:00 +0000</pubDate>
  <description>arXiv cs.AI - We investigate intelligent personal assistants (IPAs) accessibility for deaf and hard of hearing (DHH) people who can use their voice in everyday communication. The inability of IPAs to understand diverse accents including deaf speech renders them largely inaccessible to non-signing and speaking DHH individuals. Using an Echo Show, we compare the usability of natural language input via spoken Engl</description>
</item>

<item>
  <title>Where Do AI Coding Agents Fail? An Empirical Study of Failed Agentic Pull Requests in GitHub</title>
  <link>https://arxiv.org/abs/2601.15195v1</link>
  <guid>https://arxiv.org/abs/2601.15195v1</guid>
  <pubDate>Wed, 21 Jan 2026 17:12:46 +0000</pubDate>
  <description>arXiv cs.AI - AI coding agents are now submitting pull requests (PRs) to software projects, acting not just as assistants but as autonomous contributors. As these agentic contributions are rapidly increasing across real repositories, little is known about how they behave in practice and why many of them fail to be merged. In this paper, we conduct a large-scale study of 33k agent-authored PRs made by five codin</description>
</item>

<item>
  <title>The Flexibility Trap: Why Arbitrary Order Limits Reasoning Potential in Diffusion Language Models</title>
  <link>https://arxiv.org/abs/2601.15165v1</link>
  <guid>https://arxiv.org/abs/2601.15165v1</guid>
  <pubDate>Wed, 21 Jan 2026 16:41:58 +0000</pubDate>
  <description>arXiv cs.AI - Diffusion Large Language Models (dLLMs) break the rigid left-to-right constraint of traditional LLMs, enabling token generation in arbitrary orders. Intuitively, this flexibility implies a solution space that strictly supersets the fixed autoregressive trajectory, theoretically unlocking superior reasoning potential for general tasks like mathematics and coding. Consequently, numerous works have l</description>
</item>

<item>
  <title>The Flexibility Trap: Why Arbitrary Order Limits Reasoning Potential in Diffusion Language Models</title>
  <link>https://arxiv.org/abs/2601.15165v1</link>
  <guid>https://arxiv.org/abs/2601.15165v1</guid>
  <pubDate>Wed, 21 Jan 2026 16:41:58 +0000</pubDate>
  <description>arXiv cs.LG - Diffusion Large Language Models (dLLMs) break the rigid left-to-right constraint of traditional LLMs, enabling token generation in arbitrary orders. Intuitively, this flexibility implies a solution space that strictly supersets the fixed autoregressive trajectory, theoretically unlocking superior reasoning potential for general tasks like mathematics and coding. Consequently, numerous works have l</description>
</item>

<item>
  <title>Automated Rubrics for Reliable Evaluation of Medical Dialogue Systems</title>
  <link>https://arxiv.org/abs/2601.15161v1</link>
  <guid>https://arxiv.org/abs/2601.15161v1</guid>
  <pubDate>Wed, 21 Jan 2026 16:40:41 +0000</pubDate>
  <description>arXiv cs.AI - Large Language Models (LLMs) are increasingly used for clinical decision support, where hallucinations and unsafe suggestions may pose direct risks to patient safety. These risks are particularly challenging as they often manifest as subtle clinical errors that evade detection by generic metrics, while expert-authored fine-grained rubrics remain costly to construct and difficult to scale. In this </description>
</item>

<item>
  <title>How to Build AI Agents by Augmenting LLMs with Codified Human Expert Domain Knowledge? A Software Engineering Framework</title>
  <link>https://arxiv.org/abs/2601.15153v1</link>
  <guid>https://arxiv.org/abs/2601.15153v1</guid>
  <pubDate>Wed, 21 Jan 2026 16:23:22 +0000</pubDate>
  <description>arXiv cs.AI - Critical domain knowledge typically resides with few experts, creating organizational bottlenecks in scalability and decision-making. Non-experts struggle to create effective visualizations, leading to suboptimal insights and diverting expert time. This paper investigates how to capture and embed human domain knowledge into AI agent systems through an industrial case study. We propose a software e</description>
</item>

<item>
  <title>CLEANER: Self-Purified Trajectories Boost Agentic Reinforcement Learning</title>
  <link>https://arxiv.org/abs/2601.15141v1</link>
  <guid>https://arxiv.org/abs/2601.15141v1</guid>
  <pubDate>Wed, 21 Jan 2026 16:14:30 +0000</pubDate>
  <description>arXiv cs.LG - Agentic Reinforcement Learning (RL) has empowered Large Language Models (LLMs) to utilize tools like Python interpreters for complex problem-solving. However, for parameter-constrained models (e.g., 4B--7B), the exploration phase is often plagued by frequent execution failures, creating noisy trajectories that hinder policy optimization. Under standard outcome-based reward settings, this noise lea</description>
</item>

<item>
  <title>Emerging from Ground: Addressing Intent Deviation in Tool-Using Agents via Deriving Real Calls into Virtual Trajectories</title>
  <link>https://arxiv.org/abs/2601.15120v1</link>
  <guid>https://arxiv.org/abs/2601.15120v1</guid>
  <pubDate>Wed, 21 Jan 2026 15:58:54 +0000</pubDate>
  <description>arXiv cs.AI - LLMs have advanced tool-using agents for real-world applications, yet they often lead to unexpected behaviors or results. Beyond obvious failures, the subtle issue of &quot;intent deviation&quot; severely hinders reliable evaluation and performance improvement. Existing post-training methods generally leverage either real system samples or virtual data simulated by LLMs. However, the former is costly due to</description>
</item>

<item>
  <title>Memory Retention Is Not Enough to Master Memory Tasks in Reinforcement Learning</title>
  <link>https://arxiv.org/abs/2601.15086v1</link>
  <guid>https://arxiv.org/abs/2601.15086v1</guid>
  <pubDate>Wed, 21 Jan 2026 15:27:23 +0000</pubDate>
  <description>arXiv cs.LG - Effective decision-making in the real world depends on memory that is both stable and adaptive: environments change over time, and agents must retain relevant information over long horizons while also updating or overwriting outdated content when circumstances shift. Existing Reinforcement Learning (RL) benchmarks and memory-augmented agents focus primarily on retention, leaving the equally critic</description>
</item>

<item>
  <title>Multi-Agent Constraint Factorization Reveals Latent Invariant Solution Structure</title>
  <link>https://arxiv.org/abs/2601.15077v1</link>
  <guid>https://arxiv.org/abs/2601.15077v1</guid>
  <pubDate>Wed, 21 Jan 2026 15:23:04 +0000</pubDate>
  <description>arXiv cs.LG - Multi-agent systems (MAS) composed of large language models often exhibit improved problem-solving performance despite operating on identical information. In this work, we provide a formal explanation for this phenomenon grounded in operator theory and constrained optimization. We model each agent as enforcing a distinct family of validity constraints on a shared solution state, and show that a MA</description>
</item>

<item>
  <title>SmartOracle -- An Agentic Approach to Mitigate Noise in Differential Oracles</title>
  <link>https://arxiv.org/abs/2601.15074v1</link>
  <guid>https://arxiv.org/abs/2601.15074v1</guid>
  <pubDate>Wed, 21 Jan 2026 15:20:53 +0000</pubDate>
  <description>arXiv cs.LG - Differential fuzzers detect bugs by executing identical inputs across distinct implementations of the same specification, such as JavaScript interpreters. Validating the outputs requires an oracle and for differential testing of JavaScript, these are constructed manually, making them expensive, time-consuming, and prone to false positives. Worse, when the specification evolves, this manual effort </description>
</item>

<item>
  <title>APEX-Agents</title>
  <link>https://arxiv.org/abs/2601.14242v1</link>
  <guid>https://arxiv.org/abs/2601.14242v1</guid>
  <pubDate>Tue, 20 Jan 2026 18:53:44 +0000</pubDate>
  <description>arXiv cs.AI - We introduce the AI Productivity Index for Agents (APEX-Agents), a benchmark for assessing whether AI agents can execute long-horizon, cross-application tasks created by investment banking analysts, management consultants, and corporate lawyers. APEX-Agents requires agents to navigate realistic work environments with files and tools. We test eight agents for the leaderboard using Pass@1. Gemini 3 </description>
</item>

<item>
  <title>APEX-Agents</title>
  <link>https://arxiv.org/abs/2601.14242v1</link>
  <guid>https://arxiv.org/abs/2601.14242v1</guid>
  <pubDate>Tue, 20 Jan 2026 18:53:44 +0000</pubDate>
  <description>arXiv cs.LG - We introduce the AI Productivity Index for Agents (APEX-Agents), a benchmark for assessing whether AI agents can execute long-horizon, cross-application tasks created by investment banking analysts, management consultants, and corporate lawyers. APEX-Agents requires agents to navigate realistic work environments with files and tools. We test eight agents for the leaderboard using Pass@1. Gemini 3 </description>
</item>

<item>
  <title>Spatiotemporal Wildfire Prediction and Reinforcement Learning for Helitack Suppression</title>
  <link>https://arxiv.org/abs/2601.14238v1</link>
  <guid>https://arxiv.org/abs/2601.14238v1</guid>
  <pubDate>Tue, 20 Jan 2026 18:50:12 +0000</pubDate>
  <description>arXiv cs.LG - Wildfires are growing in frequency and intensity, devastating ecosystems and communities while causing billions of dollars in suppression costs and economic damage annually in the U.S. Traditional wildfire management is mostly reactive, addressing fires only after they are detected. We introduce \textit{FireCastRL}, a proactive artificial intelligence (AI) framework that combines wildfire forecast</description>
</item>

<item>
  <title>Opportunities in AI/ML for the Rubin LSST Dark Energy Science Collaboration</title>
  <link>https://arxiv.org/abs/2601.14235v1</link>
  <guid>https://arxiv.org/abs/2601.14235v1</guid>
  <pubDate>Tue, 20 Jan 2026 18:46:42 +0000</pubDate>
  <description>arXiv cs.AI - The Vera C. Rubin Observatory&apos;s Legacy Survey of Space and Time (LSST) will produce unprecedented volumes of heterogeneous astronomical data (images, catalogs, and alerts) that challenge traditional analysis pipelines. The LSST Dark Energy Science Collaboration (DESC) aims to derive robust constraints on dark energy and dark matter from these data, requiring methods that are statistically powerful</description>
</item>

<item>
  <title>Opportunities in AI/ML for the Rubin LSST Dark Energy Science Collaboration</title>
  <link>https://arxiv.org/abs/2601.14235v1</link>
  <guid>https://arxiv.org/abs/2601.14235v1</guid>
  <pubDate>Tue, 20 Jan 2026 18:46:42 +0000</pubDate>
  <description>arXiv cs.LG - The Vera C. Rubin Observatory&apos;s Legacy Survey of Space and Time (LSST) will produce unprecedented volumes of heterogeneous astronomical data (images, catalogs, and alerts) that challenge traditional analysis pipelines. The LSST Dark Energy Science Collaboration (DESC) aims to derive robust constraints on dark energy and dark matter from these data, requiring methods that are statistically powerful</description>
</item>

<item>
  <title>KAGE-Bench: Fast Known-Axis Visual Generalization Evaluation for Reinforcement Learning</title>
  <link>https://arxiv.org/abs/2601.14232v1</link>
  <guid>https://arxiv.org/abs/2601.14232v1</guid>
  <pubDate>Tue, 20 Jan 2026 18:44:28 +0000</pubDate>
  <description>arXiv cs.AI - Pixel-based reinforcement learning agents often fail under purely visual distribution shift even when latent dynamics and rewards are unchanged, but existing benchmarks entangle multiple sources of shift and hinder systematic analysis. We introduce KAGE-Env, a JAX-native 2D platformer that factorizes the observation process into independently controllable visual axes while keeping the underlying c</description>
</item>

<item>
  <title>KAGE-Bench: Fast Known-Axis Visual Generalization Evaluation for Reinforcement Learning</title>
  <link>https://arxiv.org/abs/2601.14232v1</link>
  <guid>https://arxiv.org/abs/2601.14232v1</guid>
  <pubDate>Tue, 20 Jan 2026 18:44:28 +0000</pubDate>
  <description>arXiv cs.LG - Pixel-based reinforcement learning agents often fail under purely visual distribution shift even when latent dynamics and rewards are unchanged, but existing benchmarks entangle multiple sources of shift and hinder systematic analysis. We introduce KAGE-Env, a JAX-native 2D platformer that factorizes the observation process into independently controllable visual axes while keeping the underlying c</description>
</item>

<item>
  <title>MASCOT: Towards Multi-Agent Socio-Collaborative Companion Systems</title>
  <link>https://arxiv.org/abs/2601.14230v1</link>
  <guid>https://arxiv.org/abs/2601.14230v1</guid>
  <pubDate>Tue, 20 Jan 2026 18:44:04 +0000</pubDate>
  <description>arXiv cs.AI - Multi-agent systems (MAS) have recently emerged as promising socio-collaborative companions for emotional and cognitive support. However, these systems frequently suffer from persona collapse--where agents revert to generic, homogenized assistant behaviors--and social sycophancy, which produces redundant, non-constructive dialogue. We propose MASCOT, a generalizable framework for multi-perspective</description>
</item>

<item>
  <title>Attention-Based Offline Reinforcement Learning and Clustering for Interpretable Sepsis Treatment</title>
  <link>https://arxiv.org/abs/2601.14228v1</link>
  <guid>https://arxiv.org/abs/2601.14228v1</guid>
  <pubDate>Tue, 20 Jan 2026 18:41:44 +0000</pubDate>
  <description>arXiv cs.LG - Sepsis remains one of the leading causes of mortality in intensive care units, where timely and accurate treatment decisions can significantly impact patient outcomes. In this work, we propose an interpretable decision support framework. Our system integrates four core components: (1) a clustering-based stratification module that categorizes patients into low, intermediate, and high-risk groups up</description>
</item>

</channel>
</rss>
