<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
<channel>
  <title>AI Research Digest</title>
  <link>https://xiaolin-econ.github.io/ai-digest/</link>
  <description>Curated AI research + releases</description>
  <lastBuildDate>Tue, 03 Feb 2026 18:43:02 +0000</lastBuildDate>
  <atom:link href="https://xiaolin-econ.github.io/ai-digest/rss.xml" rel="self" type="application/rss+xml" xmlns:atom="http://www.w3.org/2005/Atom"/>
  
<item>
  <title>AI Digest — Daily Summary</title>
  <link>https://xiaolin-econ.github.io/ai-digest/rss.xml</link>
  <guid>https://xiaolin-econ.github.io/ai-digest/rss.xml#summary</guid>
  <pubDate>Tue, 03 Feb 2026 18:43:02 +0000</pubDate>
  <description>Clinical brain-to-text interfaces are designed for paralysed patients who cannot provide extensive training recordings. Pre-training improves data-efficient generalisation by learning statistical priors across subjects, but these priors critically depend on context. While natural speech might unfold gradually over minutes, most methods pre-train with only a few seconds of context. Thus, we propose MEG-XL, a model pre-trained with 2.5 minutes of MEG context per sample, 5-300x longer than prior work, and equivalent to 191k tokens, capturing extended neural context. Fine-tuning on the task of word decoding from brain data, MEG-XL matches supervised performance with a fraction of the data (e.g. 1hr vs 50hrs) and outperforms brain foundation models. We find that models pre-trained with longer…</description>
</item>

<item>
  <title>MEG-XL: Data-Efficient Brain-to-Text via Long-Context Pre-Training</title>
  <link>https://arxiv.org/abs/2602.02494v1</link>
  <guid>https://arxiv.org/abs/2602.02494v1</guid>
  <pubDate>Mon, 02 Feb 2026 18:59:50 +0000</pubDate>
  <description>arXiv cs.LG - Clinical brain-to-text interfaces are designed for paralysed patients who cannot provide extensive training recordings. Pre-training improves data-efficient generalisation by learning statistical priors across subjects, but these priors critically depend on context. While natural speech might unfold gradually over minutes, most methods pre-train with only a few seconds of context. Thus, we propose</description>
</item>

<item>
  <title>RLAnything: Forge Environment, Policy, and Reward Model in Completely Dynamic RL System</title>
  <link>https://arxiv.org/abs/2602.02488v1</link>
  <guid>https://arxiv.org/abs/2602.02488v1</guid>
  <pubDate>Mon, 02 Feb 2026 18:59:04 +0000</pubDate>
  <description>arXiv cs.LG - We propose RLAnything, a reinforcement learning framework that dynamically forges environment, policy, and reward models through closed-loop optimization, amplifying learning signals and strengthening the overall RL system for any LLM or agentic scenarios. Specifically, the policy is trained with integrated feedback from step-wise and outcome signals, while the reward model is jointly optimized vi</description>
</item>

<item>
  <title>RE-TRAC: REcursive TRAjectory Compression for Deep Search Agents</title>
  <link>https://arxiv.org/abs/2602.02486v1</link>
  <guid>https://arxiv.org/abs/2602.02486v1</guid>
  <pubDate>Mon, 02 Feb 2026 18:58:07 +0000</pubDate>
  <description>arXiv cs.AI - LLM-based deep research agents are largely built on the ReAct framework. This linear design makes it difficult to revisit earlier states, branch into alternative search directions, or maintain global awareness under long contexts, often leading to local optima, redundant exploration, and inefficient search. We propose Re-TRAC, an agentic framework that performs cross-trajectory exploration by gene</description>
</item>

<item>
  <title>Expanding the Capabilities of Reinforcement Learning via Text Feedback</title>
  <link>https://arxiv.org/abs/2602.02482v1</link>
  <guid>https://arxiv.org/abs/2602.02482v1</guid>
  <pubDate>Mon, 02 Feb 2026 18:56:56 +0000</pubDate>
  <description>arXiv cs.LG - The success of RL for LLM post-training stems from an unreasonably uninformative source: a single bit of information per rollout as binary reward or preference label. At the other extreme, distillation offers dense supervision but requires demonstrations, which are costly and difficult to scale. We study text feedback as an intermediate signal: richer than scalar rewards, yet cheaper than complete</description>
</item>

<item>
  <title>AgentRx: Diagnosing AI Agent Failures from Execution Trajectories</title>
  <link>https://arxiv.org/abs/2602.02475v1</link>
  <guid>https://arxiv.org/abs/2602.02475v1</guid>
  <pubDate>Mon, 02 Feb 2026 18:54:07 +0000</pubDate>
  <description>arXiv cs.AI - AI agents often fail in ways that are difficult to localize because executions are probabilistic, long-horizon, multi-agent, and mediated by noisy tool outputs. We address this gap by manually annotating failed agent runs and release a novel benchmark of 115 failed trajectories spanning structured API workflows, incident management, and open-ended web/file tasks. Each trajectory is annotated with </description>
</item>

<item>
  <title>MemSkill: Learning and Evolving Memory Skills for Self-Evolving Agents</title>
  <link>https://arxiv.org/abs/2602.02474v1</link>
  <guid>https://arxiv.org/abs/2602.02474v1</guid>
  <pubDate>Mon, 02 Feb 2026 18:53:28 +0000</pubDate>
  <description>arXiv cs.AI - Most Large Language Model (LLM) agent memory systems rely on a small set of static, hand-designed operations for extracting memory. These fixed procedures hard-code human priors about what to store and how to revise memory, making them rigid under diverse interaction patterns and inefficient on long histories. To this end, we present \textbf{MemSkill}, which reframes these operations as learnable </description>
</item>

<item>
  <title>MemSkill: Learning and Evolving Memory Skills for Self-Evolving Agents</title>
  <link>https://arxiv.org/abs/2602.02474v1</link>
  <guid>https://arxiv.org/abs/2602.02474v1</guid>
  <pubDate>Mon, 02 Feb 2026 18:53:28 +0000</pubDate>
  <description>arXiv cs.LG - Most Large Language Model (LLM) agent memory systems rely on a small set of static, hand-designed operations for extracting memory. These fixed procedures hard-code human priors about what to store and how to revise memory, making them rigid under diverse interaction patterns and inefficient on long histories. To this end, we present \textbf{MemSkill}, which reframes these operations as learnable </description>
</item>

<item>
  <title>Multi-head automated segmentation by incorporating detection head into the contextual layer neural network</title>
  <link>https://arxiv.org/abs/2602.02471v1</link>
  <guid>https://arxiv.org/abs/2602.02471v1</guid>
  <pubDate>Mon, 02 Feb 2026 18:51:25 +0000</pubDate>
  <description>arXiv cs.AI - Deep learning based auto segmentation is increasingly used in radiotherapy, but conventional models often produce anatomically implausible false positives, or hallucinations, in slices lacking target structures. We propose a gated multi-head Transformer architecture based on Swin U-Net, augmented with inter-slice context integration and a parallel detection head, which jointly performs slice-level</description>
</item>

<item>
  <title>Avenir-Web: Human-Experience-Imitating Multimodal Web Agents with Mixture of Grounding Experts</title>
  <link>https://arxiv.org/abs/2602.02468v1</link>
  <guid>https://arxiv.org/abs/2602.02468v1</guid>
  <pubDate>Mon, 02 Feb 2026 18:50:07 +0000</pubDate>
  <description>arXiv cs.AI - Despite advances in multimodal large language models, autonomous web agents still struggle to reliably execute long-horizon tasks on complex and dynamic web interfaces. Existing agents often suffer from inaccurate element grounding, the absence of site-specific procedural knowledge, and unstable long-term task tracking and memory, particularly when operating over complex Document Object Model stru</description>
</item>

<item>
  <title>Drift-Bench: Diagnosing Cooperative Breakdowns in LLM Agents under Input Faults via Multi-Turn Interaction</title>
  <link>https://arxiv.org/abs/2602.02455v1</link>
  <guid>https://arxiv.org/abs/2602.02455v1</guid>
  <pubDate>Mon, 02 Feb 2026 18:46:16 +0000</pubDate>
  <description>arXiv cs.AI - As Large Language Models transition to autonomous agents, user inputs frequently violate cooperative assumptions (e.g., implicit intent, missing parameters, false presuppositions, or ambiguous expressions), creating execution risks that text-only evaluations do not capture. Existing benchmarks typically assume well-specified instructions or restrict evaluation to text-only, single-turn clarificati</description>
</item>

<item>
  <title>Energy-Efficient Neuromorphic Computing for Edge AI: A Framework with Adaptive Spiking Neural Networks and Hardware-Aware Optimization</title>
  <link>https://arxiv.org/abs/2602.02439v1</link>
  <guid>https://arxiv.org/abs/2602.02439v1</guid>
  <pubDate>Mon, 02 Feb 2026 18:34:48 +0000</pubDate>
  <description>arXiv cs.LG - Edge AI applications increasingly require ultra-low-power, low-latency inference. Neuromorphic computing based on event-driven spiking neural networks (SNNs) offers an attractive path, but practical deployment on resource-constrained devices is limited by training difficulty, hardware-mapping overheads, and sensitivity to temporal dynamics. We present NeuEdge, a framework that combines adaptive SN</description>
</item>

<item>
  <title>UniReason 1.0: A Unified Reasoning Framework for World Knowledge Aligned Image Generation and Editing</title>
  <link>https://arxiv.org/abs/2602.02437v1</link>
  <guid>https://arxiv.org/abs/2602.02437v1</guid>
  <pubDate>Mon, 02 Feb 2026 18:34:35 +0000</pubDate>
  <description>arXiv cs.AI - Unified multimodal models often struggle with complex synthesis tasks that demand deep reasoning, and typically treat text-to-image generation and image editing as isolated capabilities rather than interconnected reasoning steps. To address this, we propose UniReason, a unified framework that harmonizes these two tasks through a dual reasoning paradigm. We formulate generation as world knowledge-e</description>
</item>

<item>
  <title>David vs. Goliath: Verifiable Agent-to-Agent Jailbreaking via Reinforcement Learning</title>
  <link>https://arxiv.org/abs/2602.02395v1</link>
  <guid>https://arxiv.org/abs/2602.02395v1</guid>
  <pubDate>Mon, 02 Feb 2026 17:56:55 +0000</pubDate>
  <description>arXiv cs.AI - The evolution of large language models into autonomous agents introduces adversarial failures that exploit legitimate tool privileges, transforming safety evaluation in tool-augmented environments from a subjective NLP task into an objective control problem. We formalize this threat model as Tag-Along Attacks: a scenario where a tool-less adversary &quot;tags along&quot; on the trusted privileges of a safet</description>
</item>

<item>
  <title>End-to-end Optimization of Belief and Policy Learning in Shared Autonomy Paradigms</title>
  <link>https://arxiv.org/abs/2601.23285v1</link>
  <guid>https://arxiv.org/abs/2601.23285v1</guid>
  <pubDate>Fri, 30 Jan 2026 18:59:16 +0000</pubDate>
  <description>arXiv cs.AI - Shared autonomy systems require principled methods for inferring user intent and determining appropriate assistance levels. This is a central challenge in human-robot interaction, where systems must be successful while being mindful of user agency. Previous approaches relied on static blending ratios or separated goal inference from assistance arbitration, leading to suboptimal performance in unst</description>
</item>

<item>
  <title>End-to-end Optimization of Belief and Policy Learning in Shared Autonomy Paradigms</title>
  <link>https://arxiv.org/abs/2601.23285v1</link>
  <guid>https://arxiv.org/abs/2601.23285v1</guid>
  <pubDate>Fri, 30 Jan 2026 18:59:16 +0000</pubDate>
  <description>arXiv cs.LG - Shared autonomy systems require principled methods for inferring user intent and determining appropriate assistance levels. This is a central challenge in human-robot interaction, where systems must be successful while being mindful of user agency. Previous approaches relied on static blending ratios or separated goal inference from assistance arbitration, leading to suboptimal performance in unst</description>
</item>

<item>
  <title>FOCUS: DLLMs Know How to Tame Their Compute Bound</title>
  <link>https://arxiv.org/abs/2601.23278v1</link>
  <guid>https://arxiv.org/abs/2601.23278v1</guid>
  <pubDate>Fri, 30 Jan 2026 18:52:06 +0000</pubDate>
  <description>arXiv cs.LG - Diffusion Large Language Models (DLLMs) offer a compelling alternative to Auto-Regressive models, but their deployment is constrained by high decoding cost. In this work, we identify a key inefficiency in DLLM decoding: while computation is parallelized over token blocks, only a small subset of tokens is decodable at each diffusion step, causing most compute to be wasted on non-decodable tokens. W</description>
</item>

<item>
  <title>Denoising the Deep Sky: Physics-Based CCD Noise Formation for Astronomical Imaging</title>
  <link>https://arxiv.org/abs/2601.23276v1</link>
  <guid>https://arxiv.org/abs/2601.23276v1</guid>
  <pubDate>Fri, 30 Jan 2026 18:47:54 +0000</pubDate>
  <description>arXiv cs.LG - Astronomical imaging remains noise-limited under practical observing constraints, while standard calibration pipelines mainly remove structured artifacts and leave stochastic noise largely unresolved. Learning-based denoising is promising, yet progress is hindered by scarce paired training data and the need for physically interpretable and reproducible models in scientific workflows. We propose a </description>
</item>

<item>
  <title>IRL-DAL: Safe and Adaptive Trajectory Planning for Autonomous Driving via Energy-Guided Diffusion Models</title>
  <link>https://arxiv.org/abs/2601.23266v1</link>
  <guid>https://arxiv.org/abs/2601.23266v1</guid>
  <pubDate>Fri, 30 Jan 2026 18:34:10 +0000</pubDate>
  <description>arXiv cs.AI - This paper proposes a novel inverse reinforcement learning framework using a diffusion-based adaptive lookahead planner (IRL-DAL) for autonomous vehicles. Training begins with imitation from an expert finite state machine (FSM) controller to provide a stable initialization. Environment terms are combined with an IRL discriminator signal to align with expert goals. Reinforcement learning (RL) is th</description>
</item>

<item>
  <title>Now You Hear Me: Audio Narrative Attacks Against Large Audio-Language Models</title>
  <link>https://arxiv.org/abs/2601.23255v1</link>
  <guid>https://arxiv.org/abs/2601.23255v1</guid>
  <pubDate>Fri, 30 Jan 2026 18:23:02 +0000</pubDate>
  <description>arXiv cs.AI - Large audio-language models increasingly operate on raw speech inputs, enabling more seamless integration across domains such as voice assistants, education, and clinical triage. This transition, however, introduces a distinct class of vulnerabilities that remain largely uncharacterized. We examine the security implications of this modality shift by designing a text-to-audio jailbreak that embeds </description>
</item>

<item>
  <title>ShotFinder: Imagination-Driven Open-Domain Video Shot Retrieval via Web Search</title>
  <link>https://arxiv.org/abs/2601.23232v1</link>
  <guid>https://arxiv.org/abs/2601.23232v1</guid>
  <pubDate>Fri, 30 Jan 2026 18:01:17 +0000</pubDate>
  <description>arXiv cs.AI - In recent years, large language models (LLMs) have made rapid progress in information retrieval, yet existing research has mainly focused on text or static multimodal settings. Open-domain video shot retrieval, which involves richer temporal structure and more complex semantics, still lacks systematic benchmarks and analysis. To fill this gap, we introduce ShotFinder, a benchmark that formalizes e</description>
</item>

<item>
  <title>Scaling Multiagent Systems with Process Rewards</title>
  <link>https://arxiv.org/abs/2601.23228v1</link>
  <guid>https://arxiv.org/abs/2601.23228v1</guid>
  <pubDate>Fri, 30 Jan 2026 17:55:27 +0000</pubDate>
  <description>arXiv cs.AI - While multiagent systems have shown promise for tackling complex tasks via specialization, finetuning multiple agents simultaneously faces two key challenges: (1) credit assignment across agents, and (2) sample efficiency of expensive multiagent rollouts. In this work, we propose finetuning multiagent systems with per-action process rewards from AI feedback (MAPPA) to address both. Through assigni</description>
</item>

<item>
  <title>MonoScale: Scaling Multi-Agent System with Monotonic Improvement</title>
  <link>https://arxiv.org/abs/2601.23219v1</link>
  <guid>https://arxiv.org/abs/2601.23219v1</guid>
  <pubDate>Fri, 30 Jan 2026 17:44:49 +0000</pubDate>
  <description>arXiv cs.AI - In recent years, LLM-based multi-agent systems (MAS) have advanced rapidly, using a router to decompose tasks and delegate subtasks to specialized agents. A natural way to expand capability is to scale up the agent pool by continually integrating new functional agents or tool interfaces, but naive expansion can trigger performance collapse when the router cold-starts on newly added, heterogeneous,</description>
</item>

<item>
  <title>Tackling air quality with SAPIENS</title>
  <link>https://arxiv.org/abs/2601.23215v1</link>
  <guid>https://arxiv.org/abs/2601.23215v1</guid>
  <pubDate>Fri, 30 Jan 2026 17:41:38 +0000</pubDate>
  <description>arXiv cs.LG - Air pollution is a chronic problem in large cities worldwide and awareness is rising as the long-term health implications become clearer. Vehicular traffic has been identified as a major contributor to poor air quality. In a lot of cities the publicly available air quality measurements and forecasts are coarse-grained both in space and time. However, in general, real-time traffic intensity data is</description>
</item>

<item>
  <title>High-quality generation of dynamic game content via small language models: A proof of concept</title>
  <link>https://arxiv.org/abs/2601.23206v1</link>
  <guid>https://arxiv.org/abs/2601.23206v1</guid>
  <pubDate>Fri, 30 Jan 2026 17:30:59 +0000</pubDate>
  <description>arXiv cs.AI - Large language models (LLMs) offer promise for dynamic game content generation, but they face critical barriers, including narrative incoherence and high operational costs. Due to their large size, they are often accessed in the cloud, limiting their application in offline games. Many of these practical issues are solved by pivoting to small language models (SLMs), but existing studies using SLMs </description>
</item>

<item>
  <title>Ensuring Semantics in Weights of Implicit Neural Representations through the Implicit Function Theorem</title>
  <link>https://arxiv.org/abs/2601.23181v1</link>
  <guid>https://arxiv.org/abs/2601.23181v1</guid>
  <pubDate>Fri, 30 Jan 2026 17:05:37 +0000</pubDate>
  <description>arXiv cs.LG - Weight Space Learning (WSL), which frames neural network weights as a data modality, is an emerging field with potential for tasks like meta-learning or transfer learning. Particularly, Implicit Neural Representations (INRs) provide a convenient testbed, where each set of weights determines the corresponding individual data sample as a mapping from coordinates to contextual values. So far, a preci</description>
</item>

<item>
  <title>TriSpec: Ternary Speculative Decoding via Lightweight Proxy Verification</title>
  <link>https://arxiv.org/abs/2601.23180v1</link>
  <guid>https://arxiv.org/abs/2601.23180v1</guid>
  <pubDate>Fri, 30 Jan 2026 17:04:18 +0000</pubDate>
  <description>arXiv cs.LG - Inference efficiency in Large Language Models (LLMs) is fundamentally limited by their serial, autoregressive generation, especially as reasoning becomes a key capability and response sequences grow longer. Speculative decoding (SD) offers a powerful solution, providing significant speed-ups through its lightweight drafting and parallel verification mechanism. While existing work has nearly satura</description>
</item>

<item>
  <title>Beyond Fixed Frames: Dynamic Character-Aligned Speech Tokenization</title>
  <link>https://arxiv.org/abs/2601.23174v1</link>
  <guid>https://arxiv.org/abs/2601.23174v1</guid>
  <pubDate>Fri, 30 Jan 2026 16:58:40 +0000</pubDate>
  <description>arXiv cs.AI - Neural audio codecs are at the core of modern conversational speech technologies, converting continuous speech into sequences of discrete tokens that can be processed by LLMs. However, existing codecs typically operate at fixed frame rates, allocating tokens uniformly in time and producing unnecessarily long sequences. In this work, we introduce DyCAST, a Dynamic Character-Aligned Speech Tokenizer</description>
</item>

<item>
  <title>Beyond Fixed Frames: Dynamic Character-Aligned Speech Tokenization</title>
  <link>https://arxiv.org/abs/2601.23174v1</link>
  <guid>https://arxiv.org/abs/2601.23174v1</guid>
  <pubDate>Fri, 30 Jan 2026 16:58:40 +0000</pubDate>
  <description>arXiv cs.LG - Neural audio codecs are at the core of modern conversational speech technologies, converting continuous speech into sequences of discrete tokens that can be processed by LLMs. However, existing codecs typically operate at fixed frame rates, allocating tokens uniformly in time and producing unnecessarily long sequences. In this work, we introduce DyCAST, a Dynamic Character-Aligned Speech Tokenizer</description>
</item>

<item>
  <title>RedSage: A Cybersecurity Generalist LLM</title>
  <link>https://arxiv.org/abs/2601.22159v1</link>
  <guid>https://arxiv.org/abs/2601.22159v1</guid>
  <pubDate>Thu, 29 Jan 2026 18:59:57 +0000</pubDate>
  <description>arXiv cs.AI - Cybersecurity operations demand assistant LLMs that support diverse workflows without exposing sensitive data. Existing solutions either rely on proprietary APIs with privacy risks or on open models lacking domain adaptation. To bridge this gap, we curate 11.8B tokens of cybersecurity-focused continual pretraining data via large-scale web filtering and manual collection of high-quality resources, </description>
</item>

<item>
  <title>Hybrid Linear Attention Done Right: Efficient Distillation and Effective Architectures for Extremely Long Contexts</title>
  <link>https://arxiv.org/abs/2601.22156v1</link>
  <guid>https://arxiv.org/abs/2601.22156v1</guid>
  <pubDate>Thu, 29 Jan 2026 18:59:53 +0000</pubDate>
  <description>arXiv cs.AI - Hybrid Transformer architectures, which combine softmax attention blocks and recurrent neural networks (RNNs), have shown a desirable performance-throughput tradeoff for long-context modeling, but their adoption and studies are hindered by the prohibitive cost of large-scale pre-training from scratch. Some recent studies have shown that pre-trained softmax attention blocks can be converted into RN</description>
</item>

<item>
  <title>Hybrid Linear Attention Done Right: Efficient Distillation and Effective Architectures for Extremely Long Contexts</title>
  <link>https://arxiv.org/abs/2601.22156v1</link>
  <guid>https://arxiv.org/abs/2601.22156v1</guid>
  <pubDate>Thu, 29 Jan 2026 18:59:53 +0000</pubDate>
  <description>arXiv cs.LG - Hybrid Transformer architectures, which combine softmax attention blocks and recurrent neural networks (RNNs), have shown a desirable performance-throughput tradeoff for long-context modeling, but their adoption and studies are hindered by the prohibitive cost of large-scale pre-training from scratch. Some recent studies have shown that pre-trained softmax attention blocks can be converted into RN</description>
</item>

<item>
  <title>Exploring Reasoning Reward Model for Agents</title>
  <link>https://arxiv.org/abs/2601.22154v1</link>
  <guid>https://arxiv.org/abs/2601.22154v1</guid>
  <pubDate>Thu, 29 Jan 2026 18:59:52 +0000</pubDate>
  <description>arXiv cs.AI - Agentic Reinforcement Learning (Agentic RL) has achieved notable success in enabling agents to perform complex reasoning and tool use. However, most methods still relies on sparse outcome-based reward for training. Such feedback fails to differentiate intermediate reasoning quality, leading to suboptimal training results. In this paper, we introduce Agent Reasoning Reward Model (Agent-RRM), a mult</description>
</item>

<item>
  <title>DynaWeb: Model-Based Reinforcement Learning of Web Agents</title>
  <link>https://arxiv.org/abs/2601.22149v1</link>
  <guid>https://arxiv.org/abs/2601.22149v1</guid>
  <pubDate>Thu, 29 Jan 2026 18:59:07 +0000</pubDate>
  <description>arXiv cs.AI - The development of autonomous web agents, powered by Large Language Models (LLMs) and reinforcement learning (RL), represents a significant step towards general-purpose AI assistants. However, training these agents is severely hampered by the challenges of interacting with the live internet, which is inefficient, costly, and fraught with risks. Model-based reinforcement learning (MBRL) offers a pr</description>
</item>

<item>
  <title>StepShield: When, Not Whether to Intervene on Rogue Agents</title>
  <link>https://arxiv.org/abs/2601.22136v1</link>
  <guid>https://arxiv.org/abs/2601.22136v1</guid>
  <pubDate>Thu, 29 Jan 2026 18:55:46 +0000</pubDate>
  <description>arXiv cs.AI - Existing agent safety benchmarks report binary accuracy, conflating early intervention with post-mortem analysis. A detector that flags a violation at step 8 enables intervention; one that reports it at step 48 provides only forensic value. This distinction is critical, yet current benchmarks cannot measure it. We introduce StepShield, the first benchmark to evaluate when violations are detected, </description>
</item>

<item>
  <title>StepShield: When, Not Whether to Intervene on Rogue Agents</title>
  <link>https://arxiv.org/abs/2601.22136v1</link>
  <guid>https://arxiv.org/abs/2601.22136v1</guid>
  <pubDate>Thu, 29 Jan 2026 18:55:46 +0000</pubDate>
  <description>arXiv cs.LG - Existing agent safety benchmarks report binary accuracy, conflating early intervention with post-mortem analysis. A detector that flags a violation at step 8 enables intervention; one that reports it at step 48 provides only forensic value. This distinction is critical, yet current benchmarks cannot measure it. We introduce StepShield, the first benchmark to evaluate when violations are detected, </description>
</item>

<item>
  <title>Pay for Hints, Not Answers: LLM Shepherding for Cost-Efficient Inference</title>
  <link>https://arxiv.org/abs/2601.22132v1</link>
  <guid>https://arxiv.org/abs/2601.22132v1</guid>
  <pubDate>Thu, 29 Jan 2026 18:52:54 +0000</pubDate>
  <description>arXiv cs.LG - Large Language Models (LLMs) deliver state-of-the-art performance on complex reasoning tasks, but their inference costs limit deployment at scale. Small Language Models (SLMs) offer dramatic cost savings yet lag substantially in accuracy. Existing approaches - routing and cascading - treat the LLM as an all-or-nothing resource: either the query bypasses the LLM entirely, or the LLM generates a com</description>
</item>

<item>
  <title>World of Workflows: a Benchmark for Bringing World Models to Enterprise Systems</title>
  <link>https://arxiv.org/abs/2601.22130v1</link>
  <guid>https://arxiv.org/abs/2601.22130v1</guid>
  <pubDate>Thu, 29 Jan 2026 18:51:54 +0000</pubDate>
  <description>arXiv cs.AI - Frontier large language models (LLMs) excel as autonomous agents in many domains, yet they remain untested in complex enterprise systems where hidden workflows create cascading effects across interconnected databases. Existing enterprise benchmarks evaluate surface-level agentic task completion similar to general consumer benchmarks, ignoring true challenges in enterprises, such as limited observa</description>
</item>

<item>
  <title>SWE-Replay: Efficient Test-Time Scaling for Software Engineering Agents</title>
  <link>https://arxiv.org/abs/2601.22129v1</link>
  <guid>https://arxiv.org/abs/2601.22129v1</guid>
  <pubDate>Thu, 29 Jan 2026 18:50:29 +0000</pubDate>
  <description>arXiv cs.AI - Test-time scaling has been widely adopted to enhance the capabilities of Large Language Model (LLM) agents in software engineering (SWE) tasks. However, the standard approach of repeatedly sampling trajectories from scratch is computationally expensive. While recent methods have attempted to mitigate costs using specialized value agents, they can suffer from model miscalibration and fail to genera</description>
</item>

<item>
  <title>SWE-Replay: Efficient Test-Time Scaling for Software Engineering Agents</title>
  <link>https://arxiv.org/abs/2601.22129v1</link>
  <guid>https://arxiv.org/abs/2601.22129v1</guid>
  <pubDate>Thu, 29 Jan 2026 18:50:29 +0000</pubDate>
  <description>arXiv cs.LG - Test-time scaling has been widely adopted to enhance the capabilities of Large Language Model (LLM) agents in software engineering (SWE) tasks. However, the standard approach of repeatedly sampling trajectories from scratch is computationally expensive. While recent methods have attempted to mitigate costs using specialized value agents, they can suffer from model miscalibration and fail to genera</description>
</item>

<item>
  <title>Vision-DeepResearch: Incentivizing DeepResearch Capability in Multimodal Large Language Models</title>
  <link>https://arxiv.org/abs/2601.22060v1</link>
  <guid>https://arxiv.org/abs/2601.22060v1</guid>
  <pubDate>Thu, 29 Jan 2026 17:58:40 +0000</pubDate>
  <description>arXiv cs.AI - Multimodal large language models (MLLMs) have achieved remarkable success across a broad range of vision tasks. However, constrained by the capacity of their internal world knowledge, prior work has proposed augmenting MLLMs by ``reasoning-then-tool-call&apos;&apos; for visual and textual search engines to obtain substantial gains on tasks requiring extensive factual information. However, these approaches t</description>
</item>

<item>
  <title>SIA: Symbolic Interpretability for Anticipatory Deep Reinforcement Learning in Network Control</title>
  <link>https://arxiv.org/abs/2601.22044v1</link>
  <guid>https://arxiv.org/abs/2601.22044v1</guid>
  <pubDate>Thu, 29 Jan 2026 17:46:46 +0000</pubDate>
  <description>arXiv cs.AI - Deep reinforcement learning (DRL) promises adaptive control for future mobile networks but conventional agents remain reactive: they act on past and current measurements and cannot leverage short-term forecasts of exogenous KPIs such as bandwidth. Augmenting agents with predictions can overcome this temporal myopia, yet uptake in networking is scarce because forecast-aware agents act as closed-box</description>
</item>

<item>
  <title>Learning to Communicate Across Modalities: Perceptual Heterogeneity in Multi-Agent Systems</title>
  <link>https://arxiv.org/abs/2601.22041v1</link>
  <guid>https://arxiv.org/abs/2601.22041v1</guid>
  <pubDate>Thu, 29 Jan 2026 17:45:41 +0000</pubDate>
  <description>arXiv cs.AI - Emergent communication offers insight into how agents develop shared structured representations, yet most research assumes homogeneous modalities or aligned representational spaces, overlooking the perceptual heterogeneity of real-world settings. We study a heterogeneous multi-step binary communication game where agents differ in modality and lack perceptual grounding. Despite perceptual misalignm</description>
</item>

<item>
  <title>Learning to Communicate Across Modalities: Perceptual Heterogeneity in Multi-Agent Systems</title>
  <link>https://arxiv.org/abs/2601.22041v1</link>
  <guid>https://arxiv.org/abs/2601.22041v1</guid>
  <pubDate>Thu, 29 Jan 2026 17:45:41 +0000</pubDate>
  <description>arXiv cs.LG - Emergent communication offers insight into how agents develop shared structured representations, yet most research assumes homogeneous modalities or aligned representational spaces, overlooking the perceptual heterogeneity of real-world settings. We study a heterogeneous multi-step binary communication game where agents differ in modality and lack perceptual grounding. Despite perceptual misalignm</description>
</item>

<item>
  <title>Optimizing Agentic Workflows using Meta-tools</title>
  <link>https://arxiv.org/abs/2601.22037v1</link>
  <guid>https://arxiv.org/abs/2601.22037v1</guid>
  <pubDate>Thu, 29 Jan 2026 17:43:08 +0000</pubDate>
  <description>arXiv cs.AI - Agentic AI enables LLM to dynamically reason, plan, and interact with tools to solve complex tasks. However, agentic workflows often require many iterative reasoning steps and tool invocations, leading to significant operational expense, end-to-end latency and failures due to hallucinations. This work introduces Agent Workflow Optimization (AWO), a framework that identifies and optimizes redundant</description>
</item>

<item>
  <title>Deep Researcher with Sequential Plan Reflection and Candidates Crossover (Deep Researcher Reflect Evolve)</title>
  <link>https://arxiv.org/abs/2601.20843v1</link>
  <guid>https://arxiv.org/abs/2601.20843v1</guid>
  <pubDate>Wed, 28 Jan 2026 18:45:39 +0000</pubDate>
  <description>arXiv cs.AI - This paper introduces a novel Deep Researcher architecture designed to generate detailed research reports on complex PhD level topics by addressing the inherent limitations of the Parallel Scaling paradigm. Our system utilizes two key innovations: Sequential Research Plan Refinement via Reflection and a Candidates Crossover algorithm. The sequential refinement process is demonstrated as an efficie</description>
</item>

<item>
  <title>MemCtrl: Using MLLMs as Active Memory Controllers on Embodied Agents</title>
  <link>https://arxiv.org/abs/2601.20831v1</link>
  <guid>https://arxiv.org/abs/2601.20831v1</guid>
  <pubDate>Wed, 28 Jan 2026 18:31:17 +0000</pubDate>
  <description>arXiv cs.AI - Foundation models rely on in-context learning for personalized decision making. The limited size of this context window necessitates memory compression and retrieval systems like RAG. These systems however often treat memory as large offline storage spaces, which is unfavorable for embodied agents that are expected to operate under strict memory and compute constraints, online. In this work, we pr</description>
</item>

<item>
  <title>Demystifying Prediction Powered Inference</title>
  <link>https://arxiv.org/abs/2601.20819v1</link>
  <guid>https://arxiv.org/abs/2601.20819v1</guid>
  <pubDate>Wed, 28 Jan 2026 18:16:02 +0000</pubDate>
  <description>arXiv cs.LG - Machine learning predictions are increasingly used to supplement incomplete or costly-to-measure outcomes in fields such as biomedical research, environmental science, and social science. However, treating predictions as ground truth introduces bias while ignoring them wastes valuable information. Prediction-Powered Inference (PPI) offers a principled framework that leverages predictions from larg</description>
</item>

<item>
  <title>SERA: Soft-Verified Efficient Repository Agents</title>
  <link>https://arxiv.org/abs/2601.20789v1</link>
  <guid>https://arxiv.org/abs/2601.20789v1</guid>
  <pubDate>Wed, 28 Jan 2026 17:27:08 +0000</pubDate>
  <description>arXiv cs.LG - Open-weight coding agents should hold a fundamental advantage over closed-source systems: they can be specialized to private codebases, encoding repository-specific information directly in their weights. Yet the cost and complexity of training has kept this advantage theoretical. We show it is now practical. We present Soft-Verified Efficient Repository Agents (SERA), an efficient method for train</description>
</item>

<item>
  <title>COMET-SG1: Lightweight Autoregressive Regressor for Edge and Embedded AI</title>
  <link>https://arxiv.org/abs/2601.20772v1</link>
  <guid>https://arxiv.org/abs/2601.20772v1</guid>
  <pubDate>Wed, 28 Jan 2026 16:59:56 +0000</pubDate>
  <description>arXiv cs.LG - COMET-SG1 is a lightweight, stability-oriented autoregressive regression model designed for time-series prediction on edge and embedded AI systems. Unlike recurrent neural networks or transformer-based sequence models, COMET-SG1 operates through linear behavior-space encoding, memory-anchored transition estimation, and deterministic state updates. This structure prioritizes bounded long-horizon be</description>
</item>

<item>
  <title>Li-ViP3D++: Query-Gated Deformable Camera-LiDAR Fusion for End-to-End Perception and Trajectory Prediction</title>
  <link>https://arxiv.org/abs/2601.20720v1</link>
  <guid>https://arxiv.org/abs/2601.20720v1</guid>
  <pubDate>Wed, 28 Jan 2026 15:53:32 +0000</pubDate>
  <description>arXiv cs.AI - End-to-end perception and trajectory prediction from raw sensor data is one of the key capabilities for autonomous driving. Modular pipelines restrict information flow and can amplify upstream errors. Recent query-based, fully differentiable perception-and-prediction (PnP) models mitigate these issues, yet the complementarity of cameras and LiDAR in the query-space has not been sufficiently explor</description>
</item>

</channel>
</rss>
