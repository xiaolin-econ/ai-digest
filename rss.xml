<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
<channel>
  <title>AI Research Digest</title>
  <link>https://xiaolin-econ.github.io/ai-digest/</link>
  <description>Curated AI research + releases</description>
  <lastBuildDate>Fri, 23 Jan 2026 06:22:01 +0000</lastBuildDate>
  <atom:link href="https://xiaolin-econ.github.io/ai-digest/rss.xml" rel="self" type="application/rss+xml" xmlns:atom="http://www.w3.org/2005/Atom"/>
  
<item>
  <title>AI Digest — Daily Summary</title>
  <link>https://xiaolin-econ.github.io/ai-digest/rss.xml</link>
  <guid>https://xiaolin-econ.github.io/ai-digest/rss.xml#summary</guid>
  <pubDate>Fri, 23 Jan 2026 06:22:01 +0000</pubDate>
  <description>We present a novel differentiable grid-based representation for efficiently solving differential equations (DEs). Widely used architectures for neural solvers, such as sinusoidal neural networks, are coordinate-based MLPs that are both computationally intensive and slow to train. Although grid-based alternatives for implicit representations (e.g., Instant-NGP and K-Planes) train faster by… Tool-Integrated Reasoning (TIR) empowers large language models (LLMs) to tackle complex tasks by interleaving reasoning steps with external tool interactions. However, existing reinforcement learning methods typically rely on outcome- or trajectory-level rewards, assigning uniform advantages to all steps within a trajectory. This coarse-grained credit assignment fails to distinguish effective……</description>
</item>

<item>
  <title>LLM-in-Sandbox Elicits General Agentic Intelligence</title>
  <link>https://arxiv.org/abs/2601.16206v1</link>
  <guid>https://arxiv.org/abs/2601.16206v1</guid>
  <pubDate>Thu, 22 Jan 2026 18:57:09 +0000</pubDate>
  <description>arXiv cs.AI - We introduce LLM-in-Sandbox, enabling LLMs to explore within a code sandbox (i.e., a virtual computer), to elicit general intelligence in non-code domains. We first demonstrate that strong LLMs, without additional training, exhibit generalization capabilities to leverage the code sandbox for non-code tasks. For example, LLMs spontaneously access external resources to acquire new knowledge, leverag</description>
</item>

<item>
  <title>Delayed Assignments in Online Non-Centroid Clustering with Stochastic Arrivals</title>
  <link>https://arxiv.org/abs/2601.16091v1</link>
  <guid>https://arxiv.org/abs/2601.16091v1</guid>
  <pubDate>Thu, 22 Jan 2026 16:42:05 +0000</pubDate>
  <description>arXiv cs.AI - Clustering is a fundamental problem, aiming to partition a set of elements, like agents or data points, into clusters such that elements in the same cluster are closer to each other than to those in other clusters. In this paper, we present a new framework for studying online non-centroid clustering with delays, where elements, that arrive one at a time as points in a finite metric space, should b</description>
</item>

<item>
  <title>Delayed Assignments in Online Non-Centroid Clustering with Stochastic Arrivals</title>
  <link>https://arxiv.org/abs/2601.16091v1</link>
  <guid>https://arxiv.org/abs/2601.16091v1</guid>
  <pubDate>Thu, 22 Jan 2026 16:42:05 +0000</pubDate>
  <description>arXiv cs.LG - Clustering is a fundamental problem, aiming to partition a set of elements, like agents or data points, into clusters such that elements in the same cluster are closer to each other than to those in other clusters. In this paper, we present a new framework for studying online non-centroid clustering with delays, where elements, that arrive one at a time as points in a finite metric space, should b</description>
</item>

<item>
  <title>Controlling Long-Horizon Behavior in Language Model Agents with Explicit State Dynamics</title>
  <link>https://arxiv.org/abs/2601.16087v1</link>
  <guid>https://arxiv.org/abs/2601.16087v1</guid>
  <pubDate>Thu, 22 Jan 2026 16:34:05 +0000</pubDate>
  <description>arXiv cs.AI - Large language model (LLM) agents often exhibit abrupt shifts in tone and persona during extended interaction, reflecting the absence of explicit temporal structure governing agent-level state. While prior work emphasizes turn-local sentiment or static emotion classification, the role of explicit affective dynamics in shaping long-horizon agent behavior remains underexplored. This work investigate</description>
</item>

<item>
  <title>AgriPINN: A Process-Informed Neural Network for Interpretable and Scalable Crop Biomass Prediction Under Water Stress</title>
  <link>https://arxiv.org/abs/2601.16045v1</link>
  <guid>https://arxiv.org/abs/2601.16045v1</guid>
  <pubDate>Thu, 22 Jan 2026 15:20:00 +0000</pubDate>
  <description>arXiv cs.AI - Accurate prediction of crop above-ground biomass (AGB) under water stress is critical for monitoring crop productivity, guiding irrigation, and supporting climate-resilient agriculture. Data-driven models scale well but often lack interpretability and degrade under distribution shift, whereas process-based crop models (e.g. DSSAT, APSIM, LINTUL5) require extensive calibration and are difficult to </description>
</item>

<item>
  <title>RayRoPE: Projective Ray Positional Encoding for Multi-view Attention</title>
  <link>https://arxiv.org/abs/2601.15275v1</link>
  <guid>https://arxiv.org/abs/2601.15275v1</guid>
  <pubDate>Wed, 21 Jan 2026 18:55:51 +0000</pubDate>
  <description>arXiv cs.LG - We study positional encodings for multi-view transformers that process tokens from a set of posed input images, and seek a mechanism that encodes patches uniquely, allows SE(3)-invariant attention with multi-frequency similarity, and can be adaptive to the geometry of the underlying scene. We find that prior (absolute or relative) encoding schemes for multi-view attention do not meet the above des</description>
</item>

<item>
  <title>Evaluation of Large Language Models in Legal Applications: Challenges, Methods, and Future Directions</title>
  <link>https://arxiv.org/abs/2601.15267v1</link>
  <guid>https://arxiv.org/abs/2601.15267v1</guid>
  <pubDate>Wed, 21 Jan 2026 18:51:37 +0000</pubDate>
  <description>arXiv cs.AI - Large language models (LLMs) are being increasingly integrated into legal applications, including judicial decision support, legal practice assistance, and public-facing legal services. While LLMs show strong potential in handling legal knowledge and tasks, their deployment in real-world legal settings raises critical concerns beyond surface-level accuracy, involving the soundness of legal reasoni</description>
</item>

<item>
  <title>Deaf and Hard of Hearing Access to Intelligent Personal Assistants: Comparison of Voice-Based Options with an LLM-Powered Touch Interface</title>
  <link>https://arxiv.org/abs/2601.15209v1</link>
  <guid>https://arxiv.org/abs/2601.15209v1</guid>
  <pubDate>Wed, 21 Jan 2026 17:33:00 +0000</pubDate>
  <description>arXiv cs.AI - We investigate intelligent personal assistants (IPAs) accessibility for deaf and hard of hearing (DHH) people who can use their voice in everyday communication. The inability of IPAs to understand diverse accents including deaf speech renders them largely inaccessible to non-signing and speaking DHH individuals. Using an Echo Show, we compare the usability of natural language input via spoken Engl</description>
</item>

<item>
  <title>Where Do AI Coding Agents Fail? An Empirical Study of Failed Agentic Pull Requests in GitHub</title>
  <link>https://arxiv.org/abs/2601.15195v1</link>
  <guid>https://arxiv.org/abs/2601.15195v1</guid>
  <pubDate>Wed, 21 Jan 2026 17:12:46 +0000</pubDate>
  <description>arXiv cs.AI - AI coding agents are now submitting pull requests (PRs) to software projects, acting not just as assistants but as autonomous contributors. As these agentic contributions are rapidly increasing across real repositories, little is known about how they behave in practice and why many of them fail to be merged. In this paper, we conduct a large-scale study of 33k agent-authored PRs made by five codin</description>
</item>

<item>
  <title>The Flexibility Trap: Why Arbitrary Order Limits Reasoning Potential in Diffusion Language Models</title>
  <link>https://arxiv.org/abs/2601.15165v1</link>
  <guid>https://arxiv.org/abs/2601.15165v1</guid>
  <pubDate>Wed, 21 Jan 2026 16:41:58 +0000</pubDate>
  <description>arXiv cs.AI - Diffusion Large Language Models (dLLMs) break the rigid left-to-right constraint of traditional LLMs, enabling token generation in arbitrary orders. Intuitively, this flexibility implies a solution space that strictly supersets the fixed autoregressive trajectory, theoretically unlocking superior reasoning potential for general tasks like mathematics and coding. Consequently, numerous works have l</description>
</item>

<item>
  <title>The Flexibility Trap: Why Arbitrary Order Limits Reasoning Potential in Diffusion Language Models</title>
  <link>https://arxiv.org/abs/2601.15165v1</link>
  <guid>https://arxiv.org/abs/2601.15165v1</guid>
  <pubDate>Wed, 21 Jan 2026 16:41:58 +0000</pubDate>
  <description>arXiv cs.LG - Diffusion Large Language Models (dLLMs) break the rigid left-to-right constraint of traditional LLMs, enabling token generation in arbitrary orders. Intuitively, this flexibility implies a solution space that strictly supersets the fixed autoregressive trajectory, theoretically unlocking superior reasoning potential for general tasks like mathematics and coding. Consequently, numerous works have l</description>
</item>

<item>
  <title>Automated Rubrics for Reliable Evaluation of Medical Dialogue Systems</title>
  <link>https://arxiv.org/abs/2601.15161v1</link>
  <guid>https://arxiv.org/abs/2601.15161v1</guid>
  <pubDate>Wed, 21 Jan 2026 16:40:41 +0000</pubDate>
  <description>arXiv cs.AI - Large Language Models (LLMs) are increasingly used for clinical decision support, where hallucinations and unsafe suggestions may pose direct risks to patient safety. These risks are particularly challenging as they often manifest as subtle clinical errors that evade detection by generic metrics, while expert-authored fine-grained rubrics remain costly to construct and difficult to scale. In this </description>
</item>

<item>
  <title>How to Build AI Agents by Augmenting LLMs with Codified Human Expert Domain Knowledge? A Software Engineering Framework</title>
  <link>https://arxiv.org/abs/2601.15153v1</link>
  <guid>https://arxiv.org/abs/2601.15153v1</guid>
  <pubDate>Wed, 21 Jan 2026 16:23:22 +0000</pubDate>
  <description>arXiv cs.AI - Critical domain knowledge typically resides with few experts, creating organizational bottlenecks in scalability and decision-making. Non-experts struggle to create effective visualizations, leading to suboptimal insights and diverting expert time. This paper investigates how to capture and embed human domain knowledge into AI agent systems through an industrial case study. We propose a software e</description>
</item>

<item>
  <title>CLEANER: Self-Purified Trajectories Boost Agentic Reinforcement Learning</title>
  <link>https://arxiv.org/abs/2601.15141v1</link>
  <guid>https://arxiv.org/abs/2601.15141v1</guid>
  <pubDate>Wed, 21 Jan 2026 16:14:30 +0000</pubDate>
  <description>arXiv cs.LG - Agentic Reinforcement Learning (RL) has empowered Large Language Models (LLMs) to utilize tools like Python interpreters for complex problem-solving. However, for parameter-constrained models (e.g., 4B--7B), the exploration phase is often plagued by frequent execution failures, creating noisy trajectories that hinder policy optimization. Under standard outcome-based reward settings, this noise lea</description>
</item>

<item>
  <title>Emerging from Ground: Addressing Intent Deviation in Tool-Using Agents via Deriving Real Calls into Virtual Trajectories</title>
  <link>https://arxiv.org/abs/2601.15120v1</link>
  <guid>https://arxiv.org/abs/2601.15120v1</guid>
  <pubDate>Wed, 21 Jan 2026 15:58:54 +0000</pubDate>
  <description>arXiv cs.AI - LLMs have advanced tool-using agents for real-world applications, yet they often lead to unexpected behaviors or results. Beyond obvious failures, the subtle issue of &quot;intent deviation&quot; severely hinders reliable evaluation and performance improvement. Existing post-training methods generally leverage either real system samples or virtual data simulated by LLMs. However, the former is costly due to</description>
</item>

<item>
  <title>Memory Retention Is Not Enough to Master Memory Tasks in Reinforcement Learning</title>
  <link>https://arxiv.org/abs/2601.15086v1</link>
  <guid>https://arxiv.org/abs/2601.15086v1</guid>
  <pubDate>Wed, 21 Jan 2026 15:27:23 +0000</pubDate>
  <description>arXiv cs.LG - Effective decision-making in the real world depends on memory that is both stable and adaptive: environments change over time, and agents must retain relevant information over long horizons while also updating or overwriting outdated content when circumstances shift. Existing Reinforcement Learning (RL) benchmarks and memory-augmented agents focus primarily on retention, leaving the equally critic</description>
</item>

<item>
  <title>Multi-Agent Constraint Factorization Reveals Latent Invariant Solution Structure</title>
  <link>https://arxiv.org/abs/2601.15077v1</link>
  <guid>https://arxiv.org/abs/2601.15077v1</guid>
  <pubDate>Wed, 21 Jan 2026 15:23:04 +0000</pubDate>
  <description>arXiv cs.LG - Multi-agent systems (MAS) composed of large language models often exhibit improved problem-solving performance despite operating on identical information. In this work, we provide a formal explanation for this phenomenon grounded in operator theory and constrained optimization. We model each agent as enforcing a distinct family of validity constraints on a shared solution state, and show that a MA</description>
</item>

<item>
  <title>SmartOracle -- An Agentic Approach to Mitigate Noise in Differential Oracles</title>
  <link>https://arxiv.org/abs/2601.15074v1</link>
  <guid>https://arxiv.org/abs/2601.15074v1</guid>
  <pubDate>Wed, 21 Jan 2026 15:20:53 +0000</pubDate>
  <description>arXiv cs.LG - Differential fuzzers detect bugs by executing identical inputs across distinct implementations of the same specification, such as JavaScript interpreters. Validating the outputs requires an oracle and for differential testing of JavaScript, these are constructed manually, making them expensive, time-consuming, and prone to false positives. Worse, when the specification evolves, this manual effort </description>
</item>

<item>
  <title>APEX-Agents</title>
  <link>https://arxiv.org/abs/2601.14242v1</link>
  <guid>https://arxiv.org/abs/2601.14242v1</guid>
  <pubDate>Tue, 20 Jan 2026 18:53:44 +0000</pubDate>
  <description>arXiv cs.AI - We introduce the AI Productivity Index for Agents (APEX-Agents), a benchmark for assessing whether AI agents can execute long-horizon, cross-application tasks created by investment banking analysts, management consultants, and corporate lawyers. APEX-Agents requires agents to navigate realistic work environments with files and tools. We test eight agents for the leaderboard using Pass@1. Gemini 3 </description>
</item>

<item>
  <title>APEX-Agents</title>
  <link>https://arxiv.org/abs/2601.14242v1</link>
  <guid>https://arxiv.org/abs/2601.14242v1</guid>
  <pubDate>Tue, 20 Jan 2026 18:53:44 +0000</pubDate>
  <description>arXiv cs.LG - We introduce the AI Productivity Index for Agents (APEX-Agents), a benchmark for assessing whether AI agents can execute long-horizon, cross-application tasks created by investment banking analysts, management consultants, and corporate lawyers. APEX-Agents requires agents to navigate realistic work environments with files and tools. We test eight agents for the leaderboard using Pass@1. Gemini 3 </description>
</item>

<item>
  <title>Spatiotemporal Wildfire Prediction and Reinforcement Learning for Helitack Suppression</title>
  <link>https://arxiv.org/abs/2601.14238v1</link>
  <guid>https://arxiv.org/abs/2601.14238v1</guid>
  <pubDate>Tue, 20 Jan 2026 18:50:12 +0000</pubDate>
  <description>arXiv cs.LG - Wildfires are growing in frequency and intensity, devastating ecosystems and communities while causing billions of dollars in suppression costs and economic damage annually in the U.S. Traditional wildfire management is mostly reactive, addressing fires only after they are detected. We introduce \textit{FireCastRL}, a proactive artificial intelligence (AI) framework that combines wildfire forecast</description>
</item>

<item>
  <title>Opportunities in AI/ML for the Rubin LSST Dark Energy Science Collaboration</title>
  <link>https://arxiv.org/abs/2601.14235v1</link>
  <guid>https://arxiv.org/abs/2601.14235v1</guid>
  <pubDate>Tue, 20 Jan 2026 18:46:42 +0000</pubDate>
  <description>arXiv cs.AI - The Vera C. Rubin Observatory&apos;s Legacy Survey of Space and Time (LSST) will produce unprecedented volumes of heterogeneous astronomical data (images, catalogs, and alerts) that challenge traditional analysis pipelines. The LSST Dark Energy Science Collaboration (DESC) aims to derive robust constraints on dark energy and dark matter from these data, requiring methods that are statistically powerful</description>
</item>

<item>
  <title>Opportunities in AI/ML for the Rubin LSST Dark Energy Science Collaboration</title>
  <link>https://arxiv.org/abs/2601.14235v1</link>
  <guid>https://arxiv.org/abs/2601.14235v1</guid>
  <pubDate>Tue, 20 Jan 2026 18:46:42 +0000</pubDate>
  <description>arXiv cs.LG - The Vera C. Rubin Observatory&apos;s Legacy Survey of Space and Time (LSST) will produce unprecedented volumes of heterogeneous astronomical data (images, catalogs, and alerts) that challenge traditional analysis pipelines. The LSST Dark Energy Science Collaboration (DESC) aims to derive robust constraints on dark energy and dark matter from these data, requiring methods that are statistically powerful</description>
</item>

<item>
  <title>KAGE-Bench: Fast Known-Axis Visual Generalization Evaluation for Reinforcement Learning</title>
  <link>https://arxiv.org/abs/2601.14232v1</link>
  <guid>https://arxiv.org/abs/2601.14232v1</guid>
  <pubDate>Tue, 20 Jan 2026 18:44:28 +0000</pubDate>
  <description>arXiv cs.AI - Pixel-based reinforcement learning agents often fail under purely visual distribution shift even when latent dynamics and rewards are unchanged, but existing benchmarks entangle multiple sources of shift and hinder systematic analysis. We introduce KAGE-Env, a JAX-native 2D platformer that factorizes the observation process into independently controllable visual axes while keeping the underlying c</description>
</item>

<item>
  <title>KAGE-Bench: Fast Known-Axis Visual Generalization Evaluation for Reinforcement Learning</title>
  <link>https://arxiv.org/abs/2601.14232v1</link>
  <guid>https://arxiv.org/abs/2601.14232v1</guid>
  <pubDate>Tue, 20 Jan 2026 18:44:28 +0000</pubDate>
  <description>arXiv cs.LG - Pixel-based reinforcement learning agents often fail under purely visual distribution shift even when latent dynamics and rewards are unchanged, but existing benchmarks entangle multiple sources of shift and hinder systematic analysis. We introduce KAGE-Env, a JAX-native 2D platformer that factorizes the observation process into independently controllable visual axes while keeping the underlying c</description>
</item>

<item>
  <title>MASCOT: Towards Multi-Agent Socio-Collaborative Companion Systems</title>
  <link>https://arxiv.org/abs/2601.14230v1</link>
  <guid>https://arxiv.org/abs/2601.14230v1</guid>
  <pubDate>Tue, 20 Jan 2026 18:44:04 +0000</pubDate>
  <description>arXiv cs.AI - Multi-agent systems (MAS) have recently emerged as promising socio-collaborative companions for emotional and cognitive support. However, these systems frequently suffer from persona collapse--where agents revert to generic, homogenized assistant behaviors--and social sycophancy, which produces redundant, non-constructive dialogue. We propose MASCOT, a generalizable framework for multi-perspective</description>
</item>

<item>
  <title>Attention-Based Offline Reinforcement Learning and Clustering for Interpretable Sepsis Treatment</title>
  <link>https://arxiv.org/abs/2601.14228v1</link>
  <guid>https://arxiv.org/abs/2601.14228v1</guid>
  <pubDate>Tue, 20 Jan 2026 18:41:44 +0000</pubDate>
  <description>arXiv cs.LG - Sepsis remains one of the leading causes of mortality in intensive care units, where timely and accurate treatment decisions can significantly impact patient outcomes. In this work, we propose an interpretable decision support framework. Our system integrates four core components: (1) a clustering-based stratification module that categorizes patients into low, intermediate, and high-risk groups up</description>
</item>

<item>
  <title>Toward Efficient Agents: Memory, Tool learning, and Planning</title>
  <link>https://arxiv.org/abs/2601.14192v1</link>
  <guid>https://arxiv.org/abs/2601.14192v1</guid>
  <pubDate>Tue, 20 Jan 2026 17:51:56 +0000</pubDate>
  <description>arXiv cs.AI - Recent years have witnessed increasing interest in extending large language models into agentic systems. While the effectiveness of agents has continued to improve, efficiency, which is crucial for real-world deployment, has often been overlooked. This paper therefore investigates efficiency from three core components of agents: memory, tool learning, and planning, considering costs such as latenc</description>
</item>

<item>
  <title>Paper2Rebuttal: A Multi-Agent Framework for Transparent Author Response Assistance</title>
  <link>https://arxiv.org/abs/2601.14171v1</link>
  <guid>https://arxiv.org/abs/2601.14171v1</guid>
  <pubDate>Tue, 20 Jan 2026 17:23:51 +0000</pubDate>
  <description>arXiv cs.AI - Writing effective rebuttals is a high-stakes task that demands more than linguistic fluency, as it requires precise alignment between reviewer intent and manuscript details. Current solutions typically treat this as a direct-to-text generation problem, suffering from hallucination, overlooked critiques, and a lack of verifiable grounding. To address these limitations, we introduce $\textbf{Rebutta</description>
</item>

<item>
  <title>Remapping and navigation of an embedding space via error minimization: a fundamental organizational principle of cognition in natural and artificial systems</title>
  <link>https://arxiv.org/abs/2601.14096v1</link>
  <guid>https://arxiv.org/abs/2601.14096v1</guid>
  <pubDate>Tue, 20 Jan 2026 15:57:36 +0000</pubDate>
  <description>arXiv cs.AI - The emerging field of diverse intelligence seeks an integrated view of problem-solving in agents of very different provenance, composition, and substrates. From subcellular chemical networks to swarms of organisms, and across evolved, engineered, and chimeric systems, it is hypothesized that scale-invariant principles of decision-making can be discovered. We propose that cognition in both natural </description>
</item>

<item>
  <title>Zero-shot adaptable task planning for autonomous construction robots: a comparative study of lightweight single and multi-AI agent systems</title>
  <link>https://arxiv.org/abs/2601.14091v1</link>
  <guid>https://arxiv.org/abs/2601.14091v1</guid>
  <pubDate>Tue, 20 Jan 2026 15:54:33 +0000</pubDate>
  <description>arXiv cs.AI - Robots are expected to play a major role in the future construction industry but face challenges due to high costs and difficulty adapting to dynamic tasks. This study explores the potential of foundation models to enhance the adaptability and generalizability of task planning in construction robots. Four models are proposed and implemented using lightweight, open-source large language models (LLM</description>
</item>

<item>
  <title>LLMOrbit: A Circular Taxonomy of Large Language Models -From Scaling Walls to Agentic AI Systems</title>
  <link>https://arxiv.org/abs/2601.14053v1</link>
  <guid>https://arxiv.org/abs/2601.14053v1</guid>
  <pubDate>Tue, 20 Jan 2026 15:06:19 +0000</pubDate>
  <description>arXiv cs.LG - The field of artificial intelligence has undergone a revolution from foundational Transformer architectures to reasoning-capable systems approaching human-level performance. We present LLMOrbit, a comprehensive circular taxonomy navigating the landscape of large language models spanning 2019-2025. This survey examines over 50 models across 15 organizations through eight interconnected orbital dime</description>
</item>

<item>
  <title>The Poisoned Apple Effect: Strategic Manipulation of Mediated Markets via Technology Expansion of AI Agents</title>
  <link>https://arxiv.org/abs/2601.11496v1</link>
  <guid>https://arxiv.org/abs/2601.11496v1</guid>
  <pubDate>Fri, 16 Jan 2026 18:18:03 +0000</pubDate>
  <description>arXiv cs.AI - The integration of AI agents into economic markets fundamentally alters the landscape of strategic interaction. We investigate the economic implications of expanding the set of available technologies in three canonical game-theoretic settings: bargaining (resource division), negotiation (asymmetric information trade), and persuasion (strategic information transmission). We find that simply increas</description>
</item>

<item>
  <title>BoxMind: Closed-loop AI strategy optimization for elite boxing validated in the 2024 Olympics</title>
  <link>https://arxiv.org/abs/2601.11492v1</link>
  <guid>https://arxiv.org/abs/2601.11492v1</guid>
  <pubDate>Fri, 16 Jan 2026 18:14:46 +0000</pubDate>
  <description>arXiv cs.AI - Competitive sports require sophisticated tactical analysis, yet combat disciplines like boxing remain underdeveloped in AI-driven analytics due to the complexity of action dynamics and the lack of structured tactical representations. To address this, we present BoxMind, a closed-loop AI expert system validated in elite boxing competition. By defining atomic punch events with precise temporal bound</description>
</item>

<item>
  <title>Health Facility Location in Ethiopia: Leveraging LLMs to Integrate Expert Knowledge into Algorithmic Planning</title>
  <link>https://arxiv.org/abs/2601.11479v1</link>
  <guid>https://arxiv.org/abs/2601.11479v1</guid>
  <pubDate>Fri, 16 Jan 2026 18:02:09 +0000</pubDate>
  <description>arXiv cs.AI - Ethiopia&apos;s Ministry of Health is upgrading health posts to improve access to essential services, particularly in rural areas. Limited resources, however, require careful prioritization of which facilities to upgrade to maximize population coverage while accounting for diverse expert and stakeholder preferences. In collaboration with the Ethiopian Public Health Institute and Ministry of Health, we </description>
</item>

<item>
  <title>Low-Rank Key Value Attention</title>
  <link>https://arxiv.org/abs/2601.11471v1</link>
  <guid>https://arxiv.org/abs/2601.11471v1</guid>
  <pubDate>Fri, 16 Jan 2026 17:56:40 +0000</pubDate>
  <description>arXiv cs.LG - Transformer pretraining is increasingly constrained by memory and compute requirements, with the key-value (KV) cache emerging as a dominant bottleneck during training and autoregressive decoding. We propose \textit{low-rank KV adaptation} (LRKV), a simple modification of multi-head attention that reduces KV cache memory by exploiting redundancy across attention heads while preserving full token-l</description>
</item>

<item>
  <title>Inter-patient ECG Arrhythmia Classification with LGNs and LUTNs</title>
  <link>https://arxiv.org/abs/2601.11433v1</link>
  <guid>https://arxiv.org/abs/2601.11433v1</guid>
  <pubDate>Fri, 16 Jan 2026 16:55:36 +0000</pubDate>
  <description>arXiv cs.LG - Deep Differentiable Logic Gate Networks (LGNs) and Lookup Table Networks (LUTNs) are demonstrated to be suitable for the automatic classification of electrocardiograms (ECGs) using the inter-patient paradigm. The methods are benchmarked using the MIT-BIH arrhythmia data set, achieving up to 94.28% accuracy and a $jκ$ index of 0.683 on a four-class classification problem. Our models use between 2.8</description>
</item>

<item>
  <title>The Great March 100: 100 Detail-oriented Tasks for Evaluating Embodied AI Agents</title>
  <link>https://arxiv.org/abs/2601.11421v1</link>
  <guid>https://arxiv.org/abs/2601.11421v1</guid>
  <pubDate>Fri, 16 Jan 2026 16:42:05 +0000</pubDate>
  <description>arXiv cs.AI - Recently, with the rapid development of robot learning and imitation learning, numerous datasets and methods have emerged. However, these datasets and their task designs often lack systematic consideration and principles. This raises important questions: Do the current datasets and task designs truly advance the capabilities of robotic agents? Do evaluations on a few common tasks accurately reflec</description>
</item>

<item>
  <title>Factored Value Functions for Graph-Based Multi-Agent Reinforcement Learning</title>
  <link>https://arxiv.org/abs/2601.11401v1</link>
  <guid>https://arxiv.org/abs/2601.11401v1</guid>
  <pubDate>Fri, 16 Jan 2026 16:11:50 +0000</pubDate>
  <description>arXiv cs.LG - Credit assignment is a core challenge in multi-agent reinforcement learning (MARL), especially in large-scale systems with structured, local interactions. Graph-based Markov decision processes (GMDPs) capture such settings via an influence graph, but standard critics are poorly aligned with this structure: global value functions provide weak per-agent learning signals, while existing local constru</description>
</item>

<item>
  <title>Evaluating LLM Behavior in Hiring: Implicit Weights, Fairness Across Groups, and Alignment with Human Preferences</title>
  <link>https://arxiv.org/abs/2601.11379v1</link>
  <guid>https://arxiv.org/abs/2601.11379v1</guid>
  <pubDate>Fri, 16 Jan 2026 15:38:03 +0000</pubDate>
  <description>arXiv cs.AI - General-purpose Large Language Models (LLMs) show significant potential in recruitment applications, where decisions require reasoning over unstructured text, balancing multiple criteria, and inferring fit and competence from indirect productivity signals. Yet, it is still uncertain how LLMs assign importance to each attribute and whether such assignments are in line with economic principles, recr</description>
</item>

<item>
  <title>Institutional AI: Governing LLM Collusion in Multi-Agent Cournot Markets via Public Governance Graphs</title>
  <link>https://arxiv.org/abs/2601.11369v1</link>
  <guid>https://arxiv.org/abs/2601.11369v1</guid>
  <pubDate>Fri, 16 Jan 2026 15:26:56 +0000</pubDate>
  <description>arXiv cs.AI - Multi-agent LLM ensembles can converge on coordinated, socially harmful equilibria. This paper advances an experimental framework for evaluating Institutional AI, our system-level approach to AI alignment that reframes alignment from preference engineering in agent-space to mechanism design in institution-space. Central to this approach is the governance graph, a public, immutable manifest that de</description>
</item>

<item>
  <title>AstroReason-Bench: Evaluating Unified Agentic Planning across Heterogeneous Space Planning Problems</title>
  <link>https://arxiv.org/abs/2601.11354v1</link>
  <guid>https://arxiv.org/abs/2601.11354v1</guid>
  <pubDate>Fri, 16 Jan 2026 15:02:41 +0000</pubDate>
  <description>arXiv cs.AI - Recent advances in agentic Large Language Models (LLMs) have positioned them as generalist planners capable of reasoning and acting across diverse tasks. However, existing agent benchmarks largely focus on symbolic or weakly grounded environments, leaving their performance in physics-constrained real-world domains underexplored. We introduce AstroReason-Bench, a comprehensive benchmark for evaluat</description>
</item>

<item>
  <title>Offline Reinforcement-Learning-Based Power Control for Application-Agnostic Energy Efficiency</title>
  <link>https://arxiv.org/abs/2601.11352v1</link>
  <guid>https://arxiv.org/abs/2601.11352v1</guid>
  <pubDate>Fri, 16 Jan 2026 15:00:17 +0000</pubDate>
  <description>arXiv cs.LG - Energy efficiency has become an integral aspect of modern computing infrastructure design, impacting the performance, cost, scalability, and durability of production systems. The incorporation of power actuation and sensing capabilities in CPU designs is indicative of this, enabling the deployment of system software that can actively monitor and adjust energy consumption and performance at runtime</description>
</item>

<item>
  <title>FEATHer: Fourier-Efficient Adaptive Temporal Hierarchy Forecaster for Time-Series Forecasting</title>
  <link>https://arxiv.org/abs/2601.11350v1</link>
  <guid>https://arxiv.org/abs/2601.11350v1</guid>
  <pubDate>Fri, 16 Jan 2026 14:57:41 +0000</pubDate>
  <description>arXiv cs.AI - Time-series forecasting is fundamental in industrial domains like manufacturing and smart factories. As systems evolve toward automation, models must operate on edge devices (e.g., PLCs, microcontrollers) with strict constraints on latency and memory, limiting parameters to a few thousand. Conventional deep architectures are often impractical here. We propose the Fourier-Efficient Adaptive Tempora</description>
</item>

<item>
  <title>How Much Would a Clinician Edit This Draft? Evaluating LLM Alignment for Patient Message Response Drafting</title>
  <link>https://arxiv.org/abs/2601.11344v1</link>
  <guid>https://arxiv.org/abs/2601.11344v1</guid>
  <pubDate>Fri, 16 Jan 2026 14:48:00 +0000</pubDate>
  <description>arXiv cs.AI - Large language models (LLMs) show promise in drafting responses to patient portal messages, yet their integration into clinical workflows raises various concerns, including whether they would actually save clinicians time and effort in their portal workload. We investigate LLM alignment with individual clinicians through a comprehensive evaluation of the patient message response drafting task. We </description>
</item>

<item>
  <title>DInf-Grid: A Neural Differential Equation Solver with Differentiable Feature Grids</title>
  <link>https://arxiv.org/abs/2601.10715v1</link>
  <guid>https://arxiv.org/abs/2601.10715v1</guid>
  <pubDate>Thu, 15 Jan 2026 18:59:57 +0000</pubDate>
  <description>arXiv cs.LG - We present a novel differentiable grid-based representation for efficiently solving differential equations (DEs). Widely used architectures for neural solvers, such as sinusoidal neural networks, are coordinate-based MLPs that are both computationally intensive and slow to train. Although grid-based alternatives for implicit representations (e.g., Instant-NGP and K-Planes) train faster by exploiti

AI summary: We present a novel differentiable grid-based representation for efficiently solving differential equations (DEs). Widely used architectures for neural solvers, such as sinusoidal neural networks, are coordinate-based MLPs that are both computationally intensive and slow to train. Although grid-based alternatives for implicit representations (e.g., Instant-NGP and K-Planes) train faster by…</description>
</item>

<item>
  <title>MatchTIR: Fine-Grained Supervision for Tool-Integrated Reasoning via Bipartite Matching</title>
  <link>https://arxiv.org/abs/2601.10712v1</link>
  <guid>https://arxiv.org/abs/2601.10712v1</guid>
  <pubDate>Thu, 15 Jan 2026 18:59:23 +0000</pubDate>
  <description>arXiv cs.AI - Tool-Integrated Reasoning (TIR) empowers large language models (LLMs) to tackle complex tasks by interleaving reasoning steps with external tool interactions. However, existing reinforcement learning methods typically rely on outcome- or trajectory-level rewards, assigning uniform advantages to all steps within a trajectory. This coarse-grained credit assignment fails to distinguish effective tool

AI summary: Tool-Integrated Reasoning (TIR) empowers large language models (LLMs) to tackle complex tasks by interleaving reasoning steps with external tool interactions. However, existing reinforcement learning methods typically rely on outcome- or trajectory-level rewards, assigning uniform advantages to all steps within a trajectory. This coarse-grained credit assignment fails to distinguish effective…</description>
</item>

<item>
  <title>High-accuracy and dimension-free sampling with diffusions</title>
  <link>https://arxiv.org/abs/2601.10708v1</link>
  <guid>https://arxiv.org/abs/2601.10708v1</guid>
  <pubDate>Thu, 15 Jan 2026 18:58:50 +0000</pubDate>
  <description>arXiv cs.LG - Diffusion models have shown remarkable empirical success in sampling from rich multi-modal distributions. Their inference relies on numerically solving a certain differential equation. This differential equation cannot be solved in closed form, and its resolution via discretization typically requires many small iterations to produce \emph{high-quality} samples.
  More precisely, prior works have s

AI summary: Diffusion models have shown remarkable empirical success in sampling from rich multi-modal distributions. Their inference relies on numerically solving a certain differential equation. This differential equation cannot be solved in closed form, and its resolution via discretization typically requires many small iterations to produce \emph{high-quality} samples. More precisely, prior works have…</description>
</item>

<item>
  <title>See Less, Drive Better: Generalizable End-to-End Autonomous Driving via Foundation Models Stochastic Patch Selection</title>
  <link>https://arxiv.org/abs/2601.10707v1</link>
  <guid>https://arxiv.org/abs/2601.10707v1</guid>
  <pubDate>Thu, 15 Jan 2026 18:58:33 +0000</pubDate>
  <description>arXiv cs.LG - Recent advances in end-to-end autonomous driving show that policies trained on patch-aligned features extracted from foundation models generalize better to Out-of-Distribution (OOD). We hypothesize that due to the self-attention mechanism, each patch feature implicitly embeds/contains information from all other patches, represented in a different way and intensity, making these descriptors highly 

AI summary: Recent advances in end-to-end autonomous driving show that policies trained on patch-aligned features extracted from foundation models generalize better to Out-of-Distribution (OOD). We hypothesize that due to the self-attention mechanism, each patch feature implicitly embeds/contains information from all other patches, represented in a different way and intensity, making these descriptors…</description>
</item>

<item>
  <title>Distributed Perceptron under Bounded Staleness, Partial Participation, and Noisy Communication</title>
  <link>https://arxiv.org/abs/2601.10705v1</link>
  <guid>https://arxiv.org/abs/2601.10705v1</guid>
  <pubDate>Thu, 15 Jan 2026 18:56:54 +0000</pubDate>
  <description>arXiv cs.LG - We study a semi-asynchronous client-server perceptron trained via iterative parameter mixing (IPM-style averaging): clients run local perceptron updates and a server forms a global model by aggregating the updates that arrive in each communication round. The setting captures three system effects in federated and distributed deployments: (i) stale updates due to delayed model delivery and delayed a

AI summary: We study a semi-asynchronous client-server perceptron trained via iterative parameter mixing (IPM-style averaging): clients run local perceptron updates and a server forms a global model by aggregating the updates that arrive in each communication round. The setting captures three system effects in federated and distributed deployments: (i) stale updates due to delayed model delivery and delayed…</description>
</item>

</channel>
</rss>
