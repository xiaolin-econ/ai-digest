<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
<channel>
  <title>AI Research Digest</title>
  <link>https://xiaolin-econ.github.io/ai-digest/</link>
  <description>Curated AI research + releases</description>
  <lastBuildDate>Thu, 05 Feb 2026 06:45:52 +0000</lastBuildDate>
  <atom:link href="https://xiaolin-econ.github.io/ai-digest/rss.xml" rel="self" type="application/rss+xml" xmlns:atom="http://www.w3.org/2005/Atom"/>
  
<item>
  <title>AI Digest — Daily Summary</title>
  <link>https://xiaolin-econ.github.io/ai-digest/rss.xml</link>
  <guid>https://xiaolin-econ.github.io/ai-digest/rss.xml#summary</guid>
  <pubDate>Thu, 05 Feb 2026 06:45:52 +0000</pubDate>
  <description>Continual reinforcement learning (CRL) requires agents to learn from a sequence of tasks without forgetting previously acquired policies. In this work, we introduce a novel benchmark suite for CRL based on realistically simulated robots in the Gazebo simulator. Our Continual Robotic Simulation Suite (CRoSS) benchmarks rely on two robotic platforms: a two-wheeled differential-drive robot with lidar, camera and bumper sensor, and a robotic arm with seven joints. The former represent an agent in line-following and object-pushing scenarios, where variation of visual and structural parameters yields a large number of distinct tasks, whereas the latter is used in two goal-reaching scenarios with high-level cartesian hand position control (modeled after the Continual World benchmark), and…</description>
</item>

<item>
  <title>CRoSS: A Continual Robotic Simulation Suite for Scalable Reinforcement Learning with High Task Diversity and Realistic Physics Simulation</title>
  <link>https://arxiv.org/abs/2602.04868v1</link>
  <guid>https://arxiv.org/abs/2602.04868v1</guid>
  <pubDate>Wed, 04 Feb 2026 18:54:26 +0000</pubDate>
  <description>arXiv cs.AI - Continual reinforcement learning (CRL) requires agents to learn from a sequence of tasks without forgetting previously acquired policies. In this work, we introduce a novel benchmark suite for CRL based on realistically simulated robots in the Gazebo simulator. Our Continual Robotic Simulation Suite (CRoSS) benchmarks rely on two robotic platforms: a two-wheeled differential-drive robot with lidar</description>
</item>

<item>
  <title>CRoSS: A Continual Robotic Simulation Suite for Scalable Reinforcement Learning with High Task Diversity and Realistic Physics Simulation</title>
  <link>https://arxiv.org/abs/2602.04868v1</link>
  <guid>https://arxiv.org/abs/2602.04868v1</guid>
  <pubDate>Wed, 04 Feb 2026 18:54:26 +0000</pubDate>
  <description>arXiv cs.LG - Continual reinforcement learning (CRL) requires agents to learn from a sequence of tasks without forgetting previously acquired policies. In this work, we introduce a novel benchmark suite for CRL based on realistically simulated robots in the Gazebo simulator. Our Continual Robotic Simulation Suite (CRoSS) benchmarks rely on two robotic platforms: a two-wheeled differential-drive robot with lidar</description>
</item>

<item>
  <title>El Agente Quntur: A research collaborator agent for quantum chemistry</title>
  <link>https://arxiv.org/abs/2602.04850v1</link>
  <guid>https://arxiv.org/abs/2602.04850v1</guid>
  <pubDate>Wed, 04 Feb 2026 18:38:50 +0000</pubDate>
  <description>arXiv cs.AI - Quantum chemistry is a foundational enabling tool for the fields of chemistry, materials science, computational biology and others. Despite of its power, the practical application of quantum chemistry simulations remains in the hands of qualified experts due to methodological complexity, software heterogeneity, and the need for informed interpretation of results. To bridge the accessibility gap fo</description>
</item>

<item>
  <title>El Agente Estructural: An Artificially Intelligent Molecular Editor</title>
  <link>https://arxiv.org/abs/2602.04849v1</link>
  <guid>https://arxiv.org/abs/2602.04849v1</guid>
  <pubDate>Wed, 04 Feb 2026 18:38:48 +0000</pubDate>
  <description>arXiv cs.AI - We present El Agente Estructural, a multimodal, natural-language-driven geometry-generation and manipulation agent for autonomous chemistry and molecular modelling. Unlike molecular generation or editing via generative models, Estructural mimics how human experts directly manipulate molecular systems in three dimensions by integrating a comprehensive set of domain-informed tools and vision-languag</description>
</item>

<item>
  <title>Fluid Representations in Reasoning Models</title>
  <link>https://arxiv.org/abs/2602.04843v1</link>
  <guid>https://arxiv.org/abs/2602.04843v1</guid>
  <pubDate>Wed, 04 Feb 2026 18:34:50 +0000</pubDate>
  <description>arXiv cs.AI - Reasoning language models, which generate long chains of thought, dramatically outperform non-reasoning language models on abstract problems. However, the internal model mechanisms that allow this superior performance remain poorly understood. We present a mechanistic analysis of how QwQ-32B - a model specifically trained to produce extensive reasoning traces - process abstract structural informat</description>
</item>

<item>
  <title>Group-Evolving Agents: Open-Ended Self-Improvement via Experience Sharing</title>
  <link>https://arxiv.org/abs/2602.04837v1</link>
  <guid>https://arxiv.org/abs/2602.04837v1</guid>
  <pubDate>Wed, 04 Feb 2026 18:29:36 +0000</pubDate>
  <description>arXiv cs.AI - Open-ended self-improving agents can autonomously modify their own structural designs to advance their capabilities and overcome the limits of pre-defined architectures, thus reducing reliance on human intervention. We introduce Group-Evolving Agents (GEA), a new paradigm for open-ended self-improvements, which treats a group of agents as the fundamental evolutionary unit, enabling explicit experi</description>
</item>

<item>
  <title>Safe Urban Traffic Control via Uncertainty-Aware Conformal Prediction and World-Model Reinforcement Learning</title>
  <link>https://arxiv.org/abs/2602.04821v1</link>
  <guid>https://arxiv.org/abs/2602.04821v1</guid>
  <pubDate>Wed, 04 Feb 2026 18:10:59 +0000</pubDate>
  <description>arXiv cs.AI - Urban traffic management demands systems that simultaneously predict future conditions, detect anomalies, and take safe corrective actions -- all while providing reliability guarantees. We present STREAM-RL, a unified framework that introduces three novel algorithmic contributions: (1) PU-GAT+, an Uncertainty-Guided Adaptive Conformal Forecaster that uses prediction uncertainty to dynamically rewe</description>
</item>

<item>
  <title>Safe Urban Traffic Control via Uncertainty-Aware Conformal Prediction and World-Model Reinforcement Learning</title>
  <link>https://arxiv.org/abs/2602.04821v1</link>
  <guid>https://arxiv.org/abs/2602.04821v1</guid>
  <pubDate>Wed, 04 Feb 2026 18:10:59 +0000</pubDate>
  <description>arXiv cs.LG - Urban traffic management demands systems that simultaneously predict future conditions, detect anomalies, and take safe corrective actions -- all while providing reliability guarantees. We present STREAM-RL, a unified framework that introduces three novel algorithmic contributions: (1) PU-GAT+, an Uncertainty-Guided Adaptive Conformal Forecaster that uses prediction uncertainty to dynamically rewe</description>
</item>

<item>
  <title>Agentic AI in Healthcare &amp; Medicine: A Seven-Dimensional Taxonomy for Empirical Evaluation of LLM-based Agents</title>
  <link>https://arxiv.org/abs/2602.04813v1</link>
  <guid>https://arxiv.org/abs/2602.04813v1</guid>
  <pubDate>Wed, 04 Feb 2026 17:59:14 +0000</pubDate>
  <description>arXiv cs.AI - Large Language Model (LLM)-based agents that plan, use tools and act has begun to shape healthcare and medicine. Reported studies demonstrate competence on various tasks ranging from EHR analysis and differential diagnosis to treatment planning and research workflows. Yet the literature largely consists of overviews which are either broad surveys or narrow dives into a single capability (e.g., mem</description>
</item>

<item>
  <title>SE-Bench: Benchmarking Self-Evolution with Knowledge Internalization</title>
  <link>https://arxiv.org/abs/2602.04811v1</link>
  <guid>https://arxiv.org/abs/2602.04811v1</guid>
  <pubDate>Wed, 04 Feb 2026 17:58:32 +0000</pubDate>
  <description>arXiv cs.AI - True self-evolution requires agents to act as lifelong learners that internalize novel experiences to solve future problems. However, rigorously measuring this foundational capability is hindered by two obstacles: the entanglement of prior knowledge, where ``new&apos;&apos; knowledge may appear in pre-training data, and the entanglement of reasoning complexity, where failures may stem from problem difficult</description>
</item>

<item>
  <title>SE-Bench: Benchmarking Self-Evolution with Knowledge Internalization</title>
  <link>https://arxiv.org/abs/2602.04811v1</link>
  <guid>https://arxiv.org/abs/2602.04811v1</guid>
  <pubDate>Wed, 04 Feb 2026 17:58:32 +0000</pubDate>
  <description>arXiv cs.LG - True self-evolution requires agents to act as lifelong learners that internalize novel experiences to solve future problems. However, rigorously measuring this foundational capability is hindered by two obstacles: the entanglement of prior knowledge, where ``new&apos;&apos; knowledge may appear in pre-training data, and the entanglement of reasoning complexity, where failures may stem from problem difficult</description>
</item>

<item>
  <title>Beyond Rewards in Reinforcement Learning for Cyber Defence</title>
  <link>https://arxiv.org/abs/2602.04809v1</link>
  <guid>https://arxiv.org/abs/2602.04809v1</guid>
  <pubDate>Wed, 04 Feb 2026 17:55:23 +0000</pubDate>
  <description>arXiv cs.AI - Recent years have seen an explosion of interest in autonomous cyber defence agents trained to defend computer networks using deep reinforcement learning. These agents are typically trained in cyber gym environments using dense, highly engineered reward functions which combine many penalties and incentives for a range of (un)desirable states and costly actions. Dense rewards help alleviate the chal</description>
</item>

<item>
  <title>Beyond Rewards in Reinforcement Learning for Cyber Defence</title>
  <link>https://arxiv.org/abs/2602.04809v1</link>
  <guid>https://arxiv.org/abs/2602.04809v1</guid>
  <pubDate>Wed, 04 Feb 2026 17:55:23 +0000</pubDate>
  <description>arXiv cs.LG - Recent years have seen an explosion of interest in autonomous cyber defence agents trained to defend computer networks using deep reinforcement learning. These agents are typically trained in cyber gym environments using dense, highly engineered reward functions which combine many penalties and incentives for a range of (un)desirable states and costly actions. Dense rewards help alleviate the chal</description>
</item>

<item>
  <title>Active Asymmetric Multi-Agent Multimodal Learning under Uncertainty</title>
  <link>https://arxiv.org/abs/2602.04763v1</link>
  <guid>https://arxiv.org/abs/2602.04763v1</guid>
  <pubDate>Wed, 04 Feb 2026 17:01:31 +0000</pubDate>
  <description>arXiv cs.AI - Multi-agent systems are increasingly equipped with heterogeneous multimodal sensors, enabling richer perception but introducing modality-specific and agent-dependent uncertainty. Existing multi-agent collaboration frameworks typically reason at the agent level, assume homogeneous sensing, and handle uncertainty implicitly, limiting robustness under sensor corruption. We propose Active Asymmetric M</description>
</item>

<item>
  <title>Understanding and Exploiting Weight Update Sparsity for Communication-Efficient Distributed RL</title>
  <link>https://arxiv.org/abs/2602.03839v1</link>
  <guid>https://arxiv.org/abs/2602.03839v1</guid>
  <pubDate>Tue, 03 Feb 2026 18:56:48 +0000</pubDate>
  <description>arXiv cs.LG - Reinforcement learning (RL) is a critical component for post-training large language models (LLMs). However, in bandwidth-constrained distributed RL, scalability is often bottlenecked by the synchronization of policy weights from trainers to inference workers, particularly over commodity networks or in decentralized settings. While recent studies suggest that RL updates modify only a small fractio</description>
</item>

<item>
  <title>PrevizWhiz: Combining Rough 3D Scenes and 2D Video to Guide Generative Video Previsualization</title>
  <link>https://arxiv.org/abs/2602.03838v1</link>
  <guid>https://arxiv.org/abs/2602.03838v1</guid>
  <pubDate>Tue, 03 Feb 2026 18:56:40 +0000</pubDate>
  <description>arXiv cs.AI - In pre-production, filmmakers and 3D animation experts must rapidly prototype ideas to explore a film&apos;s possibilities before fullscale production, yet conventional approaches involve trade-offs in efficiency and expressiveness. Hand-drawn storyboards often lack spatial precision needed for complex cinematography, while 3D previsualization demands expertise and high-quality rigged assets. To addres</description>
</item>

<item>
  <title>Accelerating Scientific Research with Gemini: Case Studies and Common Techniques</title>
  <link>https://arxiv.org/abs/2602.03837v1</link>
  <guid>https://arxiv.org/abs/2602.03837v1</guid>
  <pubDate>Tue, 03 Feb 2026 18:56:17 +0000</pubDate>
  <description>arXiv cs.AI - Recent advances in large language models (LLMs) have opened new avenues for accelerating scientific research. While models are increasingly capable of assisting with routine tasks, their ability to contribute to novel, expert-level mathematical discovery is less understood. We present a collection of case studies demonstrating how researchers have successfully collaborated with advanced AI models,</description>
</item>

<item>
  <title>AutoFigure: Generating and Refining Publication-Ready Scientific Illustrations</title>
  <link>https://arxiv.org/abs/2602.03828v1</link>
  <guid>https://arxiv.org/abs/2602.03828v1</guid>
  <pubDate>Tue, 03 Feb 2026 18:41:43 +0000</pubDate>
  <description>arXiv cs.AI - High-quality scientific illustrations are crucial for effectively communicating complex scientific and technical concepts, yet their manual creation remains a well-recognized bottleneck in both academia and industry. We present FigureBench, the first large-scale benchmark for generating scientific illustrations from long-form scientific texts. It contains 3,300 high-quality scientific text-figure </description>
</item>

<item>
  <title>SymPlex: A Structure-Aware Transformer for Symbolic PDE Solving</title>
  <link>https://arxiv.org/abs/2602.03816v1</link>
  <guid>https://arxiv.org/abs/2602.03816v1</guid>
  <pubDate>Tue, 03 Feb 2026 18:18:30 +0000</pubDate>
  <description>arXiv cs.LG - We propose SymPlex, a reinforcement learning framework for discovering analytical symbolic solutions to partial differential equations (PDEs) without access to ground-truth expressions. SymPlex formulates symbolic PDE solving as tree-structured decision-making and optimizes candidate solutions using only the PDE and its boundary conditions. At its core is SymFormer, a structure-aware Transformer t</description>
</item>

<item>
  <title>Understanding Agent Scaling in LLM-Based Multi-Agent Systems via Diversity</title>
  <link>https://arxiv.org/abs/2602.03794v1</link>
  <guid>https://arxiv.org/abs/2602.03794v1</guid>
  <pubDate>Tue, 03 Feb 2026 17:58:10 +0000</pubDate>
  <description>arXiv cs.AI - LLM-based multi-agent systems (MAS) have emerged as a promising approach to tackle complex tasks that are difficult for individual LLMs. A natural strategy is to scale performance by increasing the number of agents; however, we find that such scaling exhibits strong diminishing returns in homogeneous settings, while introducing heterogeneity (e.g., different models, prompts, or tools) continues to</description>
</item>

<item>
  <title>Understanding Agent Scaling in LLM-Based Multi-Agent Systems via Diversity</title>
  <link>https://arxiv.org/abs/2602.03794v1</link>
  <guid>https://arxiv.org/abs/2602.03794v1</guid>
  <pubDate>Tue, 03 Feb 2026 17:58:10 +0000</pubDate>
  <description>arXiv cs.LG - LLM-based multi-agent systems (MAS) have emerged as a promising approach to tackle complex tasks that are difficult for individual LLMs. A natural strategy is to scale performance by increasing the number of agents; however, we find that such scaling exhibits strong diminishing returns in homogeneous settings, while introducing heterogeneity (e.g., different models, prompts, or tools) continues to</description>
</item>

<item>
  <title>WebSentinel: Detecting and Localizing Prompt Injection Attacks for Web Agents</title>
  <link>https://arxiv.org/abs/2602.03792v1</link>
  <guid>https://arxiv.org/abs/2602.03792v1</guid>
  <pubDate>Tue, 03 Feb 2026 17:55:04 +0000</pubDate>
  <description>arXiv cs.AI - Prompt injection attacks manipulate webpage content to cause web agents to execute attacker-specified tasks instead of the user&apos;s intended ones. Existing methods for detecting and localizing such attacks achieve limited effectiveness, as their underlying assumptions often do not hold in the web-agent setting. In this work, we propose WebSentinel, a two-step approach for detecting and localizing pr</description>
</item>

<item>
  <title>AOrchestra: Automating Sub-Agent Creation for Agentic Orchestration</title>
  <link>https://arxiv.org/abs/2602.03786v1</link>
  <guid>https://arxiv.org/abs/2602.03786v1</guid>
  <pubDate>Tue, 03 Feb 2026 17:46:16 +0000</pubDate>
  <description>arXiv cs.AI - Language agents have shown strong promise for task automation. Realizing this promise for increasingly complex, long-horizon tasks has driven the rise of a sub-agent-as-tools paradigm for multi-turn task solving. However, existing designs still lack a dynamic abstraction view of sub-agents, thereby hurting adaptability. We address this challenge with a unified, framework-agnostic agent abstraction</description>
</item>

<item>
  <title>Efficient Estimation of Kernel Surrogate Models for Task Attribution</title>
  <link>https://arxiv.org/abs/2602.03783v1</link>
  <guid>https://arxiv.org/abs/2602.03783v1</guid>
  <pubDate>Tue, 03 Feb 2026 17:43:48 +0000</pubDate>
  <description>arXiv cs.AI - Modern AI agents such as large language models are trained on diverse tasks -- translation, code generation, mathematical reasoning, and text prediction -- simultaneously. A key question is to quantify how each individual training task influences performance on a target task, a problem we refer to as task attribution. The direct approach, leave-one-out retraining, measures the effect of removing e</description>
</item>

<item>
  <title>Efficient Estimation of Kernel Surrogate Models for Task Attribution</title>
  <link>https://arxiv.org/abs/2602.03783v1</link>
  <guid>https://arxiv.org/abs/2602.03783v1</guid>
  <pubDate>Tue, 03 Feb 2026 17:43:48 +0000</pubDate>
  <description>arXiv cs.LG - Modern AI agents such as large language models are trained on diverse tasks -- translation, code generation, mathematical reasoning, and text prediction -- simultaneously. A key question is to quantify how each individual training task influences performance on a target task, a problem we refer to as task attribution. The direct approach, leave-one-out retraining, measures the effect of removing e</description>
</item>

<item>
  <title>DiffLOB: Diffusion Models for Counterfactual Generation in Limit Order Books</title>
  <link>https://arxiv.org/abs/2602.03776v1</link>
  <guid>https://arxiv.org/abs/2602.03776v1</guid>
  <pubDate>Tue, 03 Feb 2026 17:34:56 +0000</pubDate>
  <description>arXiv cs.AI - Modern generative models for limit order books (LOBs) can reproduce realistic market dynamics, but remain fundamentally passive: they either model what typically happens without accounting for hypothetical future market conditions, or they require interaction with another agent to explore alternative outcomes. This limits their usefulness for stress testing, scenario analysis, and decision-making.</description>
</item>

<item>
  <title>An Empirical Study of Collective Behaviors and Social Dynamics in Large Language Model Agents</title>
  <link>https://arxiv.org/abs/2602.03775v1</link>
  <guid>https://arxiv.org/abs/2602.03775v1</guid>
  <pubDate>Tue, 03 Feb 2026 17:34:32 +0000</pubDate>
  <description>arXiv cs.AI - Large Language Models (LLMs) increasingly mediate our social, cultural, and political interactions. While they can simulate some aspects of human behavior and decision-making, it is still underexplored whether repeated interactions with other agents amplify their biases or lead to exclusionary behaviors. To this end, we study Chirper.ai-an LLM-driven social media platform-analyzing 7M posts and in</description>
</item>

<item>
  <title>Reasoning Cache: Continual Improvement Over Long Horizons via Short-Horizon RL</title>
  <link>https://arxiv.org/abs/2602.03773v1</link>
  <guid>https://arxiv.org/abs/2602.03773v1</guid>
  <pubDate>Tue, 03 Feb 2026 17:34:04 +0000</pubDate>
  <description>arXiv cs.LG - Large Language Models (LLMs) that can continually improve beyond their training budgets are able to solve increasingly difficult problems by adapting at test time, a property we refer to as extrapolation. However, standard reinforcement learning (RL) operates over fixed problem distributions and training budgets, which limits extrapolation amidst distribution shift at test time. To address this, w</description>
</item>

<item>
  <title>Zero-shot large vision-language model prompting for automated bone identification in paleoradiology x-ray archives</title>
  <link>https://arxiv.org/abs/2602.03750v1</link>
  <guid>https://arxiv.org/abs/2602.03750v1</guid>
  <pubDate>Tue, 03 Feb 2026 17:14:23 +0000</pubDate>
  <description>arXiv cs.AI - Paleoradiology, the use of modern imaging technologies to study archaeological and anthropological remains, offers new windows on millennial scale patterns of human health. Unfortunately, the radiographs collected during field campaigns are heterogeneous: bones are disarticulated, positioning is ad hoc, and laterality markers are often absent. Additionally, factors such as age at death, age of bon</description>
</item>

<item>
  <title>Cognitively Diverse Multiple-Choice Question Generation: A Hybrid Multi-Agent Framework with Large Language Models</title>
  <link>https://arxiv.org/abs/2602.03704v1</link>
  <guid>https://arxiv.org/abs/2602.03704v1</guid>
  <pubDate>Tue, 03 Feb 2026 16:26:47 +0000</pubDate>
  <description>arXiv cs.AI - Recent advances in large language models (LLMs) have made automated multiple-choice question (MCQ) generation increasingly feasible; however, reliably producing items that satisfy controlled cognitive demands remains a challenge. To address this gap, we introduce ReQUESTA, a hybrid, multi-agent framework for generating cognitively diverse MCQs that systematically target text-based, inferential, an</description>
</item>

<item>
  <title>Agent Primitives: Reusable Latent Building Blocks for Multi-Agent Systems</title>
  <link>https://arxiv.org/abs/2602.03695v1</link>
  <guid>https://arxiv.org/abs/2602.03695v1</guid>
  <pubDate>Tue, 03 Feb 2026 16:17:53 +0000</pubDate>
  <description>arXiv cs.AI - While existing multi-agent systems (MAS) can handle complex problems by enabling collaboration among multiple agents, they are often highly task-specific, relying on manually crafted agent roles and interaction prompts, which leads to increased architectural complexity and limited reusability across tasks. Moreover, most MAS communicate primarily through natural language, making them vulnerable to</description>
</item>

<item>
  <title>MEG-XL: Data-Efficient Brain-to-Text via Long-Context Pre-Training</title>
  <link>https://arxiv.org/abs/2602.02494v1</link>
  <guid>https://arxiv.org/abs/2602.02494v1</guid>
  <pubDate>Mon, 02 Feb 2026 18:59:50 +0000</pubDate>
  <description>arXiv cs.LG - Clinical brain-to-text interfaces are designed for paralysed patients who cannot provide extensive training recordings. Pre-training improves data-efficient generalisation by learning statistical priors across subjects, but these priors critically depend on context. While natural speech might unfold gradually over minutes, most methods pre-train with only a few seconds of context. Thus, we propose</description>
</item>

<item>
  <title>RLAnything: Forge Environment, Policy, and Reward Model in Completely Dynamic RL System</title>
  <link>https://arxiv.org/abs/2602.02488v1</link>
  <guid>https://arxiv.org/abs/2602.02488v1</guid>
  <pubDate>Mon, 02 Feb 2026 18:59:04 +0000</pubDate>
  <description>arXiv cs.LG - We propose RLAnything, a reinforcement learning framework that dynamically forges environment, policy, and reward models through closed-loop optimization, amplifying learning signals and strengthening the overall RL system for any LLM or agentic scenarios. Specifically, the policy is trained with integrated feedback from step-wise and outcome signals, while the reward model is jointly optimized vi</description>
</item>

<item>
  <title>RE-TRAC: REcursive TRAjectory Compression for Deep Search Agents</title>
  <link>https://arxiv.org/abs/2602.02486v1</link>
  <guid>https://arxiv.org/abs/2602.02486v1</guid>
  <pubDate>Mon, 02 Feb 2026 18:58:07 +0000</pubDate>
  <description>arXiv cs.AI - LLM-based deep research agents are largely built on the ReAct framework. This linear design makes it difficult to revisit earlier states, branch into alternative search directions, or maintain global awareness under long contexts, often leading to local optima, redundant exploration, and inefficient search. We propose Re-TRAC, an agentic framework that performs cross-trajectory exploration by gene</description>
</item>

<item>
  <title>Expanding the Capabilities of Reinforcement Learning via Text Feedback</title>
  <link>https://arxiv.org/abs/2602.02482v1</link>
  <guid>https://arxiv.org/abs/2602.02482v1</guid>
  <pubDate>Mon, 02 Feb 2026 18:56:56 +0000</pubDate>
  <description>arXiv cs.LG - The success of RL for LLM post-training stems from an unreasonably uninformative source: a single bit of information per rollout as binary reward or preference label. At the other extreme, distillation offers dense supervision but requires demonstrations, which are costly and difficult to scale. We study text feedback as an intermediate signal: richer than scalar rewards, yet cheaper than complete</description>
</item>

<item>
  <title>AgentRx: Diagnosing AI Agent Failures from Execution Trajectories</title>
  <link>https://arxiv.org/abs/2602.02475v1</link>
  <guid>https://arxiv.org/abs/2602.02475v1</guid>
  <pubDate>Mon, 02 Feb 2026 18:54:07 +0000</pubDate>
  <description>arXiv cs.AI - AI agents often fail in ways that are difficult to localize because executions are probabilistic, long-horizon, multi-agent, and mediated by noisy tool outputs. We address this gap by manually annotating failed agent runs and release a novel benchmark of 115 failed trajectories spanning structured API workflows, incident management, and open-ended web/file tasks. Each trajectory is annotated with </description>
</item>

<item>
  <title>MemSkill: Learning and Evolving Memory Skills for Self-Evolving Agents</title>
  <link>https://arxiv.org/abs/2602.02474v1</link>
  <guid>https://arxiv.org/abs/2602.02474v1</guid>
  <pubDate>Mon, 02 Feb 2026 18:53:28 +0000</pubDate>
  <description>arXiv cs.AI - Most Large Language Model (LLM) agent memory systems rely on a small set of static, hand-designed operations for extracting memory. These fixed procedures hard-code human priors about what to store and how to revise memory, making them rigid under diverse interaction patterns and inefficient on long histories. To this end, we present \textbf{MemSkill}, which reframes these operations as learnable </description>
</item>

<item>
  <title>MemSkill: Learning and Evolving Memory Skills for Self-Evolving Agents</title>
  <link>https://arxiv.org/abs/2602.02474v1</link>
  <guid>https://arxiv.org/abs/2602.02474v1</guid>
  <pubDate>Mon, 02 Feb 2026 18:53:28 +0000</pubDate>
  <description>arXiv cs.LG - Most Large Language Model (LLM) agent memory systems rely on a small set of static, hand-designed operations for extracting memory. These fixed procedures hard-code human priors about what to store and how to revise memory, making them rigid under diverse interaction patterns and inefficient on long histories. To this end, we present \textbf{MemSkill}, which reframes these operations as learnable </description>
</item>

<item>
  <title>Multi-head automated segmentation by incorporating detection head into the contextual layer neural network</title>
  <link>https://arxiv.org/abs/2602.02471v1</link>
  <guid>https://arxiv.org/abs/2602.02471v1</guid>
  <pubDate>Mon, 02 Feb 2026 18:51:25 +0000</pubDate>
  <description>arXiv cs.AI - Deep learning based auto segmentation is increasingly used in radiotherapy, but conventional models often produce anatomically implausible false positives, or hallucinations, in slices lacking target structures. We propose a gated multi-head Transformer architecture based on Swin U-Net, augmented with inter-slice context integration and a parallel detection head, which jointly performs slice-level</description>
</item>

<item>
  <title>Avenir-Web: Human-Experience-Imitating Multimodal Web Agents with Mixture of Grounding Experts</title>
  <link>https://arxiv.org/abs/2602.02468v1</link>
  <guid>https://arxiv.org/abs/2602.02468v1</guid>
  <pubDate>Mon, 02 Feb 2026 18:50:07 +0000</pubDate>
  <description>arXiv cs.AI - Despite advances in multimodal large language models, autonomous web agents still struggle to reliably execute long-horizon tasks on complex and dynamic web interfaces. Existing agents often suffer from inaccurate element grounding, the absence of site-specific procedural knowledge, and unstable long-term task tracking and memory, particularly when operating over complex Document Object Model stru</description>
</item>

<item>
  <title>Drift-Bench: Diagnosing Cooperative Breakdowns in LLM Agents under Input Faults via Multi-Turn Interaction</title>
  <link>https://arxiv.org/abs/2602.02455v1</link>
  <guid>https://arxiv.org/abs/2602.02455v1</guid>
  <pubDate>Mon, 02 Feb 2026 18:46:16 +0000</pubDate>
  <description>arXiv cs.AI - As Large Language Models transition to autonomous agents, user inputs frequently violate cooperative assumptions (e.g., implicit intent, missing parameters, false presuppositions, or ambiguous expressions), creating execution risks that text-only evaluations do not capture. Existing benchmarks typically assume well-specified instructions or restrict evaluation to text-only, single-turn clarificati</description>
</item>

<item>
  <title>Energy-Efficient Neuromorphic Computing for Edge AI: A Framework with Adaptive Spiking Neural Networks and Hardware-Aware Optimization</title>
  <link>https://arxiv.org/abs/2602.02439v1</link>
  <guid>https://arxiv.org/abs/2602.02439v1</guid>
  <pubDate>Mon, 02 Feb 2026 18:34:48 +0000</pubDate>
  <description>arXiv cs.LG - Edge AI applications increasingly require ultra-low-power, low-latency inference. Neuromorphic computing based on event-driven spiking neural networks (SNNs) offers an attractive path, but practical deployment on resource-constrained devices is limited by training difficulty, hardware-mapping overheads, and sensitivity to temporal dynamics. We present NeuEdge, a framework that combines adaptive SN</description>
</item>

<item>
  <title>UniReason 1.0: A Unified Reasoning Framework for World Knowledge Aligned Image Generation and Editing</title>
  <link>https://arxiv.org/abs/2602.02437v1</link>
  <guid>https://arxiv.org/abs/2602.02437v1</guid>
  <pubDate>Mon, 02 Feb 2026 18:34:35 +0000</pubDate>
  <description>arXiv cs.AI - Unified multimodal models often struggle with complex synthesis tasks that demand deep reasoning, and typically treat text-to-image generation and image editing as isolated capabilities rather than interconnected reasoning steps. To address this, we propose UniReason, a unified framework that harmonizes these two tasks through a dual reasoning paradigm. We formulate generation as world knowledge-e</description>
</item>

<item>
  <title>David vs. Goliath: Verifiable Agent-to-Agent Jailbreaking via Reinforcement Learning</title>
  <link>https://arxiv.org/abs/2602.02395v1</link>
  <guid>https://arxiv.org/abs/2602.02395v1</guid>
  <pubDate>Mon, 02 Feb 2026 17:56:55 +0000</pubDate>
  <description>arXiv cs.AI - The evolution of large language models into autonomous agents introduces adversarial failures that exploit legitimate tool privileges, transforming safety evaluation in tool-augmented environments from a subjective NLP task into an objective control problem. We formalize this threat model as Tag-Along Attacks: a scenario where a tool-less adversary &quot;tags along&quot; on the trusted privileges of a safet</description>
</item>

<item>
  <title>End-to-end Optimization of Belief and Policy Learning in Shared Autonomy Paradigms</title>
  <link>https://arxiv.org/abs/2601.23285v1</link>
  <guid>https://arxiv.org/abs/2601.23285v1</guid>
  <pubDate>Fri, 30 Jan 2026 18:59:16 +0000</pubDate>
  <description>arXiv cs.AI - Shared autonomy systems require principled methods for inferring user intent and determining appropriate assistance levels. This is a central challenge in human-robot interaction, where systems must be successful while being mindful of user agency. Previous approaches relied on static blending ratios or separated goal inference from assistance arbitration, leading to suboptimal performance in unst</description>
</item>

<item>
  <title>End-to-end Optimization of Belief and Policy Learning in Shared Autonomy Paradigms</title>
  <link>https://arxiv.org/abs/2601.23285v1</link>
  <guid>https://arxiv.org/abs/2601.23285v1</guid>
  <pubDate>Fri, 30 Jan 2026 18:59:16 +0000</pubDate>
  <description>arXiv cs.LG - Shared autonomy systems require principled methods for inferring user intent and determining appropriate assistance levels. This is a central challenge in human-robot interaction, where systems must be successful while being mindful of user agency. Previous approaches relied on static blending ratios or separated goal inference from assistance arbitration, leading to suboptimal performance in unst</description>
</item>

<item>
  <title>FOCUS: DLLMs Know How to Tame Their Compute Bound</title>
  <link>https://arxiv.org/abs/2601.23278v1</link>
  <guid>https://arxiv.org/abs/2601.23278v1</guid>
  <pubDate>Fri, 30 Jan 2026 18:52:06 +0000</pubDate>
  <description>arXiv cs.LG - Diffusion Large Language Models (DLLMs) offer a compelling alternative to Auto-Regressive models, but their deployment is constrained by high decoding cost. In this work, we identify a key inefficiency in DLLM decoding: while computation is parallelized over token blocks, only a small subset of tokens is decodable at each diffusion step, causing most compute to be wasted on non-decodable tokens. W</description>
</item>

<item>
  <title>Denoising the Deep Sky: Physics-Based CCD Noise Formation for Astronomical Imaging</title>
  <link>https://arxiv.org/abs/2601.23276v1</link>
  <guid>https://arxiv.org/abs/2601.23276v1</guid>
  <pubDate>Fri, 30 Jan 2026 18:47:54 +0000</pubDate>
  <description>arXiv cs.LG - Astronomical imaging remains noise-limited under practical observing constraints, while standard calibration pipelines mainly remove structured artifacts and leave stochastic noise largely unresolved. Learning-based denoising is promising, yet progress is hindered by scarce paired training data and the need for physically interpretable and reproducible models in scientific workflows. We propose a </description>
</item>

<item>
  <title>IRL-DAL: Safe and Adaptive Trajectory Planning for Autonomous Driving via Energy-Guided Diffusion Models</title>
  <link>https://arxiv.org/abs/2601.23266v1</link>
  <guid>https://arxiv.org/abs/2601.23266v1</guid>
  <pubDate>Fri, 30 Jan 2026 18:34:10 +0000</pubDate>
  <description>arXiv cs.AI - This paper proposes a novel inverse reinforcement learning framework using a diffusion-based adaptive lookahead planner (IRL-DAL) for autonomous vehicles. Training begins with imitation from an expert finite state machine (FSM) controller to provide a stable initialization. Environment terms are combined with an IRL discriminator signal to align with expert goals. Reinforcement learning (RL) is th</description>
</item>

<item>
  <title>Now You Hear Me: Audio Narrative Attacks Against Large Audio-Language Models</title>
  <link>https://arxiv.org/abs/2601.23255v1</link>
  <guid>https://arxiv.org/abs/2601.23255v1</guid>
  <pubDate>Fri, 30 Jan 2026 18:23:02 +0000</pubDate>
  <description>arXiv cs.AI - Large audio-language models increasingly operate on raw speech inputs, enabling more seamless integration across domains such as voice assistants, education, and clinical triage. This transition, however, introduces a distinct class of vulnerabilities that remain largely uncharacterized. We examine the security implications of this modality shift by designing a text-to-audio jailbreak that embeds </description>
</item>

</channel>
</rss>
