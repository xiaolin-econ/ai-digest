<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
<channel>
  <title>AI Research Digest</title>
  <link>https://xiaolin-econ.github.io/ai-digest/</link>
  <description>Curated AI research + releases</description>
  <lastBuildDate>Fri, 06 Feb 2026 06:41:30 +0000</lastBuildDate>
  <atom:link href="https://xiaolin-econ.github.io/ai-digest/rss.xml" rel="self" type="application/rss+xml" xmlns:atom="http://www.w3.org/2005/Atom"/>
  
<item>
  <title>AI Digest — Daily Summary</title>
  <link>https://xiaolin-econ.github.io/ai-digest/rss.xml</link>
  <guid>https://xiaolin-econ.github.io/ai-digest/rss.xml#summary</guid>
  <pubDate>Fri, 06 Feb 2026 06:41:30 +0000</pubDate>
  <description>Multi-agent systems built from prompted large language models can improve multi-round reasoning, yet most existing pipelines rely on fixed, trajectory-wide communication patterns that are poorly matched to the stage-dependent needs of iterative problem solving. We introduce DyTopo, a manager-guided multi-agent framework that reconstructs a sparse directed communication graph at each round. Conditioned on the manager&apos;s round goal, each agent outputs lightweight natural-language query (need) and \key (offer) descriptors; DyTopo embeds these descriptors and performs semantic matching, routing private messages only along the induced edges. Across code generation and mathematical reasoning benchmarks and four LLM backbones, DyTopo consistently outperforms over the strongest baseline (avg.…</description>
</item>

<item>
  <title>DyTopo: Dynamic Topology Routing for Multi-Agent Reasoning via Semantic Matching</title>
  <link>https://arxiv.org/abs/2602.06039v1</link>
  <guid>https://arxiv.org/abs/2602.06039v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:59:51 +0000</pubDate>
  <description>arXiv cs.AI - Multi-agent systems built from prompted large language models can improve multi-round reasoning, yet most existing pipelines rely on fixed, trajectory-wide communication patterns that are poorly matched to the stage-dependent needs of iterative problem solving. We introduce DyTopo, a manager-guided multi-agent framework that reconstructs a sparse directed communication graph at each round. Conditi</description>
</item>

<item>
  <title>CommCP: Efficient Multi-Agent Coordination via LLM-Based Communication with Conformal Prediction</title>
  <link>https://arxiv.org/abs/2602.06038v1</link>
  <guid>https://arxiv.org/abs/2602.06038v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:59:45 +0000</pubDate>
  <description>arXiv cs.AI - To complete assignments provided by humans in natural language, robots must interpret commands, generate and answer relevant questions for scene understanding, and manipulate target objects. Real-world deployments often require multiple heterogeneous robots with different manipulation capabilities to handle different assignments cooperatively. Beyond the need for specialized manipulation skills, e</description>
</item>

<item>
  <title>CommCP: Efficient Multi-Agent Coordination via LLM-Based Communication with Conformal Prediction</title>
  <link>https://arxiv.org/abs/2602.06038v1</link>
  <guid>https://arxiv.org/abs/2602.06038v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:59:45 +0000</pubDate>
  <description>arXiv cs.LG - To complete assignments provided by humans in natural language, robots must interpret commands, generate and answer relevant questions for scene understanding, and manipulate target objects. Real-world deployments often require multiple heterogeneous robots with different manipulation capabilities to handle different assignments cooperatively. Beyond the need for specialized manipulation skills, e</description>
</item>

<item>
  <title>PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling</title>
  <link>https://arxiv.org/abs/2602.06030v1</link>
  <guid>https://arxiv.org/abs/2602.06030v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:59:01 +0000</pubDate>
  <description>arXiv cs.LG - Large language model (LLM)-based multi-agent systems enable expressive agent reasoning but are expensive to scale and poorly calibrated for timestep-aligned state-transition simulation, while classical agent-based models (ABMs) offer interpretability but struggle to integrate rich individual-level signals and non-stationary behaviors. We propose PhysicsAgentABM, which shifts inference to behaviora</description>
</item>

<item>
  <title>Curiosity is Knowledge: Self-Consistent Learning and No-Regret Optimization with Active Inference</title>
  <link>https://arxiv.org/abs/2602.06029v1</link>
  <guid>https://arxiv.org/abs/2602.06029v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:58:32 +0000</pubDate>
  <description>arXiv cs.LG - Active inference (AIF) unifies exploration and exploitation by minimizing the Expected Free Energy (EFE), balancing epistemic value (information gain) and pragmatic value (task performance) through a curiosity coefficient. Yet it has been unclear when this balance yields both coherent learning and efficient decision-making: insufficient curiosity can drive myopic exploitation and prevent uncertain</description>
</item>

<item>
  <title>Learning Query-Aware Budget-Tier Routing for Runtime Agent Memory</title>
  <link>https://arxiv.org/abs/2602.06025v1</link>
  <guid>https://arxiv.org/abs/2602.06025v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:57:09 +0000</pubDate>
  <description>arXiv cs.AI - Memory is increasingly central to Large Language Model (LLM) agents operating beyond a single context window, yet most existing systems rely on offline, query-agnostic memory construction that can be inefficient and may discard query-critical information. Although runtime memory utilization is a natural alternative, prior work often incurs substantial overhead and offers limited explicit control o</description>
</item>

<item>
  <title>Learning Query-Aware Budget-Tier Routing for Runtime Agent Memory</title>
  <link>https://arxiv.org/abs/2602.06025v1</link>
  <guid>https://arxiv.org/abs/2602.06025v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:57:09 +0000</pubDate>
  <description>arXiv cs.LG - Memory is increasingly central to Large Language Model (LLM) agents operating beyond a single context window, yet most existing systems rely on offline, query-agnostic memory construction that can be inefficient and may discard query-critical information. Although runtime memory utilization is a natural alternative, prior work often incurs substantial overhead and offers limited explicit control o</description>
</item>

<item>
  <title>Learning Event-Based Shooter Models from Virtual Reality Experiments</title>
  <link>https://arxiv.org/abs/2602.06023v1</link>
  <guid>https://arxiv.org/abs/2602.06023v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:56:49 +0000</pubDate>
  <description>arXiv cs.AI - Virtual reality (VR) has emerged as a powerful tool for evaluating school security measures in high-risk scenarios such as school shootings, offering experimental control and high behavioral fidelity. However, assessing new interventions in VR requires recruiting new participant cohorts for each condition, making large-scale or iterative evaluation difficult. These limitations are especially restr</description>
</item>

<item>
  <title>Multi-Token Prediction via Self-Distillation</title>
  <link>https://arxiv.org/abs/2602.06019v1</link>
  <guid>https://arxiv.org/abs/2602.06019v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:54:48 +0000</pubDate>
  <description>arXiv cs.LG - Existing techniques for accelerating language model inference, such as speculative decoding, require training auxiliary speculator models and building and deploying complex inference pipelines. We consider a new approach for converting a pretrained autoregressive language model from a slow single next token prediction model into a fast standalone multi-token prediction model using a simple online </description>
</item>

<item>
  <title>AgenticPay: A Multi-Agent LLM Negotiation System for Buyer-Seller Transactions</title>
  <link>https://arxiv.org/abs/2602.06008v1</link>
  <guid>https://arxiv.org/abs/2602.06008v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:50:36 +0000</pubDate>
  <description>arXiv cs.AI - Large language model (LLM)-based agents are increasingly expected to negotiate, coordinate, and transact autonomously, yet existing benchmarks lack principled settings for evaluating language-mediated economic interaction among multiple agents. We introduce AgenticPay, a benchmark and simulation framework for multi-agent buyer-seller negotiation driven by natural language. AgenticPay models market</description>
</item>

<item>
  <title>AgenticPay: A Multi-Agent LLM Negotiation System for Buyer-Seller Transactions</title>
  <link>https://arxiv.org/abs/2602.06008v1</link>
  <guid>https://arxiv.org/abs/2602.06008v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:50:36 +0000</pubDate>
  <description>arXiv cs.LG - Large language model (LLM)-based agents are increasingly expected to negotiate, coordinate, and transact autonomously, yet existing benchmarks lack principled settings for evaluating language-mediated economic interaction among multiple agents. We introduce AgenticPay, a benchmark and simulation framework for multi-agent buyer-seller negotiation driven by natural language. AgenticPay models market</description>
</item>

<item>
  <title>Layer-wise LoRA fine-tuning: a similarity metric approach</title>
  <link>https://arxiv.org/abs/2602.05988v1</link>
  <guid>https://arxiv.org/abs/2602.05988v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:38:53 +0000</pubDate>
  <description>arXiv cs.LG - Pre-training Large Language Models (LLMs) on web-scale datasets becomes fundamental for advancing general-purpose AI. In contrast, enhancing their predictive performance on downstream tasks typically involves adapting their knowledge through fine-tuning. Parameter-efficient fine-tuning techniques, such as Low-Rank Adaptation (LoRA), aim to reduce the computational cost of this process by freezing </description>
</item>

<item>
  <title>Learning to Share: Selective Memory for Efficient Parallel Agentic Systems</title>
  <link>https://arxiv.org/abs/2602.05965v1</link>
  <guid>https://arxiv.org/abs/2602.05965v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:20:21 +0000</pubDate>
  <description>arXiv cs.AI - Agentic systems solve complex tasks by coordinating multiple agents that iteratively reason, invoke tools, and exchange intermediate results. To improve robustness and solution quality, recent approaches deploy multiple agent teams running in parallel to explore diverse reasoning trajectories. However, parallel execution comes at a significant computational cost: when different teams independently</description>
</item>

<item>
  <title>Compound Deception in Elite Peer Review: A Failure Mode Taxonomy of 100 Fabricated Citations at NeurIPS 2025</title>
  <link>https://arxiv.org/abs/2602.05930v1</link>
  <guid>https://arxiv.org/abs/2602.05930v1</guid>
  <pubDate>Thu, 05 Feb 2026 17:43:35 +0000</pubDate>
  <description>arXiv cs.AI - Large language models (LLMs) are increasingly used in academic writing workflows, yet they frequently hallucinate by generating citations to sources that do not exist. This study analyzes 100 AI-generated hallucinated citations that appeared in papers accepted by the 2025 Conference on Neural Information Processing Systems (NeurIPS), one of the world&apos;s most prestigious AI conferences. Despite revi</description>
</item>

<item>
  <title>Quantum Reinforcement Learning with Transformers for the Capacitated Vehicle Routing Problem</title>
  <link>https://arxiv.org/abs/2602.05920v1</link>
  <guid>https://arxiv.org/abs/2602.05920v1</guid>
  <pubDate>Thu, 05 Feb 2026 17:32:14 +0000</pubDate>
  <description>arXiv cs.AI - This paper addresses the Capacitated Vehicle Routing Problem (CVRP) by comparing classical and quantum Reinforcement Learning (RL) approaches. An Advantage Actor-Critic (A2C) agent is implemented in classical, full quantum, and hybrid variants, integrating transformer architectures to capture the relationships between vehicles, clients, and the depot through self- and cross-attention mechanisms. T</description>
</item>

<item>
  <title>Parity, Sensitivity, and Transformers</title>
  <link>https://arxiv.org/abs/2602.05896v1</link>
  <guid>https://arxiv.org/abs/2602.05896v1</guid>
  <pubDate>Thu, 05 Feb 2026 17:14:33 +0000</pubDate>
  <description>arXiv cs.AI - The transformer architecture is almost a decade old. Despite that, we still have a limited understanding of what this architecture can or cannot compute. For instance, can a 1-layer transformer solve PARITY -- or more generally -- which kinds of transformers can do it? Known constructions for PARITY have at least 2 layers and employ impractical features: either a length-dependent positional encodi</description>
</item>

<item>
  <title>Metric Hedonic Games on the Line</title>
  <link>https://arxiv.org/abs/2602.05888v1</link>
  <guid>https://arxiv.org/abs/2602.05888v1</guid>
  <pubDate>Thu, 05 Feb 2026 17:05:08 +0000</pubDate>
  <description>arXiv cs.AI - Hedonic games are fundamental models for investigating the formation of coalitions among a set of strategic agents, where every agent has a certain utility for every possible coalition of agents it can be part of. To avoid the intractability of defining exponentially many utilities for all possible coalitions, many variants with succinct representations of the agents&apos; utility functions have been d</description>
</item>

<item>
  <title>CRoSS: A Continual Robotic Simulation Suite for Scalable Reinforcement Learning with High Task Diversity and Realistic Physics Simulation</title>
  <link>https://arxiv.org/abs/2602.04868v1</link>
  <guid>https://arxiv.org/abs/2602.04868v1</guid>
  <pubDate>Wed, 04 Feb 2026 18:54:26 +0000</pubDate>
  <description>arXiv cs.AI - Continual reinforcement learning (CRL) requires agents to learn from a sequence of tasks without forgetting previously acquired policies. In this work, we introduce a novel benchmark suite for CRL based on realistically simulated robots in the Gazebo simulator. Our Continual Robotic Simulation Suite (CRoSS) benchmarks rely on two robotic platforms: a two-wheeled differential-drive robot with lidar</description>
</item>

<item>
  <title>CRoSS: A Continual Robotic Simulation Suite for Scalable Reinforcement Learning with High Task Diversity and Realistic Physics Simulation</title>
  <link>https://arxiv.org/abs/2602.04868v1</link>
  <guid>https://arxiv.org/abs/2602.04868v1</guid>
  <pubDate>Wed, 04 Feb 2026 18:54:26 +0000</pubDate>
  <description>arXiv cs.LG - Continual reinforcement learning (CRL) requires agents to learn from a sequence of tasks without forgetting previously acquired policies. In this work, we introduce a novel benchmark suite for CRL based on realistically simulated robots in the Gazebo simulator. Our Continual Robotic Simulation Suite (CRoSS) benchmarks rely on two robotic platforms: a two-wheeled differential-drive robot with lidar</description>
</item>

<item>
  <title>El Agente Quntur: A research collaborator agent for quantum chemistry</title>
  <link>https://arxiv.org/abs/2602.04850v1</link>
  <guid>https://arxiv.org/abs/2602.04850v1</guid>
  <pubDate>Wed, 04 Feb 2026 18:38:50 +0000</pubDate>
  <description>arXiv cs.AI - Quantum chemistry is a foundational enabling tool for the fields of chemistry, materials science, computational biology and others. Despite of its power, the practical application of quantum chemistry simulations remains in the hands of qualified experts due to methodological complexity, software heterogeneity, and the need for informed interpretation of results. To bridge the accessibility gap fo</description>
</item>

<item>
  <title>El Agente Estructural: An Artificially Intelligent Molecular Editor</title>
  <link>https://arxiv.org/abs/2602.04849v1</link>
  <guid>https://arxiv.org/abs/2602.04849v1</guid>
  <pubDate>Wed, 04 Feb 2026 18:38:48 +0000</pubDate>
  <description>arXiv cs.AI - We present El Agente Estructural, a multimodal, natural-language-driven geometry-generation and manipulation agent for autonomous chemistry and molecular modelling. Unlike molecular generation or editing via generative models, Estructural mimics how human experts directly manipulate molecular systems in three dimensions by integrating a comprehensive set of domain-informed tools and vision-languag</description>
</item>

<item>
  <title>Fluid Representations in Reasoning Models</title>
  <link>https://arxiv.org/abs/2602.04843v1</link>
  <guid>https://arxiv.org/abs/2602.04843v1</guid>
  <pubDate>Wed, 04 Feb 2026 18:34:50 +0000</pubDate>
  <description>arXiv cs.AI - Reasoning language models, which generate long chains of thought, dramatically outperform non-reasoning language models on abstract problems. However, the internal model mechanisms that allow this superior performance remain poorly understood. We present a mechanistic analysis of how QwQ-32B - a model specifically trained to produce extensive reasoning traces - process abstract structural informat</description>
</item>

<item>
  <title>Group-Evolving Agents: Open-Ended Self-Improvement via Experience Sharing</title>
  <link>https://arxiv.org/abs/2602.04837v1</link>
  <guid>https://arxiv.org/abs/2602.04837v1</guid>
  <pubDate>Wed, 04 Feb 2026 18:29:36 +0000</pubDate>
  <description>arXiv cs.AI - Open-ended self-improving agents can autonomously modify their own structural designs to advance their capabilities and overcome the limits of pre-defined architectures, thus reducing reliance on human intervention. We introduce Group-Evolving Agents (GEA), a new paradigm for open-ended self-improvements, which treats a group of agents as the fundamental evolutionary unit, enabling explicit experi</description>
</item>

<item>
  <title>Safe Urban Traffic Control via Uncertainty-Aware Conformal Prediction and World-Model Reinforcement Learning</title>
  <link>https://arxiv.org/abs/2602.04821v1</link>
  <guid>https://arxiv.org/abs/2602.04821v1</guid>
  <pubDate>Wed, 04 Feb 2026 18:10:59 +0000</pubDate>
  <description>arXiv cs.AI - Urban traffic management demands systems that simultaneously predict future conditions, detect anomalies, and take safe corrective actions -- all while providing reliability guarantees. We present STREAM-RL, a unified framework that introduces three novel algorithmic contributions: (1) PU-GAT+, an Uncertainty-Guided Adaptive Conformal Forecaster that uses prediction uncertainty to dynamically rewe</description>
</item>

<item>
  <title>Safe Urban Traffic Control via Uncertainty-Aware Conformal Prediction and World-Model Reinforcement Learning</title>
  <link>https://arxiv.org/abs/2602.04821v1</link>
  <guid>https://arxiv.org/abs/2602.04821v1</guid>
  <pubDate>Wed, 04 Feb 2026 18:10:59 +0000</pubDate>
  <description>arXiv cs.LG - Urban traffic management demands systems that simultaneously predict future conditions, detect anomalies, and take safe corrective actions -- all while providing reliability guarantees. We present STREAM-RL, a unified framework that introduces three novel algorithmic contributions: (1) PU-GAT+, an Uncertainty-Guided Adaptive Conformal Forecaster that uses prediction uncertainty to dynamically rewe</description>
</item>

<item>
  <title>Agentic AI in Healthcare &amp; Medicine: A Seven-Dimensional Taxonomy for Empirical Evaluation of LLM-based Agents</title>
  <link>https://arxiv.org/abs/2602.04813v1</link>
  <guid>https://arxiv.org/abs/2602.04813v1</guid>
  <pubDate>Wed, 04 Feb 2026 17:59:14 +0000</pubDate>
  <description>arXiv cs.AI - Large Language Model (LLM)-based agents that plan, use tools and act has begun to shape healthcare and medicine. Reported studies demonstrate competence on various tasks ranging from EHR analysis and differential diagnosis to treatment planning and research workflows. Yet the literature largely consists of overviews which are either broad surveys or narrow dives into a single capability (e.g., mem</description>
</item>

<item>
  <title>SE-Bench: Benchmarking Self-Evolution with Knowledge Internalization</title>
  <link>https://arxiv.org/abs/2602.04811v1</link>
  <guid>https://arxiv.org/abs/2602.04811v1</guid>
  <pubDate>Wed, 04 Feb 2026 17:58:32 +0000</pubDate>
  <description>arXiv cs.AI - True self-evolution requires agents to act as lifelong learners that internalize novel experiences to solve future problems. However, rigorously measuring this foundational capability is hindered by two obstacles: the entanglement of prior knowledge, where ``new&apos;&apos; knowledge may appear in pre-training data, and the entanglement of reasoning complexity, where failures may stem from problem difficult</description>
</item>

<item>
  <title>SE-Bench: Benchmarking Self-Evolution with Knowledge Internalization</title>
  <link>https://arxiv.org/abs/2602.04811v1</link>
  <guid>https://arxiv.org/abs/2602.04811v1</guid>
  <pubDate>Wed, 04 Feb 2026 17:58:32 +0000</pubDate>
  <description>arXiv cs.LG - True self-evolution requires agents to act as lifelong learners that internalize novel experiences to solve future problems. However, rigorously measuring this foundational capability is hindered by two obstacles: the entanglement of prior knowledge, where ``new&apos;&apos; knowledge may appear in pre-training data, and the entanglement of reasoning complexity, where failures may stem from problem difficult</description>
</item>

<item>
  <title>Beyond Rewards in Reinforcement Learning for Cyber Defence</title>
  <link>https://arxiv.org/abs/2602.04809v1</link>
  <guid>https://arxiv.org/abs/2602.04809v1</guid>
  <pubDate>Wed, 04 Feb 2026 17:55:23 +0000</pubDate>
  <description>arXiv cs.AI - Recent years have seen an explosion of interest in autonomous cyber defence agents trained to defend computer networks using deep reinforcement learning. These agents are typically trained in cyber gym environments using dense, highly engineered reward functions which combine many penalties and incentives for a range of (un)desirable states and costly actions. Dense rewards help alleviate the chal</description>
</item>

<item>
  <title>Beyond Rewards in Reinforcement Learning for Cyber Defence</title>
  <link>https://arxiv.org/abs/2602.04809v1</link>
  <guid>https://arxiv.org/abs/2602.04809v1</guid>
  <pubDate>Wed, 04 Feb 2026 17:55:23 +0000</pubDate>
  <description>arXiv cs.LG - Recent years have seen an explosion of interest in autonomous cyber defence agents trained to defend computer networks using deep reinforcement learning. These agents are typically trained in cyber gym environments using dense, highly engineered reward functions which combine many penalties and incentives for a range of (un)desirable states and costly actions. Dense rewards help alleviate the chal</description>
</item>

<item>
  <title>Active Asymmetric Multi-Agent Multimodal Learning under Uncertainty</title>
  <link>https://arxiv.org/abs/2602.04763v1</link>
  <guid>https://arxiv.org/abs/2602.04763v1</guid>
  <pubDate>Wed, 04 Feb 2026 17:01:31 +0000</pubDate>
  <description>arXiv cs.AI - Multi-agent systems are increasingly equipped with heterogeneous multimodal sensors, enabling richer perception but introducing modality-specific and agent-dependent uncertainty. Existing multi-agent collaboration frameworks typically reason at the agent level, assume homogeneous sensing, and handle uncertainty implicitly, limiting robustness under sensor corruption. We propose Active Asymmetric M</description>
</item>

<item>
  <title>Understanding and Exploiting Weight Update Sparsity for Communication-Efficient Distributed RL</title>
  <link>https://arxiv.org/abs/2602.03839v1</link>
  <guid>https://arxiv.org/abs/2602.03839v1</guid>
  <pubDate>Tue, 03 Feb 2026 18:56:48 +0000</pubDate>
  <description>arXiv cs.LG - Reinforcement learning (RL) is a critical component for post-training large language models (LLMs). However, in bandwidth-constrained distributed RL, scalability is often bottlenecked by the synchronization of policy weights from trainers to inference workers, particularly over commodity networks or in decentralized settings. While recent studies suggest that RL updates modify only a small fractio</description>
</item>

<item>
  <title>PrevizWhiz: Combining Rough 3D Scenes and 2D Video to Guide Generative Video Previsualization</title>
  <link>https://arxiv.org/abs/2602.03838v1</link>
  <guid>https://arxiv.org/abs/2602.03838v1</guid>
  <pubDate>Tue, 03 Feb 2026 18:56:40 +0000</pubDate>
  <description>arXiv cs.AI - In pre-production, filmmakers and 3D animation experts must rapidly prototype ideas to explore a film&apos;s possibilities before fullscale production, yet conventional approaches involve trade-offs in efficiency and expressiveness. Hand-drawn storyboards often lack spatial precision needed for complex cinematography, while 3D previsualization demands expertise and high-quality rigged assets. To addres</description>
</item>

<item>
  <title>Accelerating Scientific Research with Gemini: Case Studies and Common Techniques</title>
  <link>https://arxiv.org/abs/2602.03837v1</link>
  <guid>https://arxiv.org/abs/2602.03837v1</guid>
  <pubDate>Tue, 03 Feb 2026 18:56:17 +0000</pubDate>
  <description>arXiv cs.AI - Recent advances in large language models (LLMs) have opened new avenues for accelerating scientific research. While models are increasingly capable of assisting with routine tasks, their ability to contribute to novel, expert-level mathematical discovery is less understood. We present a collection of case studies demonstrating how researchers have successfully collaborated with advanced AI models,</description>
</item>

<item>
  <title>AutoFigure: Generating and Refining Publication-Ready Scientific Illustrations</title>
  <link>https://arxiv.org/abs/2602.03828v1</link>
  <guid>https://arxiv.org/abs/2602.03828v1</guid>
  <pubDate>Tue, 03 Feb 2026 18:41:43 +0000</pubDate>
  <description>arXiv cs.AI - High-quality scientific illustrations are crucial for effectively communicating complex scientific and technical concepts, yet their manual creation remains a well-recognized bottleneck in both academia and industry. We present FigureBench, the first large-scale benchmark for generating scientific illustrations from long-form scientific texts. It contains 3,300 high-quality scientific text-figure </description>
</item>

<item>
  <title>SymPlex: A Structure-Aware Transformer for Symbolic PDE Solving</title>
  <link>https://arxiv.org/abs/2602.03816v1</link>
  <guid>https://arxiv.org/abs/2602.03816v1</guid>
  <pubDate>Tue, 03 Feb 2026 18:18:30 +0000</pubDate>
  <description>arXiv cs.LG - We propose SymPlex, a reinforcement learning framework for discovering analytical symbolic solutions to partial differential equations (PDEs) without access to ground-truth expressions. SymPlex formulates symbolic PDE solving as tree-structured decision-making and optimizes candidate solutions using only the PDE and its boundary conditions. At its core is SymFormer, a structure-aware Transformer t</description>
</item>

<item>
  <title>Understanding Agent Scaling in LLM-Based Multi-Agent Systems via Diversity</title>
  <link>https://arxiv.org/abs/2602.03794v1</link>
  <guid>https://arxiv.org/abs/2602.03794v1</guid>
  <pubDate>Tue, 03 Feb 2026 17:58:10 +0000</pubDate>
  <description>arXiv cs.AI - LLM-based multi-agent systems (MAS) have emerged as a promising approach to tackle complex tasks that are difficult for individual LLMs. A natural strategy is to scale performance by increasing the number of agents; however, we find that such scaling exhibits strong diminishing returns in homogeneous settings, while introducing heterogeneity (e.g., different models, prompts, or tools) continues to</description>
</item>

<item>
  <title>Understanding Agent Scaling in LLM-Based Multi-Agent Systems via Diversity</title>
  <link>https://arxiv.org/abs/2602.03794v1</link>
  <guid>https://arxiv.org/abs/2602.03794v1</guid>
  <pubDate>Tue, 03 Feb 2026 17:58:10 +0000</pubDate>
  <description>arXiv cs.LG - LLM-based multi-agent systems (MAS) have emerged as a promising approach to tackle complex tasks that are difficult for individual LLMs. A natural strategy is to scale performance by increasing the number of agents; however, we find that such scaling exhibits strong diminishing returns in homogeneous settings, while introducing heterogeneity (e.g., different models, prompts, or tools) continues to</description>
</item>

<item>
  <title>WebSentinel: Detecting and Localizing Prompt Injection Attacks for Web Agents</title>
  <link>https://arxiv.org/abs/2602.03792v1</link>
  <guid>https://arxiv.org/abs/2602.03792v1</guid>
  <pubDate>Tue, 03 Feb 2026 17:55:04 +0000</pubDate>
  <description>arXiv cs.AI - Prompt injection attacks manipulate webpage content to cause web agents to execute attacker-specified tasks instead of the user&apos;s intended ones. Existing methods for detecting and localizing such attacks achieve limited effectiveness, as their underlying assumptions often do not hold in the web-agent setting. In this work, we propose WebSentinel, a two-step approach for detecting and localizing pr</description>
</item>

<item>
  <title>AOrchestra: Automating Sub-Agent Creation for Agentic Orchestration</title>
  <link>https://arxiv.org/abs/2602.03786v1</link>
  <guid>https://arxiv.org/abs/2602.03786v1</guid>
  <pubDate>Tue, 03 Feb 2026 17:46:16 +0000</pubDate>
  <description>arXiv cs.AI - Language agents have shown strong promise for task automation. Realizing this promise for increasingly complex, long-horizon tasks has driven the rise of a sub-agent-as-tools paradigm for multi-turn task solving. However, existing designs still lack a dynamic abstraction view of sub-agents, thereby hurting adaptability. We address this challenge with a unified, framework-agnostic agent abstraction</description>
</item>

<item>
  <title>Efficient Estimation of Kernel Surrogate Models for Task Attribution</title>
  <link>https://arxiv.org/abs/2602.03783v1</link>
  <guid>https://arxiv.org/abs/2602.03783v1</guid>
  <pubDate>Tue, 03 Feb 2026 17:43:48 +0000</pubDate>
  <description>arXiv cs.AI - Modern AI agents such as large language models are trained on diverse tasks -- translation, code generation, mathematical reasoning, and text prediction -- simultaneously. A key question is to quantify how each individual training task influences performance on a target task, a problem we refer to as task attribution. The direct approach, leave-one-out retraining, measures the effect of removing e</description>
</item>

<item>
  <title>Efficient Estimation of Kernel Surrogate Models for Task Attribution</title>
  <link>https://arxiv.org/abs/2602.03783v1</link>
  <guid>https://arxiv.org/abs/2602.03783v1</guid>
  <pubDate>Tue, 03 Feb 2026 17:43:48 +0000</pubDate>
  <description>arXiv cs.LG - Modern AI agents such as large language models are trained on diverse tasks -- translation, code generation, mathematical reasoning, and text prediction -- simultaneously. A key question is to quantify how each individual training task influences performance on a target task, a problem we refer to as task attribution. The direct approach, leave-one-out retraining, measures the effect of removing e</description>
</item>

<item>
  <title>DiffLOB: Diffusion Models for Counterfactual Generation in Limit Order Books</title>
  <link>https://arxiv.org/abs/2602.03776v1</link>
  <guid>https://arxiv.org/abs/2602.03776v1</guid>
  <pubDate>Tue, 03 Feb 2026 17:34:56 +0000</pubDate>
  <description>arXiv cs.AI - Modern generative models for limit order books (LOBs) can reproduce realistic market dynamics, but remain fundamentally passive: they either model what typically happens without accounting for hypothetical future market conditions, or they require interaction with another agent to explore alternative outcomes. This limits their usefulness for stress testing, scenario analysis, and decision-making.</description>
</item>

<item>
  <title>An Empirical Study of Collective Behaviors and Social Dynamics in Large Language Model Agents</title>
  <link>https://arxiv.org/abs/2602.03775v1</link>
  <guid>https://arxiv.org/abs/2602.03775v1</guid>
  <pubDate>Tue, 03 Feb 2026 17:34:32 +0000</pubDate>
  <description>arXiv cs.AI - Large Language Models (LLMs) increasingly mediate our social, cultural, and political interactions. While they can simulate some aspects of human behavior and decision-making, it is still underexplored whether repeated interactions with other agents amplify their biases or lead to exclusionary behaviors. To this end, we study Chirper.ai-an LLM-driven social media platform-analyzing 7M posts and in</description>
</item>

<item>
  <title>Reasoning Cache: Continual Improvement Over Long Horizons via Short-Horizon RL</title>
  <link>https://arxiv.org/abs/2602.03773v1</link>
  <guid>https://arxiv.org/abs/2602.03773v1</guid>
  <pubDate>Tue, 03 Feb 2026 17:34:04 +0000</pubDate>
  <description>arXiv cs.LG - Large Language Models (LLMs) that can continually improve beyond their training budgets are able to solve increasingly difficult problems by adapting at test time, a property we refer to as extrapolation. However, standard reinforcement learning (RL) operates over fixed problem distributions and training budgets, which limits extrapolation amidst distribution shift at test time. To address this, w</description>
</item>

<item>
  <title>Zero-shot large vision-language model prompting for automated bone identification in paleoradiology x-ray archives</title>
  <link>https://arxiv.org/abs/2602.03750v1</link>
  <guid>https://arxiv.org/abs/2602.03750v1</guid>
  <pubDate>Tue, 03 Feb 2026 17:14:23 +0000</pubDate>
  <description>arXiv cs.AI - Paleoradiology, the use of modern imaging technologies to study archaeological and anthropological remains, offers new windows on millennial scale patterns of human health. Unfortunately, the radiographs collected during field campaigns are heterogeneous: bones are disarticulated, positioning is ad hoc, and laterality markers are often absent. Additionally, factors such as age at death, age of bon</description>
</item>

<item>
  <title>Cognitively Diverse Multiple-Choice Question Generation: A Hybrid Multi-Agent Framework with Large Language Models</title>
  <link>https://arxiv.org/abs/2602.03704v1</link>
  <guid>https://arxiv.org/abs/2602.03704v1</guid>
  <pubDate>Tue, 03 Feb 2026 16:26:47 +0000</pubDate>
  <description>arXiv cs.AI - Recent advances in large language models (LLMs) have made automated multiple-choice question (MCQ) generation increasingly feasible; however, reliably producing items that satisfy controlled cognitive demands remains a challenge. To address this gap, we introduce ReQUESTA, a hybrid, multi-agent framework for generating cognitively diverse MCQs that systematically target text-based, inferential, an</description>
</item>

<item>
  <title>Agent Primitives: Reusable Latent Building Blocks for Multi-Agent Systems</title>
  <link>https://arxiv.org/abs/2602.03695v1</link>
  <guid>https://arxiv.org/abs/2602.03695v1</guid>
  <pubDate>Tue, 03 Feb 2026 16:17:53 +0000</pubDate>
  <description>arXiv cs.AI - While existing multi-agent systems (MAS) can handle complex problems by enabling collaboration among multiple agents, they are often highly task-specific, relying on manually crafted agent roles and interaction prompts, which leads to increased architectural complexity and limited reusability across tasks. Moreover, most MAS communicate primarily through natural language, making them vulnerable to</description>
</item>

<item>
  <title>MEG-XL: Data-Efficient Brain-to-Text via Long-Context Pre-Training</title>
  <link>https://arxiv.org/abs/2602.02494v1</link>
  <guid>https://arxiv.org/abs/2602.02494v1</guid>
  <pubDate>Mon, 02 Feb 2026 18:59:50 +0000</pubDate>
  <description>arXiv cs.LG - Clinical brain-to-text interfaces are designed for paralysed patients who cannot provide extensive training recordings. Pre-training improves data-efficient generalisation by learning statistical priors across subjects, but these priors critically depend on context. While natural speech might unfold gradually over minutes, most methods pre-train with only a few seconds of context. Thus, we propose</description>
</item>

<item>
  <title>RLAnything: Forge Environment, Policy, and Reward Model in Completely Dynamic RL System</title>
  <link>https://arxiv.org/abs/2602.02488v1</link>
  <guid>https://arxiv.org/abs/2602.02488v1</guid>
  <pubDate>Mon, 02 Feb 2026 18:59:04 +0000</pubDate>
  <description>arXiv cs.LG - We propose RLAnything, a reinforcement learning framework that dynamically forges environment, policy, and reward models through closed-loop optimization, amplifying learning signals and strengthening the overall RL system for any LLM or agentic scenarios. Specifically, the policy is trained with integrated feedback from step-wise and outcome signals, while the reward model is jointly optimized vi</description>
</item>

</channel>
</rss>
