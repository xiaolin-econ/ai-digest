<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
<channel>
  <title>AI Research Digest</title>
  <link>https://xiaolin-econ.github.io/ai-digest/</link>
  <description>Curated AI research + releases</description>
  <lastBuildDate>Mon, 09 Feb 2026 18:44:54 +0000</lastBuildDate>
  <atom:link href="https://xiaolin-econ.github.io/ai-digest/rss.xml" rel="self" type="application/rss+xml" xmlns:atom="http://www.w3.org/2005/Atom"/>
  
<item>
  <title>AI Digest — Daily Summary</title>
  <link>https://xiaolin-econ.github.io/ai-digest/rss.xml</link>
  <guid>https://xiaolin-econ.github.io/ai-digest/rss.xml#summary</guid>
  <pubDate>Mon, 09 Feb 2026 18:44:54 +0000</pubDate>
  <description>Addressing class imbalance is a central challenge in credit card fraud detection, as it directly impacts predictive reliability in real-world financial systems. To overcome this, the study proposes an enhanced workflow based on the Explainable Boosting Machine (EBM)-a transparent, state-of-the-art implementation of the GA2M algorithm-optimized through systematic hyperparameter tuning, feature selection, and preprocessing refinement. Rather than relying on conventional sampling techniques that may introduce bias or cause information loss, the optimized EBM achieves an effective balance between accuracy and interpretability, enabling precise detection of fraudulent transactions while providing actionable insights into feature importance and interaction effects. Furthermore, the Taguchi…</description>
</item>

<item>
  <title>Improving Credit Card Fraud Detection with an Optimized Explainable Boosting Machine</title>
  <link>https://arxiv.org/abs/2602.06955v1</link>
  <guid>https://arxiv.org/abs/2602.06955v1</guid>
  <pubDate>Fri, 06 Feb 2026 18:56:17 +0000</pubDate>
  <description>arXiv cs.LG - Addressing class imbalance is a central challenge in credit card fraud detection, as it directly impacts predictive reliability in real-world financial systems. To overcome this, the study proposes an enhanced workflow based on the Explainable Boosting Machine (EBM)-a transparent, state-of-the-art implementation of the GA2M algorithm-optimized through systematic hyperparameter tuning, feature sele</description>
</item>

<item>
  <title>DreamDojo: A Generalist Robot World Model from Large-Scale Human Videos</title>
  <link>https://arxiv.org/abs/2602.06949v1</link>
  <guid>https://arxiv.org/abs/2602.06949v1</guid>
  <pubDate>Fri, 06 Feb 2026 18:49:43 +0000</pubDate>
  <description>arXiv cs.AI - Being able to simulate the outcomes of actions in varied environments will revolutionize the development of generalist agents at scale. However, modeling these world dynamics, especially for dexterous robotics tasks, poses significant challenges due to limited data coverage and scarce action labels. As an endeavor towards this end, we introduce DreamDojo, a foundation world model that learns diver</description>
</item>

<item>
  <title>DreamDojo: A Generalist Robot World Model from Large-Scale Human Videos</title>
  <link>https://arxiv.org/abs/2602.06949v1</link>
  <guid>https://arxiv.org/abs/2602.06949v1</guid>
  <pubDate>Fri, 06 Feb 2026 18:49:43 +0000</pubDate>
  <description>arXiv cs.LG - Being able to simulate the outcomes of actions in varied environments will revolutionize the development of generalist agents at scale. However, modeling these world dynamics, especially for dexterous robotics tasks, poses significant challenges due to limited data coverage and scarce action labels. As an endeavor towards this end, we introduce DreamDojo, a foundation world model that learns diver</description>
</item>

<item>
  <title>Agentic Uncertainty Reveals Agentic Overconfidence</title>
  <link>https://arxiv.org/abs/2602.06948v1</link>
  <guid>https://arxiv.org/abs/2602.06948v1</guid>
  <pubDate>Fri, 06 Feb 2026 18:49:35 +0000</pubDate>
  <description>arXiv cs.AI - Can AI agents predict whether they will succeed at a task? We study agentic uncertainty by eliciting success probability estimates before, during, and after task execution. All results exhibit agentic overconfidence: some agents that succeed only 22% of the time predict 77% success. Counterintuitively, pre-execution assessment with strictly less information tends to yield better discrimination tha</description>
</item>

<item>
  <title>Agentic Uncertainty Reveals Agentic Overconfidence</title>
  <link>https://arxiv.org/abs/2602.06948v1</link>
  <guid>https://arxiv.org/abs/2602.06948v1</guid>
  <pubDate>Fri, 06 Feb 2026 18:49:35 +0000</pubDate>
  <description>arXiv cs.LG - Can AI agents predict whether they will succeed at a task? We study agentic uncertainty by eliciting success probability estimates before, during, and after task execution. All results exhibit agentic overconfidence: some agents that succeed only 22% of the time predict 77% success. Counterintuitively, pre-execution assessment with strictly less information tends to yield better discrimination tha</description>
</item>

<item>
  <title>Reciprocal Latent Fields for Precomputed Sound Propagation</title>
  <link>https://arxiv.org/abs/2602.06937v1</link>
  <guid>https://arxiv.org/abs/2602.06937v1</guid>
  <pubDate>Fri, 06 Feb 2026 18:31:11 +0000</pubDate>
  <description>arXiv cs.LG - Realistic sound propagation is essential for immersion in a virtual scene, yet physically accurate wave-based simulations remain computationally prohibitive for real-time applications. Wave coding methods address this limitation by precomputing and compressing impulse responses of a given scene into a set of scalar acoustic parameters, which can reach unmanageable sizes in large environments with </description>
</item>

<item>
  <title>Implementing Grassroots Logic Programs with Multiagent Transition Systems and AI</title>
  <link>https://arxiv.org/abs/2602.06934v1</link>
  <guid>https://arxiv.org/abs/2602.06934v1</guid>
  <pubDate>Fri, 06 Feb 2026 18:30:11 +0000</pubDate>
  <description>arXiv cs.AI - Grassroots Logic Programs (GLP) is a concurrent logic programming language with variables partitioned into paired \emph{readers} and \emph{writers}, conjuring both linear logic and futures/promises: an assignment is produced at most once via the sole occurrence of a writer (promise) and consumed at most once via the sole occurrence of its paired reader (future), and may contain additional readers </description>
</item>

<item>
  <title>When RL Meets Adaptive Speculative Training: A Unified Training-Serving System</title>
  <link>https://arxiv.org/abs/2602.06932v1</link>
  <guid>https://arxiv.org/abs/2602.06932v1</guid>
  <pubDate>Fri, 06 Feb 2026 18:28:54 +0000</pubDate>
  <description>arXiv cs.LG - Speculative decoding can significantly accelerate LLM serving, yet most deployments today disentangle speculator training from serving, treating speculator training as a standalone offline modeling problem. We show that this decoupled formulation introduces substantial deployment and adaptation lag: (1) high time-to-serve, since a speculator must be trained offline for a considerable period before</description>
</item>

<item>
  <title>From Kepler to Newton: Inductive Biases Guide Learned World Models in Transformers</title>
  <link>https://arxiv.org/abs/2602.06923v1</link>
  <guid>https://arxiv.org/abs/2602.06923v1</guid>
  <pubDate>Fri, 06 Feb 2026 18:17:37 +0000</pubDate>
  <description>arXiv cs.AI - Can general-purpose AI architectures go beyond prediction to discover the physical laws governing the universe? True intelligence relies on &quot;world models&quot; -- causal abstractions that allow an agent to not only predict future states but understand the underlying governing dynamics. While previous &quot;AI Physicist&quot; approaches have successfully recovered such laws, they typically rely on strong, domain-</description>
</item>

<item>
  <title>From Kepler to Newton: Inductive Biases Guide Learned World Models in Transformers</title>
  <link>https://arxiv.org/abs/2602.06923v1</link>
  <guid>https://arxiv.org/abs/2602.06923v1</guid>
  <pubDate>Fri, 06 Feb 2026 18:17:37 +0000</pubDate>
  <description>arXiv cs.LG - Can general-purpose AI architectures go beyond prediction to discover the physical laws governing the universe? True intelligence relies on &quot;world models&quot; -- causal abstractions that allow an agent to not only predict future states but understand the underlying governing dynamics. While previous &quot;AI Physicist&quot; approaches have successfully recovered such laws, they typically rely on strong, domain-</description>
</item>

<item>
  <title>TraceCoder: A Trace-Driven Multi-Agent Framework for Automated Debugging of LLM-Generated Code</title>
  <link>https://arxiv.org/abs/2602.06875v1</link>
  <guid>https://arxiv.org/abs/2602.06875v1</guid>
  <pubDate>Fri, 06 Feb 2026 16:59:48 +0000</pubDate>
  <description>arXiv cs.AI - Large Language Models (LLMs) often generate code with subtle but critical bugs, especially for complex tasks. Existing automated repair methods typically rely on superficial pass/fail signals, offering limited visibility into program behavior and hindering precise error localization. In addition, without a way to learn from prior failures, repair processes often fall into repetitive and inefficien</description>
</item>

<item>
  <title>AIRS-Bench: a Suite of Tasks for Frontier AI Research Science Agents</title>
  <link>https://arxiv.org/abs/2602.06855v1</link>
  <guid>https://arxiv.org/abs/2602.06855v1</guid>
  <pubDate>Fri, 06 Feb 2026 16:45:02 +0000</pubDate>
  <description>arXiv cs.AI - LLM agents hold significant promise for advancing scientific research. To accelerate this progress, we introduce AIRS-Bench (the AI Research Science Benchmark), a suite of 20 tasks sourced from state-of-the-art machine learning papers. These tasks span diverse domains, including language modeling, mathematics, bioinformatics, and time series forecasting. AIRS-Bench tasks assess agentic capabilitie</description>
</item>

<item>
  <title>From Features to Actions: Explainability in Traditional and Agentic AI Systems</title>
  <link>https://arxiv.org/abs/2602.06841v1</link>
  <guid>https://arxiv.org/abs/2602.06841v1</guid>
  <pubDate>Fri, 06 Feb 2026 16:34:29 +0000</pubDate>
  <description>arXiv cs.AI - Over the last decade, explainable AI has primarily focused on interpreting individual model predictions, producing post-hoc explanations that relate inputs to outputs under a fixed decision structure. Recent advances in large language models (LLMs) have enabled agentic AI systems whose behaviour unfolds over multi-step trajectories. In these settings, success and failure are determined by sequence</description>
</item>

<item>
  <title>LLM Active Alignment: A Nash Equilibrium Perspective</title>
  <link>https://arxiv.org/abs/2602.06836v1</link>
  <guid>https://arxiv.org/abs/2602.06836v1</guid>
  <pubDate>Fri, 06 Feb 2026 16:26:03 +0000</pubDate>
  <description>arXiv cs.AI - We develop a game-theoretic framework for predicting and steering the behavior of populations of large language models (LLMs) through Nash equilibrium (NE) analysis. To avoid the intractability of equilibrium computation in open-ended text spaces, we model each agent&apos;s action as a mixture over human subpopulations. Agents choose actively and strategically which groups to align with, yielding an in</description>
</item>

<item>
  <title>DyTopo: Dynamic Topology Routing for Multi-Agent Reasoning via Semantic Matching</title>
  <link>https://arxiv.org/abs/2602.06039v1</link>
  <guid>https://arxiv.org/abs/2602.06039v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:59:51 +0000</pubDate>
  <description>arXiv cs.AI - Multi-agent systems built from prompted large language models can improve multi-round reasoning, yet most existing pipelines rely on fixed, trajectory-wide communication patterns that are poorly matched to the stage-dependent needs of iterative problem solving. We introduce DyTopo, a manager-guided multi-agent framework that reconstructs a sparse directed communication graph at each round. Conditi</description>
</item>

<item>
  <title>CommCP: Efficient Multi-Agent Coordination via LLM-Based Communication with Conformal Prediction</title>
  <link>https://arxiv.org/abs/2602.06038v1</link>
  <guid>https://arxiv.org/abs/2602.06038v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:59:45 +0000</pubDate>
  <description>arXiv cs.AI - To complete assignments provided by humans in natural language, robots must interpret commands, generate and answer relevant questions for scene understanding, and manipulate target objects. Real-world deployments often require multiple heterogeneous robots with different manipulation capabilities to handle different assignments cooperatively. Beyond the need for specialized manipulation skills, e</description>
</item>

<item>
  <title>CommCP: Efficient Multi-Agent Coordination via LLM-Based Communication with Conformal Prediction</title>
  <link>https://arxiv.org/abs/2602.06038v1</link>
  <guid>https://arxiv.org/abs/2602.06038v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:59:45 +0000</pubDate>
  <description>arXiv cs.LG - To complete assignments provided by humans in natural language, robots must interpret commands, generate and answer relevant questions for scene understanding, and manipulate target objects. Real-world deployments often require multiple heterogeneous robots with different manipulation capabilities to handle different assignments cooperatively. Beyond the need for specialized manipulation skills, e</description>
</item>

<item>
  <title>PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling</title>
  <link>https://arxiv.org/abs/2602.06030v1</link>
  <guid>https://arxiv.org/abs/2602.06030v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:59:01 +0000</pubDate>
  <description>arXiv cs.LG - Large language model (LLM)-based multi-agent systems enable expressive agent reasoning but are expensive to scale and poorly calibrated for timestep-aligned state-transition simulation, while classical agent-based models (ABMs) offer interpretability but struggle to integrate rich individual-level signals and non-stationary behaviors. We propose PhysicsAgentABM, which shifts inference to behaviora</description>
</item>

<item>
  <title>Curiosity is Knowledge: Self-Consistent Learning and No-Regret Optimization with Active Inference</title>
  <link>https://arxiv.org/abs/2602.06029v1</link>
  <guid>https://arxiv.org/abs/2602.06029v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:58:32 +0000</pubDate>
  <description>arXiv cs.LG - Active inference (AIF) unifies exploration and exploitation by minimizing the Expected Free Energy (EFE), balancing epistemic value (information gain) and pragmatic value (task performance) through a curiosity coefficient. Yet it has been unclear when this balance yields both coherent learning and efficient decision-making: insufficient curiosity can drive myopic exploitation and prevent uncertain</description>
</item>

<item>
  <title>Learning Query-Aware Budget-Tier Routing for Runtime Agent Memory</title>
  <link>https://arxiv.org/abs/2602.06025v1</link>
  <guid>https://arxiv.org/abs/2602.06025v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:57:09 +0000</pubDate>
  <description>arXiv cs.AI - Memory is increasingly central to Large Language Model (LLM) agents operating beyond a single context window, yet most existing systems rely on offline, query-agnostic memory construction that can be inefficient and may discard query-critical information. Although runtime memory utilization is a natural alternative, prior work often incurs substantial overhead and offers limited explicit control o</description>
</item>

<item>
  <title>Learning Query-Aware Budget-Tier Routing for Runtime Agent Memory</title>
  <link>https://arxiv.org/abs/2602.06025v1</link>
  <guid>https://arxiv.org/abs/2602.06025v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:57:09 +0000</pubDate>
  <description>arXiv cs.LG - Memory is increasingly central to Large Language Model (LLM) agents operating beyond a single context window, yet most existing systems rely on offline, query-agnostic memory construction that can be inefficient and may discard query-critical information. Although runtime memory utilization is a natural alternative, prior work often incurs substantial overhead and offers limited explicit control o</description>
</item>

<item>
  <title>Learning Event-Based Shooter Models from Virtual Reality Experiments</title>
  <link>https://arxiv.org/abs/2602.06023v1</link>
  <guid>https://arxiv.org/abs/2602.06023v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:56:49 +0000</pubDate>
  <description>arXiv cs.AI - Virtual reality (VR) has emerged as a powerful tool for evaluating school security measures in high-risk scenarios such as school shootings, offering experimental control and high behavioral fidelity. However, assessing new interventions in VR requires recruiting new participant cohorts for each condition, making large-scale or iterative evaluation difficult. These limitations are especially restr</description>
</item>

<item>
  <title>Multi-Token Prediction via Self-Distillation</title>
  <link>https://arxiv.org/abs/2602.06019v1</link>
  <guid>https://arxiv.org/abs/2602.06019v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:54:48 +0000</pubDate>
  <description>arXiv cs.LG - Existing techniques for accelerating language model inference, such as speculative decoding, require training auxiliary speculator models and building and deploying complex inference pipelines. We consider a new approach for converting a pretrained autoregressive language model from a slow single next token prediction model into a fast standalone multi-token prediction model using a simple online </description>
</item>

<item>
  <title>AgenticPay: A Multi-Agent LLM Negotiation System for Buyer-Seller Transactions</title>
  <link>https://arxiv.org/abs/2602.06008v1</link>
  <guid>https://arxiv.org/abs/2602.06008v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:50:36 +0000</pubDate>
  <description>arXiv cs.AI - Large language model (LLM)-based agents are increasingly expected to negotiate, coordinate, and transact autonomously, yet existing benchmarks lack principled settings for evaluating language-mediated economic interaction among multiple agents. We introduce AgenticPay, a benchmark and simulation framework for multi-agent buyer-seller negotiation driven by natural language. AgenticPay models market</description>
</item>

<item>
  <title>AgenticPay: A Multi-Agent LLM Negotiation System for Buyer-Seller Transactions</title>
  <link>https://arxiv.org/abs/2602.06008v1</link>
  <guid>https://arxiv.org/abs/2602.06008v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:50:36 +0000</pubDate>
  <description>arXiv cs.LG - Large language model (LLM)-based agents are increasingly expected to negotiate, coordinate, and transact autonomously, yet existing benchmarks lack principled settings for evaluating language-mediated economic interaction among multiple agents. We introduce AgenticPay, a benchmark and simulation framework for multi-agent buyer-seller negotiation driven by natural language. AgenticPay models market</description>
</item>

<item>
  <title>Layer-wise LoRA fine-tuning: a similarity metric approach</title>
  <link>https://arxiv.org/abs/2602.05988v1</link>
  <guid>https://arxiv.org/abs/2602.05988v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:38:53 +0000</pubDate>
  <description>arXiv cs.LG - Pre-training Large Language Models (LLMs) on web-scale datasets becomes fundamental for advancing general-purpose AI. In contrast, enhancing their predictive performance on downstream tasks typically involves adapting their knowledge through fine-tuning. Parameter-efficient fine-tuning techniques, such as Low-Rank Adaptation (LoRA), aim to reduce the computational cost of this process by freezing </description>
</item>

<item>
  <title>Learning to Share: Selective Memory for Efficient Parallel Agentic Systems</title>
  <link>https://arxiv.org/abs/2602.05965v1</link>
  <guid>https://arxiv.org/abs/2602.05965v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:20:21 +0000</pubDate>
  <description>arXiv cs.AI - Agentic systems solve complex tasks by coordinating multiple agents that iteratively reason, invoke tools, and exchange intermediate results. To improve robustness and solution quality, recent approaches deploy multiple agent teams running in parallel to explore diverse reasoning trajectories. However, parallel execution comes at a significant computational cost: when different teams independently</description>
</item>

<item>
  <title>Compound Deception in Elite Peer Review: A Failure Mode Taxonomy of 100 Fabricated Citations at NeurIPS 2025</title>
  <link>https://arxiv.org/abs/2602.05930v1</link>
  <guid>https://arxiv.org/abs/2602.05930v1</guid>
  <pubDate>Thu, 05 Feb 2026 17:43:35 +0000</pubDate>
  <description>arXiv cs.AI - Large language models (LLMs) are increasingly used in academic writing workflows, yet they frequently hallucinate by generating citations to sources that do not exist. This study analyzes 100 AI-generated hallucinated citations that appeared in papers accepted by the 2025 Conference on Neural Information Processing Systems (NeurIPS), one of the world&apos;s most prestigious AI conferences. Despite revi</description>
</item>

<item>
  <title>Quantum Reinforcement Learning with Transformers for the Capacitated Vehicle Routing Problem</title>
  <link>https://arxiv.org/abs/2602.05920v1</link>
  <guid>https://arxiv.org/abs/2602.05920v1</guid>
  <pubDate>Thu, 05 Feb 2026 17:32:14 +0000</pubDate>
  <description>arXiv cs.AI - This paper addresses the Capacitated Vehicle Routing Problem (CVRP) by comparing classical and quantum Reinforcement Learning (RL) approaches. An Advantage Actor-Critic (A2C) agent is implemented in classical, full quantum, and hybrid variants, integrating transformer architectures to capture the relationships between vehicles, clients, and the depot through self- and cross-attention mechanisms. T</description>
</item>

<item>
  <title>Parity, Sensitivity, and Transformers</title>
  <link>https://arxiv.org/abs/2602.05896v1</link>
  <guid>https://arxiv.org/abs/2602.05896v1</guid>
  <pubDate>Thu, 05 Feb 2026 17:14:33 +0000</pubDate>
  <description>arXiv cs.AI - The transformer architecture is almost a decade old. Despite that, we still have a limited understanding of what this architecture can or cannot compute. For instance, can a 1-layer transformer solve PARITY -- or more generally -- which kinds of transformers can do it? Known constructions for PARITY have at least 2 layers and employ impractical features: either a length-dependent positional encodi</description>
</item>

<item>
  <title>Metric Hedonic Games on the Line</title>
  <link>https://arxiv.org/abs/2602.05888v1</link>
  <guid>https://arxiv.org/abs/2602.05888v1</guid>
  <pubDate>Thu, 05 Feb 2026 17:05:08 +0000</pubDate>
  <description>arXiv cs.AI - Hedonic games are fundamental models for investigating the formation of coalitions among a set of strategic agents, where every agent has a certain utility for every possible coalition of agents it can be part of. To avoid the intractability of defining exponentially many utilities for all possible coalitions, many variants with succinct representations of the agents&apos; utility functions have been d</description>
</item>

<item>
  <title>CRoSS: A Continual Robotic Simulation Suite for Scalable Reinforcement Learning with High Task Diversity and Realistic Physics Simulation</title>
  <link>https://arxiv.org/abs/2602.04868v1</link>
  <guid>https://arxiv.org/abs/2602.04868v1</guid>
  <pubDate>Wed, 04 Feb 2026 18:54:26 +0000</pubDate>
  <description>arXiv cs.AI - Continual reinforcement learning (CRL) requires agents to learn from a sequence of tasks without forgetting previously acquired policies. In this work, we introduce a novel benchmark suite for CRL based on realistically simulated robots in the Gazebo simulator. Our Continual Robotic Simulation Suite (CRoSS) benchmarks rely on two robotic platforms: a two-wheeled differential-drive robot with lidar</description>
</item>

<item>
  <title>CRoSS: A Continual Robotic Simulation Suite for Scalable Reinforcement Learning with High Task Diversity and Realistic Physics Simulation</title>
  <link>https://arxiv.org/abs/2602.04868v1</link>
  <guid>https://arxiv.org/abs/2602.04868v1</guid>
  <pubDate>Wed, 04 Feb 2026 18:54:26 +0000</pubDate>
  <description>arXiv cs.LG - Continual reinforcement learning (CRL) requires agents to learn from a sequence of tasks without forgetting previously acquired policies. In this work, we introduce a novel benchmark suite for CRL based on realistically simulated robots in the Gazebo simulator. Our Continual Robotic Simulation Suite (CRoSS) benchmarks rely on two robotic platforms: a two-wheeled differential-drive robot with lidar</description>
</item>

<item>
  <title>El Agente Quntur: A research collaborator agent for quantum chemistry</title>
  <link>https://arxiv.org/abs/2602.04850v1</link>
  <guid>https://arxiv.org/abs/2602.04850v1</guid>
  <pubDate>Wed, 04 Feb 2026 18:38:50 +0000</pubDate>
  <description>arXiv cs.AI - Quantum chemistry is a foundational enabling tool for the fields of chemistry, materials science, computational biology and others. Despite of its power, the practical application of quantum chemistry simulations remains in the hands of qualified experts due to methodological complexity, software heterogeneity, and the need for informed interpretation of results. To bridge the accessibility gap fo</description>
</item>

<item>
  <title>El Agente Estructural: An Artificially Intelligent Molecular Editor</title>
  <link>https://arxiv.org/abs/2602.04849v1</link>
  <guid>https://arxiv.org/abs/2602.04849v1</guid>
  <pubDate>Wed, 04 Feb 2026 18:38:48 +0000</pubDate>
  <description>arXiv cs.AI - We present El Agente Estructural, a multimodal, natural-language-driven geometry-generation and manipulation agent for autonomous chemistry and molecular modelling. Unlike molecular generation or editing via generative models, Estructural mimics how human experts directly manipulate molecular systems in three dimensions by integrating a comprehensive set of domain-informed tools and vision-languag</description>
</item>

<item>
  <title>Fluid Representations in Reasoning Models</title>
  <link>https://arxiv.org/abs/2602.04843v1</link>
  <guid>https://arxiv.org/abs/2602.04843v1</guid>
  <pubDate>Wed, 04 Feb 2026 18:34:50 +0000</pubDate>
  <description>arXiv cs.AI - Reasoning language models, which generate long chains of thought, dramatically outperform non-reasoning language models on abstract problems. However, the internal model mechanisms that allow this superior performance remain poorly understood. We present a mechanistic analysis of how QwQ-32B - a model specifically trained to produce extensive reasoning traces - process abstract structural informat</description>
</item>

<item>
  <title>Group-Evolving Agents: Open-Ended Self-Improvement via Experience Sharing</title>
  <link>https://arxiv.org/abs/2602.04837v1</link>
  <guid>https://arxiv.org/abs/2602.04837v1</guid>
  <pubDate>Wed, 04 Feb 2026 18:29:36 +0000</pubDate>
  <description>arXiv cs.AI - Open-ended self-improving agents can autonomously modify their own structural designs to advance their capabilities and overcome the limits of pre-defined architectures, thus reducing reliance on human intervention. We introduce Group-Evolving Agents (GEA), a new paradigm for open-ended self-improvements, which treats a group of agents as the fundamental evolutionary unit, enabling explicit experi</description>
</item>

<item>
  <title>Safe Urban Traffic Control via Uncertainty-Aware Conformal Prediction and World-Model Reinforcement Learning</title>
  <link>https://arxiv.org/abs/2602.04821v1</link>
  <guid>https://arxiv.org/abs/2602.04821v1</guid>
  <pubDate>Wed, 04 Feb 2026 18:10:59 +0000</pubDate>
  <description>arXiv cs.AI - Urban traffic management demands systems that simultaneously predict future conditions, detect anomalies, and take safe corrective actions -- all while providing reliability guarantees. We present STREAM-RL, a unified framework that introduces three novel algorithmic contributions: (1) PU-GAT+, an Uncertainty-Guided Adaptive Conformal Forecaster that uses prediction uncertainty to dynamically rewe</description>
</item>

<item>
  <title>Safe Urban Traffic Control via Uncertainty-Aware Conformal Prediction and World-Model Reinforcement Learning</title>
  <link>https://arxiv.org/abs/2602.04821v1</link>
  <guid>https://arxiv.org/abs/2602.04821v1</guid>
  <pubDate>Wed, 04 Feb 2026 18:10:59 +0000</pubDate>
  <description>arXiv cs.LG - Urban traffic management demands systems that simultaneously predict future conditions, detect anomalies, and take safe corrective actions -- all while providing reliability guarantees. We present STREAM-RL, a unified framework that introduces three novel algorithmic contributions: (1) PU-GAT+, an Uncertainty-Guided Adaptive Conformal Forecaster that uses prediction uncertainty to dynamically rewe</description>
</item>

<item>
  <title>Agentic AI in Healthcare &amp; Medicine: A Seven-Dimensional Taxonomy for Empirical Evaluation of LLM-based Agents</title>
  <link>https://arxiv.org/abs/2602.04813v1</link>
  <guid>https://arxiv.org/abs/2602.04813v1</guid>
  <pubDate>Wed, 04 Feb 2026 17:59:14 +0000</pubDate>
  <description>arXiv cs.AI - Large Language Model (LLM)-based agents that plan, use tools and act has begun to shape healthcare and medicine. Reported studies demonstrate competence on various tasks ranging from EHR analysis and differential diagnosis to treatment planning and research workflows. Yet the literature largely consists of overviews which are either broad surveys or narrow dives into a single capability (e.g., mem</description>
</item>

<item>
  <title>SE-Bench: Benchmarking Self-Evolution with Knowledge Internalization</title>
  <link>https://arxiv.org/abs/2602.04811v1</link>
  <guid>https://arxiv.org/abs/2602.04811v1</guid>
  <pubDate>Wed, 04 Feb 2026 17:58:32 +0000</pubDate>
  <description>arXiv cs.AI - True self-evolution requires agents to act as lifelong learners that internalize novel experiences to solve future problems. However, rigorously measuring this foundational capability is hindered by two obstacles: the entanglement of prior knowledge, where ``new&apos;&apos; knowledge may appear in pre-training data, and the entanglement of reasoning complexity, where failures may stem from problem difficult</description>
</item>

<item>
  <title>SE-Bench: Benchmarking Self-Evolution with Knowledge Internalization</title>
  <link>https://arxiv.org/abs/2602.04811v1</link>
  <guid>https://arxiv.org/abs/2602.04811v1</guid>
  <pubDate>Wed, 04 Feb 2026 17:58:32 +0000</pubDate>
  <description>arXiv cs.LG - True self-evolution requires agents to act as lifelong learners that internalize novel experiences to solve future problems. However, rigorously measuring this foundational capability is hindered by two obstacles: the entanglement of prior knowledge, where ``new&apos;&apos; knowledge may appear in pre-training data, and the entanglement of reasoning complexity, where failures may stem from problem difficult</description>
</item>

<item>
  <title>Beyond Rewards in Reinforcement Learning for Cyber Defence</title>
  <link>https://arxiv.org/abs/2602.04809v1</link>
  <guid>https://arxiv.org/abs/2602.04809v1</guid>
  <pubDate>Wed, 04 Feb 2026 17:55:23 +0000</pubDate>
  <description>arXiv cs.AI - Recent years have seen an explosion of interest in autonomous cyber defence agents trained to defend computer networks using deep reinforcement learning. These agents are typically trained in cyber gym environments using dense, highly engineered reward functions which combine many penalties and incentives for a range of (un)desirable states and costly actions. Dense rewards help alleviate the chal</description>
</item>

<item>
  <title>Beyond Rewards in Reinforcement Learning for Cyber Defence</title>
  <link>https://arxiv.org/abs/2602.04809v1</link>
  <guid>https://arxiv.org/abs/2602.04809v1</guid>
  <pubDate>Wed, 04 Feb 2026 17:55:23 +0000</pubDate>
  <description>arXiv cs.LG - Recent years have seen an explosion of interest in autonomous cyber defence agents trained to defend computer networks using deep reinforcement learning. These agents are typically trained in cyber gym environments using dense, highly engineered reward functions which combine many penalties and incentives for a range of (un)desirable states and costly actions. Dense rewards help alleviate the chal</description>
</item>

<item>
  <title>Active Asymmetric Multi-Agent Multimodal Learning under Uncertainty</title>
  <link>https://arxiv.org/abs/2602.04763v1</link>
  <guid>https://arxiv.org/abs/2602.04763v1</guid>
  <pubDate>Wed, 04 Feb 2026 17:01:31 +0000</pubDate>
  <description>arXiv cs.AI - Multi-agent systems are increasingly equipped with heterogeneous multimodal sensors, enabling richer perception but introducing modality-specific and agent-dependent uncertainty. Existing multi-agent collaboration frameworks typically reason at the agent level, assume homogeneous sensing, and handle uncertainty implicitly, limiting robustness under sensor corruption. We propose Active Asymmetric M</description>
</item>

<item>
  <title>Understanding and Exploiting Weight Update Sparsity for Communication-Efficient Distributed RL</title>
  <link>https://arxiv.org/abs/2602.03839v1</link>
  <guid>https://arxiv.org/abs/2602.03839v1</guid>
  <pubDate>Tue, 03 Feb 2026 18:56:48 +0000</pubDate>
  <description>arXiv cs.LG - Reinforcement learning (RL) is a critical component for post-training large language models (LLMs). However, in bandwidth-constrained distributed RL, scalability is often bottlenecked by the synchronization of policy weights from trainers to inference workers, particularly over commodity networks or in decentralized settings. While recent studies suggest that RL updates modify only a small fractio</description>
</item>

<item>
  <title>PrevizWhiz: Combining Rough 3D Scenes and 2D Video to Guide Generative Video Previsualization</title>
  <link>https://arxiv.org/abs/2602.03838v1</link>
  <guid>https://arxiv.org/abs/2602.03838v1</guid>
  <pubDate>Tue, 03 Feb 2026 18:56:40 +0000</pubDate>
  <description>arXiv cs.AI - In pre-production, filmmakers and 3D animation experts must rapidly prototype ideas to explore a film&apos;s possibilities before fullscale production, yet conventional approaches involve trade-offs in efficiency and expressiveness. Hand-drawn storyboards often lack spatial precision needed for complex cinematography, while 3D previsualization demands expertise and high-quality rigged assets. To addres</description>
</item>

<item>
  <title>Accelerating Scientific Research with Gemini: Case Studies and Common Techniques</title>
  <link>https://arxiv.org/abs/2602.03837v1</link>
  <guid>https://arxiv.org/abs/2602.03837v1</guid>
  <pubDate>Tue, 03 Feb 2026 18:56:17 +0000</pubDate>
  <description>arXiv cs.AI - Recent advances in large language models (LLMs) have opened new avenues for accelerating scientific research. While models are increasingly capable of assisting with routine tasks, their ability to contribute to novel, expert-level mathematical discovery is less understood. We present a collection of case studies demonstrating how researchers have successfully collaborated with advanced AI models,</description>
</item>

<item>
  <title>AutoFigure: Generating and Refining Publication-Ready Scientific Illustrations</title>
  <link>https://arxiv.org/abs/2602.03828v1</link>
  <guid>https://arxiv.org/abs/2602.03828v1</guid>
  <pubDate>Tue, 03 Feb 2026 18:41:43 +0000</pubDate>
  <description>arXiv cs.AI - High-quality scientific illustrations are crucial for effectively communicating complex scientific and technical concepts, yet their manual creation remains a well-recognized bottleneck in both academia and industry. We present FigureBench, the first large-scale benchmark for generating scientific illustrations from long-form scientific texts. It contains 3,300 high-quality scientific text-figure </description>
</item>

<item>
  <title>SymPlex: A Structure-Aware Transformer for Symbolic PDE Solving</title>
  <link>https://arxiv.org/abs/2602.03816v1</link>
  <guid>https://arxiv.org/abs/2602.03816v1</guid>
  <pubDate>Tue, 03 Feb 2026 18:18:30 +0000</pubDate>
  <description>arXiv cs.LG - We propose SymPlex, a reinforcement learning framework for discovering analytical symbolic solutions to partial differential equations (PDEs) without access to ground-truth expressions. SymPlex formulates symbolic PDE solving as tree-structured decision-making and optimizes candidate solutions using only the PDE and its boundary conditions. At its core is SymFormer, a structure-aware Transformer t</description>
</item>

</channel>
</rss>
