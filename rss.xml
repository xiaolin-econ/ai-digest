<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
<channel>
  <title>AI Research Digest</title>
  <link>https://xiaolin-econ.github.io/ai-digest/</link>
  <description>Curated AI research + releases</description>
  <lastBuildDate>Wed, 11 Feb 2026 18:51:19 +0000</lastBuildDate>
  <atom:link href="https://xiaolin-econ.github.io/ai-digest/rss.xml" rel="self" type="application/rss+xml" xmlns:atom="http://www.w3.org/2005/Atom"/>
  
<item>
  <title>AI Digest — Daily Summary</title>
  <link>https://xiaolin-econ.github.io/ai-digest/rss.xml</link>
  <guid>https://xiaolin-econ.github.io/ai-digest/rss.xml#summary</guid>
  <pubDate>Wed, 11 Feb 2026 18:51:19 +0000</pubDate>
  <description>Large Language Models (LLMs) often provide chain-of-thought (CoT) reasoning traces that appear plausible, but may hide internal biases. We call these *unverbalized biases*. Monitoring models via their stated reasoning is therefore unreliable, and existing bias evaluations typically require predefined categories and hand-crafted datasets. In this work, we introduce a fully automated, black-box pipeline for detecting task-specific unverbalized biases. Given a task dataset, the pipeline uses LLM autoraters to generate candidate bias concepts. It then tests each concept on progressively larger input samples by generating positive and negative variations, and applies statistical techniques for multiple testing and early stopping. A concept is flagged as an unverbalized bias if it yields…</description>
</item>

<item>
  <title>Biases in the Blind Spot: Detecting What LLMs Fail to Mention</title>
  <link>https://arxiv.org/abs/2602.10117v1</link>
  <guid>https://arxiv.org/abs/2602.10117v1</guid>
  <pubDate>Tue, 10 Feb 2026 18:59:56 +0000</pubDate>
  <description>arXiv cs.AI - Large Language Models (LLMs) often provide chain-of-thought (CoT) reasoning traces that appear plausible, but may hide internal biases. We call these *unverbalized biases*. Monitoring models via their stated reasoning is therefore unreliable, and existing bias evaluations typically require predefined categories and hand-crafted datasets. In this work, we introduce a fully automated, black-box pipe</description>
</item>

<item>
  <title>Biases in the Blind Spot: Detecting What LLMs Fail to Mention</title>
  <link>https://arxiv.org/abs/2602.10117v1</link>
  <guid>https://arxiv.org/abs/2602.10117v1</guid>
  <pubDate>Tue, 10 Feb 2026 18:59:56 +0000</pubDate>
  <description>arXiv cs.LG - Large Language Models (LLMs) often provide chain-of-thought (CoT) reasoning traces that appear plausible, but may hide internal biases. We call these *unverbalized biases*. Monitoring models via their stated reasoning is therefore unreliable, and existing bias evaluations typically require predefined categories and hand-crafted datasets. In this work, we introduce a fully automated, black-box pipe</description>
</item>

<item>
  <title>Agent World Model: Infinity Synthetic Environments for Agentic Reinforcement Learning</title>
  <link>https://arxiv.org/abs/2602.10090v1</link>
  <guid>https://arxiv.org/abs/2602.10090v1</guid>
  <pubDate>Tue, 10 Feb 2026 18:55:41 +0000</pubDate>
  <description>arXiv cs.AI - Recent advances in large language model (LLM) have empowered autonomous agents to perform complex tasks that require multi-turn interactions with tools and environments. However, scaling such agent training is limited by the lack of diverse and reliable environments. In this paper, we propose Agent World Model (AWM), a fully synthetic environment generation pipeline. Using this pipeline, we scale </description>
</item>

<item>
  <title>Agent World Model: Infinity Synthetic Environments for Agentic Reinforcement Learning</title>
  <link>https://arxiv.org/abs/2602.10090v1</link>
  <guid>https://arxiv.org/abs/2602.10090v1</guid>
  <pubDate>Tue, 10 Feb 2026 18:55:41 +0000</pubDate>
  <description>arXiv cs.LG - Recent advances in large language model (LLM) have empowered autonomous agents to perform complex tasks that require multi-turn interactions with tools and environments. However, scaling such agent training is limited by the lack of diverse and reliable environments. In this paper, we propose Agent World Model (AWM), a fully synthetic environment generation pipeline. Using this pipeline, we scale </description>
</item>

<item>
  <title>CODE-SHARP: Continuous Open-ended Discovery and Evolution of Skills as Hierarchical Reward Programs</title>
  <link>https://arxiv.org/abs/2602.10085v1</link>
  <guid>https://arxiv.org/abs/2602.10085v1</guid>
  <pubDate>Tue, 10 Feb 2026 18:51:39 +0000</pubDate>
  <description>arXiv cs.AI - Developing agents capable of open-endedly discovering and learning novel skills is a grand challenge in Artificial Intelligence. While reinforcement learning offers a powerful framework for training agents to master complex skills, it typically relies on hand-designed reward functions. This is infeasible for open-ended skill discovery, where the set of meaningful skills is not known a priori. Whil</description>
</item>

<item>
  <title>Anagent For Enhancing Scientific Table &amp; Figure Analysis</title>
  <link>https://arxiv.org/abs/2602.10081v1</link>
  <guid>https://arxiv.org/abs/2602.10081v1</guid>
  <pubDate>Tue, 10 Feb 2026 18:46:28 +0000</pubDate>
  <description>arXiv cs.AI - In scientific research, analysis requires accurately interpreting complex multimodal knowledge, integrating evidence from different sources, and drawing inferences grounded in domain-specific knowledge. However, current artificial intelligence (AI) systems struggle to consistently demonstrate such capabilities. The complexity and variability of scientific tables and figures, combined with heteroge</description>
</item>

<item>
  <title>Chain of Mindset: Reasoning with Adaptive Cognitive Modes</title>
  <link>https://arxiv.org/abs/2602.10063v1</link>
  <guid>https://arxiv.org/abs/2602.10063v1</guid>
  <pubDate>Tue, 10 Feb 2026 18:31:47 +0000</pubDate>
  <description>arXiv cs.AI - Human problem-solving is never the repetition of a single mindset, by which we mean a distinct mode of cognitive processing. When tackling a specific task, we do not rely on a single mindset; instead, we integrate multiple mindsets within the single solution process. However, existing LLM reasoning methods fall into a common trap: they apply the same fixed mindset across all steps, overlooking tha</description>
</item>

<item>
  <title>Effectiveness of Binary Autoencoders for QUBO-Based Optimization Problems</title>
  <link>https://arxiv.org/abs/2602.10037v1</link>
  <guid>https://arxiv.org/abs/2602.10037v1</guid>
  <pubDate>Tue, 10 Feb 2026 17:59:29 +0000</pubDate>
  <description>arXiv cs.LG - In black-box combinatorial optimization, objective evaluations are often expensive, so high quality solutions must be found under a limited budget. Factorization machine with quantum annealing (FMQA) builds a quadratic surrogate model from evaluated samples and optimizes it on an Ising machine. However, FMQA requires binary decision variables, and for nonbinary structures such as integer permutati</description>
</item>

<item>
  <title>Discovering High Level Patterns from Simulation Traces</title>
  <link>https://arxiv.org/abs/2602.10009v1</link>
  <guid>https://arxiv.org/abs/2602.10009v1</guid>
  <pubDate>Tue, 10 Feb 2026 17:31:39 +0000</pubDate>
  <description>arXiv cs.AI - Artificial intelligence (AI) agents embedded in environments with physics-based interaction face many challenges including reasoning, planning, summarization, and question answering. This problem is exacerbated when a human user wishes to either guide or interact with the agent in natural language. Although the use of Language Models (LMs) is the default choice, as an AI tool, they struggle with t</description>
</item>

<item>
  <title>A Collaborative Safety Shield for Safe and Efficient CAV Lane Changes in Congested On-Ramp Merging</title>
  <link>https://arxiv.org/abs/2602.10007v1</link>
  <guid>https://arxiv.org/abs/2602.10007v1</guid>
  <pubDate>Tue, 10 Feb 2026 17:30:09 +0000</pubDate>
  <description>arXiv cs.AI - Lane changing in dense traffic is a significant challenge for Connected and Autonomous Vehicles (CAVs). Existing lane change controllers primarily either ensure safety or collaboratively improve traffic efficiency, but do not consider these conflicting objectives together. To address this, we propose the Multi-Agent Safety Shield (MASS), designed using Control Barrier Functions (CBFs) to enable sa</description>
</item>

<item>
  <title>Robustness Is a Function, Not a Number: A Factorized Comprehensive Study of OOD Robustness in Vision-Based Driving</title>
  <link>https://arxiv.org/abs/2602.09018v1</link>
  <guid>https://arxiv.org/abs/2602.09018v1</guid>
  <pubDate>Mon, 09 Feb 2026 18:59:03 +0000</pubDate>
  <description>arXiv cs.AI - Out of distribution (OOD) robustness in autonomous driving is often reduced to a single number, hiding what breaks a policy. We decompose environments along five axes: scene (rural/urban), season, weather, time (day/night), and agent mix; and measure performance under controlled $k$-factor perturbations ($k \in \{0,1,2,3\}$). Using closed loop control in VISTA, we benchmark FC, CNN, and ViT polici</description>
</item>

<item>
  <title>Robustness Is a Function, Not a Number: A Factorized Comprehensive Study of OOD Robustness in Vision-Based Driving</title>
  <link>https://arxiv.org/abs/2602.09018v1</link>
  <guid>https://arxiv.org/abs/2602.09018v1</guid>
  <pubDate>Mon, 09 Feb 2026 18:59:03 +0000</pubDate>
  <description>arXiv cs.LG - Out of distribution (OOD) robustness in autonomous driving is often reduced to a single number, hiding what breaks a policy. We decompose environments along five axes: scene (rural/urban), season, weather, time (day/night), and agent mix; and measure performance under controlled $k$-factor perturbations ($k \in \{0,1,2,3\}$). Using closed loop control in VISTA, we benchmark FC, CNN, and ViT polici</description>
</item>

<item>
  <title>Next-Gen CAPTCHAs: Leveraging the Cognitive Gap for Scalable and Diverse GUI-Agent Defense</title>
  <link>https://arxiv.org/abs/2602.09012v1</link>
  <guid>https://arxiv.org/abs/2602.09012v1</guid>
  <pubDate>Mon, 09 Feb 2026 18:55:33 +0000</pubDate>
  <description>arXiv cs.AI - The rapid evolution of GUI-enabled agents has rendered traditional CAPTCHAs obsolete. While previous benchmarks like OpenCaptchaWorld established a baseline for evaluating multimodal agents, recent advancements in reasoning-heavy models, such as Gemini3-Pro-High and GPT-5.2-Xhigh have effectively collapsed this security barrier, achieving pass rates as high as 90% on complex logic puzzles like &quot;Bi</description>
</item>

<item>
  <title>Next-Gen CAPTCHAs: Leveraging the Cognitive Gap for Scalable and Diverse GUI-Agent Defense</title>
  <link>https://arxiv.org/abs/2602.09012v1</link>
  <guid>https://arxiv.org/abs/2602.09012v1</guid>
  <pubDate>Mon, 09 Feb 2026 18:55:33 +0000</pubDate>
  <description>arXiv cs.LG - The rapid evolution of GUI-enabled agents has rendered traditional CAPTCHAs obsolete. While previous benchmarks like OpenCaptchaWorld established a baseline for evaluating multimodal agents, recent advancements in reasoning-heavy models, such as Gemini3-Pro-High and GPT-5.2-Xhigh have effectively collapsed this security barrier, achieving pass rates as high as 90% on complex logic puzzles like &quot;Bi</description>
</item>

<item>
  <title>From Obstacles to Etiquette: Robot Social Navigation with VLM-Informed Path Selection</title>
  <link>https://arxiv.org/abs/2602.09002v1</link>
  <guid>https://arxiv.org/abs/2602.09002v1</guid>
  <pubDate>Mon, 09 Feb 2026 18:46:12 +0000</pubDate>
  <description>arXiv cs.AI - Navigating socially in human environments requires more than satisfying geometric constraints, as collision-free paths may still interfere with ongoing activities or conflict with social norms. Addressing this challenge calls for analyzing interactions between agents and incorporating common-sense reasoning into planning. This paper presents a social robot navigation framework that integrates geom</description>
</item>

<item>
  <title>InternAgent-1.5: A Unified Agentic Framework for Long-Horizon Autonomous Scientific Discovery</title>
  <link>https://arxiv.org/abs/2602.08990v1</link>
  <guid>https://arxiv.org/abs/2602.08990v1</guid>
  <pubDate>Mon, 09 Feb 2026 18:36:06 +0000</pubDate>
  <description>arXiv cs.AI - We introduce InternAgent-1.5, a unified system designed for end-to-end scientific discovery across computational and empirical domains. The system is built on a structured architecture composed of three coordinated subsystems for generation, verification, and evolution. These subsystems are supported by foundational capabilities for deep research, solution optimization, and long horizon memory. Th</description>
</item>

<item>
  <title>StretchTime: Adaptive Time Series Forecasting via Symplectic Attention</title>
  <link>https://arxiv.org/abs/2602.08983v1</link>
  <guid>https://arxiv.org/abs/2602.08983v1</guid>
  <pubDate>Mon, 09 Feb 2026 18:29:25 +0000</pubDate>
  <description>arXiv cs.AI - Transformer architectures have established strong baselines in time series forecasting, yet they typically rely on positional encodings that assume uniform, index-based temporal progression. However, real-world systems, from shifting financial cycles to elastic biological rhythms, frequently exhibit &quot;time-warped&quot; dynamics where the effective flow of time decouples from the sampling index. In this </description>
</item>

<item>
  <title>StretchTime: Adaptive Time Series Forecasting via Symplectic Attention</title>
  <link>https://arxiv.org/abs/2602.08983v1</link>
  <guid>https://arxiv.org/abs/2602.08983v1</guid>
  <pubDate>Mon, 09 Feb 2026 18:29:25 +0000</pubDate>
  <description>arXiv cs.LG - Transformer architectures have established strong baselines in time series forecasting, yet they typically rely on positional encodings that assume uniform, index-based temporal progression. However, real-world systems, from shifting financial cycles to elastic biological rhythms, frequently exhibit &quot;time-warped&quot; dynamics where the effective flow of time decouples from the sampling index. In this </description>
</item>

<item>
  <title>stable-worldmodel-v1: Reproducible World Modeling Research and Evaluation</title>
  <link>https://arxiv.org/abs/2602.08968v1</link>
  <guid>https://arxiv.org/abs/2602.08968v1</guid>
  <pubDate>Mon, 09 Feb 2026 18:04:22 +0000</pubDate>
  <description>arXiv cs.AI - World Models have emerged as a powerful paradigm for learning compact, predictive representations of environment dynamics, enabling agents to reason, plan, and generalize beyond direct experience. Despite recent interest in World Models, most available implementations remain publication-specific, severely limiting their reusability, increasing the risk of bugs, and reducing evaluation standardizat</description>
</item>

<item>
  <title>Learning to Coordinate via Quantum Entanglement in Multi-Agent Reinforcement Learning</title>
  <link>https://arxiv.org/abs/2602.08965v1</link>
  <guid>https://arxiv.org/abs/2602.08965v1</guid>
  <pubDate>Mon, 09 Feb 2026 18:01:40 +0000</pubDate>
  <description>arXiv cs.LG - The inability to communicate poses a major challenge to coordination in multi-agent reinforcement learning (MARL). Prior work has explored correlating local policies via shared randomness, sometimes in the form of a correlation device, as a mechanism to assist in decentralized decision-making. In contrast, this work introduces the first framework for training MARL agents to exploit shared quantum </description>
</item>

<item>
  <title>A Behavioural and Representational Evaluation of Goal-Directedness in Language Model Agents</title>
  <link>https://arxiv.org/abs/2602.08964v1</link>
  <guid>https://arxiv.org/abs/2602.08964v1</guid>
  <pubDate>Mon, 09 Feb 2026 18:00:28 +0000</pubDate>
  <description>arXiv cs.AI - Understanding an agent&apos;s goals helps explain and predict its behaviour, yet there is no established methodology for reliably attributing goals to agentic systems. We propose a framework for evaluating goal-directedness that integrates behavioural evaluation with interpretability-based analyses of models&apos; internal representations. As a case study, we examine an LLM agent navigating a 2D grid world </description>
</item>

<item>
  <title>A Behavioural and Representational Evaluation of Goal-Directedness in Language Model Agents</title>
  <link>https://arxiv.org/abs/2602.08964v1</link>
  <guid>https://arxiv.org/abs/2602.08964v1</guid>
  <pubDate>Mon, 09 Feb 2026 18:00:28 +0000</pubDate>
  <description>arXiv cs.LG - Understanding an agent&apos;s goals helps explain and predict its behaviour, yet there is no established methodology for reliably attributing goals to agentic systems. We propose a framework for evaluating goal-directedness that integrates behavioural evaluation with interpretability-based analyses of models&apos; internal representations. As a case study, we examine an LLM agent navigating a 2D grid world </description>
</item>

<item>
  <title>Digital Twin and Agentic AI for Wild Fire Disaster Management: Intelligent Virtual Situation Room</title>
  <link>https://arxiv.org/abs/2602.08949v1</link>
  <guid>https://arxiv.org/abs/2602.08949v1</guid>
  <pubDate>Mon, 09 Feb 2026 17:44:52 +0000</pubDate>
  <description>arXiv cs.AI - According to the United Nations, wildfire frequency and intensity are projected to increase by approximately 14% by 2030 and 30% by 2050 due to global warming, posing critical threats to life, infrastructure, and ecosystems. Conventional disaster management frameworks rely on static simulations and passive data acquisition, hindering their ability to adapt to arbitrarily evolving wildfire episodes</description>
</item>

<item>
  <title>CoRefine: Confidence-Guided Self-Refinement for Adaptive Test-Time Compute</title>
  <link>https://arxiv.org/abs/2602.08948v1</link>
  <guid>https://arxiv.org/abs/2602.08948v1</guid>
  <pubDate>Mon, 09 Feb 2026 17:44:41 +0000</pubDate>
  <description>arXiv cs.AI - Large Language Models (LLMs) often rely on test-time scaling via parallel decoding (for example, 512 samples) to boost reasoning accuracy, but this incurs substantial compute. We introduce CoRefine, a confidence-guided self-refinement method that achieves competitive accuracy using a fraction of the tokens via a lightweight 211k-parameter Conv1D controller atop a frozen LLM. The controller consume</description>
</item>

<item>
  <title>pixelLOG: Logging of Online Gameplay for Cognitive Research</title>
  <link>https://arxiv.org/abs/2602.08941v1</link>
  <guid>https://arxiv.org/abs/2602.08941v1</guid>
  <pubDate>Mon, 09 Feb 2026 17:38:55 +0000</pubDate>
  <description>arXiv cs.AI - Traditional cognitive assessments often rely on isolated, output-focused measurements that may fail to capture the complexity of human cognition in naturalistic settings. We present pixelLOG, a high-performance data collection framework for Spigot-based Minecraft servers designed specifically for process-based cognitive research. Unlike existing frameworks tailored only for artificial intelligence</description>
</item>

<item>
  <title>AMS-HD: Hyperdimensional Computing for Real-Time and Energy-Efficient Acute Mountain Sickness Detection</title>
  <link>https://arxiv.org/abs/2602.08916v1</link>
  <guid>https://arxiv.org/abs/2602.08916v1</guid>
  <pubDate>Mon, 09 Feb 2026 17:16:13 +0000</pubDate>
  <description>arXiv cs.LG - Altitude sickness is a potentially life-threatening condition that impacts many individuals traveling to elevated altitudes. Timely detection is critical as symptoms can escalate rapidly. Early recognition enables simple interventions such as descent, oxygen, or medication, and prompt treatment can save lives by significantly lowering the risk of severe complications. Although conventional machine</description>
</item>

<item>
  <title>Gesturing Toward Abstraction: Multimodal Convention Formation in Collaborative Physical Tasks</title>
  <link>https://arxiv.org/abs/2602.08914v1</link>
  <guid>https://arxiv.org/abs/2602.08914v1</guid>
  <pubDate>Mon, 09 Feb 2026 17:13:34 +0000</pubDate>
  <description>arXiv cs.AI - A quintessential feature of human intelligence is the ability to create ad hoc conventions over time to achieve shared goals efficiently. We investigate how communication strategies evolve through repeated collaboration as people coordinate on shared procedural abstractions. To this end, we conducted an online unimodal study (n = 98) using natural language to probe abstraction hierarchies. In a fo</description>
</item>

<item>
  <title>Improving Credit Card Fraud Detection with an Optimized Explainable Boosting Machine</title>
  <link>https://arxiv.org/abs/2602.06955v1</link>
  <guid>https://arxiv.org/abs/2602.06955v1</guid>
  <pubDate>Fri, 06 Feb 2026 18:56:17 +0000</pubDate>
  <description>arXiv cs.LG - Addressing class imbalance is a central challenge in credit card fraud detection, as it directly impacts predictive reliability in real-world financial systems. To overcome this, the study proposes an enhanced workflow based on the Explainable Boosting Machine (EBM)-a transparent, state-of-the-art implementation of the GA2M algorithm-optimized through systematic hyperparameter tuning, feature sele</description>
</item>

<item>
  <title>DreamDojo: A Generalist Robot World Model from Large-Scale Human Videos</title>
  <link>https://arxiv.org/abs/2602.06949v1</link>
  <guid>https://arxiv.org/abs/2602.06949v1</guid>
  <pubDate>Fri, 06 Feb 2026 18:49:43 +0000</pubDate>
  <description>arXiv cs.AI - Being able to simulate the outcomes of actions in varied environments will revolutionize the development of generalist agents at scale. However, modeling these world dynamics, especially for dexterous robotics tasks, poses significant challenges due to limited data coverage and scarce action labels. As an endeavor towards this end, we introduce DreamDojo, a foundation world model that learns diver</description>
</item>

<item>
  <title>DreamDojo: A Generalist Robot World Model from Large-Scale Human Videos</title>
  <link>https://arxiv.org/abs/2602.06949v1</link>
  <guid>https://arxiv.org/abs/2602.06949v1</guid>
  <pubDate>Fri, 06 Feb 2026 18:49:43 +0000</pubDate>
  <description>arXiv cs.LG - Being able to simulate the outcomes of actions in varied environments will revolutionize the development of generalist agents at scale. However, modeling these world dynamics, especially for dexterous robotics tasks, poses significant challenges due to limited data coverage and scarce action labels. As an endeavor towards this end, we introduce DreamDojo, a foundation world model that learns diver</description>
</item>

<item>
  <title>Agentic Uncertainty Reveals Agentic Overconfidence</title>
  <link>https://arxiv.org/abs/2602.06948v1</link>
  <guid>https://arxiv.org/abs/2602.06948v1</guid>
  <pubDate>Fri, 06 Feb 2026 18:49:35 +0000</pubDate>
  <description>arXiv cs.AI - Can AI agents predict whether they will succeed at a task? We study agentic uncertainty by eliciting success probability estimates before, during, and after task execution. All results exhibit agentic overconfidence: some agents that succeed only 22% of the time predict 77% success. Counterintuitively, pre-execution assessment with strictly less information tends to yield better discrimination tha</description>
</item>

<item>
  <title>Agentic Uncertainty Reveals Agentic Overconfidence</title>
  <link>https://arxiv.org/abs/2602.06948v1</link>
  <guid>https://arxiv.org/abs/2602.06948v1</guid>
  <pubDate>Fri, 06 Feb 2026 18:49:35 +0000</pubDate>
  <description>arXiv cs.LG - Can AI agents predict whether they will succeed at a task? We study agentic uncertainty by eliciting success probability estimates before, during, and after task execution. All results exhibit agentic overconfidence: some agents that succeed only 22% of the time predict 77% success. Counterintuitively, pre-execution assessment with strictly less information tends to yield better discrimination tha</description>
</item>

<item>
  <title>Reciprocal Latent Fields for Precomputed Sound Propagation</title>
  <link>https://arxiv.org/abs/2602.06937v1</link>
  <guid>https://arxiv.org/abs/2602.06937v1</guid>
  <pubDate>Fri, 06 Feb 2026 18:31:11 +0000</pubDate>
  <description>arXiv cs.LG - Realistic sound propagation is essential for immersion in a virtual scene, yet physically accurate wave-based simulations remain computationally prohibitive for real-time applications. Wave coding methods address this limitation by precomputing and compressing impulse responses of a given scene into a set of scalar acoustic parameters, which can reach unmanageable sizes in large environments with </description>
</item>

<item>
  <title>Implementing Grassroots Logic Programs with Multiagent Transition Systems and AI</title>
  <link>https://arxiv.org/abs/2602.06934v1</link>
  <guid>https://arxiv.org/abs/2602.06934v1</guid>
  <pubDate>Fri, 06 Feb 2026 18:30:11 +0000</pubDate>
  <description>arXiv cs.AI - Grassroots Logic Programs (GLP) is a concurrent logic programming language with variables partitioned into paired \emph{readers} and \emph{writers}, conjuring both linear logic and futures/promises: an assignment is produced at most once via the sole occurrence of a writer (promise) and consumed at most once via the sole occurrence of its paired reader (future), and may contain additional readers </description>
</item>

<item>
  <title>When RL Meets Adaptive Speculative Training: A Unified Training-Serving System</title>
  <link>https://arxiv.org/abs/2602.06932v1</link>
  <guid>https://arxiv.org/abs/2602.06932v1</guid>
  <pubDate>Fri, 06 Feb 2026 18:28:54 +0000</pubDate>
  <description>arXiv cs.LG - Speculative decoding can significantly accelerate LLM serving, yet most deployments today disentangle speculator training from serving, treating speculator training as a standalone offline modeling problem. We show that this decoupled formulation introduces substantial deployment and adaptation lag: (1) high time-to-serve, since a speculator must be trained offline for a considerable period before</description>
</item>

<item>
  <title>From Kepler to Newton: Inductive Biases Guide Learned World Models in Transformers</title>
  <link>https://arxiv.org/abs/2602.06923v1</link>
  <guid>https://arxiv.org/abs/2602.06923v1</guid>
  <pubDate>Fri, 06 Feb 2026 18:17:37 +0000</pubDate>
  <description>arXiv cs.AI - Can general-purpose AI architectures go beyond prediction to discover the physical laws governing the universe? True intelligence relies on &quot;world models&quot; -- causal abstractions that allow an agent to not only predict future states but understand the underlying governing dynamics. While previous &quot;AI Physicist&quot; approaches have successfully recovered such laws, they typically rely on strong, domain-</description>
</item>

<item>
  <title>From Kepler to Newton: Inductive Biases Guide Learned World Models in Transformers</title>
  <link>https://arxiv.org/abs/2602.06923v1</link>
  <guid>https://arxiv.org/abs/2602.06923v1</guid>
  <pubDate>Fri, 06 Feb 2026 18:17:37 +0000</pubDate>
  <description>arXiv cs.LG - Can general-purpose AI architectures go beyond prediction to discover the physical laws governing the universe? True intelligence relies on &quot;world models&quot; -- causal abstractions that allow an agent to not only predict future states but understand the underlying governing dynamics. While previous &quot;AI Physicist&quot; approaches have successfully recovered such laws, they typically rely on strong, domain-</description>
</item>

<item>
  <title>TraceCoder: A Trace-Driven Multi-Agent Framework for Automated Debugging of LLM-Generated Code</title>
  <link>https://arxiv.org/abs/2602.06875v1</link>
  <guid>https://arxiv.org/abs/2602.06875v1</guid>
  <pubDate>Fri, 06 Feb 2026 16:59:48 +0000</pubDate>
  <description>arXiv cs.AI - Large Language Models (LLMs) often generate code with subtle but critical bugs, especially for complex tasks. Existing automated repair methods typically rely on superficial pass/fail signals, offering limited visibility into program behavior and hindering precise error localization. In addition, without a way to learn from prior failures, repair processes often fall into repetitive and inefficien</description>
</item>

<item>
  <title>AIRS-Bench: a Suite of Tasks for Frontier AI Research Science Agents</title>
  <link>https://arxiv.org/abs/2602.06855v1</link>
  <guid>https://arxiv.org/abs/2602.06855v1</guid>
  <pubDate>Fri, 06 Feb 2026 16:45:02 +0000</pubDate>
  <description>arXiv cs.AI - LLM agents hold significant promise for advancing scientific research. To accelerate this progress, we introduce AIRS-Bench (the AI Research Science Benchmark), a suite of 20 tasks sourced from state-of-the-art machine learning papers. These tasks span diverse domains, including language modeling, mathematics, bioinformatics, and time series forecasting. AIRS-Bench tasks assess agentic capabilitie</description>
</item>

<item>
  <title>From Features to Actions: Explainability in Traditional and Agentic AI Systems</title>
  <link>https://arxiv.org/abs/2602.06841v1</link>
  <guid>https://arxiv.org/abs/2602.06841v1</guid>
  <pubDate>Fri, 06 Feb 2026 16:34:29 +0000</pubDate>
  <description>arXiv cs.AI - Over the last decade, explainable AI has primarily focused on interpreting individual model predictions, producing post-hoc explanations that relate inputs to outputs under a fixed decision structure. Recent advances in large language models (LLMs) have enabled agentic AI systems whose behaviour unfolds over multi-step trajectories. In these settings, success and failure are determined by sequence</description>
</item>

<item>
  <title>LLM Active Alignment: A Nash Equilibrium Perspective</title>
  <link>https://arxiv.org/abs/2602.06836v1</link>
  <guid>https://arxiv.org/abs/2602.06836v1</guid>
  <pubDate>Fri, 06 Feb 2026 16:26:03 +0000</pubDate>
  <description>arXiv cs.AI - We develop a game-theoretic framework for predicting and steering the behavior of populations of large language models (LLMs) through Nash equilibrium (NE) analysis. To avoid the intractability of equilibrium computation in open-ended text spaces, we model each agent&apos;s action as a mixture over human subpopulations. Agents choose actively and strategically which groups to align with, yielding an in</description>
</item>

<item>
  <title>DyTopo: Dynamic Topology Routing for Multi-Agent Reasoning via Semantic Matching</title>
  <link>https://arxiv.org/abs/2602.06039v1</link>
  <guid>https://arxiv.org/abs/2602.06039v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:59:51 +0000</pubDate>
  <description>arXiv cs.AI - Multi-agent systems built from prompted large language models can improve multi-round reasoning, yet most existing pipelines rely on fixed, trajectory-wide communication patterns that are poorly matched to the stage-dependent needs of iterative problem solving. We introduce DyTopo, a manager-guided multi-agent framework that reconstructs a sparse directed communication graph at each round. Conditi</description>
</item>

<item>
  <title>CommCP: Efficient Multi-Agent Coordination via LLM-Based Communication with Conformal Prediction</title>
  <link>https://arxiv.org/abs/2602.06038v1</link>
  <guid>https://arxiv.org/abs/2602.06038v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:59:45 +0000</pubDate>
  <description>arXiv cs.AI - To complete assignments provided by humans in natural language, robots must interpret commands, generate and answer relevant questions for scene understanding, and manipulate target objects. Real-world deployments often require multiple heterogeneous robots with different manipulation capabilities to handle different assignments cooperatively. Beyond the need for specialized manipulation skills, e</description>
</item>

<item>
  <title>CommCP: Efficient Multi-Agent Coordination via LLM-Based Communication with Conformal Prediction</title>
  <link>https://arxiv.org/abs/2602.06038v1</link>
  <guid>https://arxiv.org/abs/2602.06038v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:59:45 +0000</pubDate>
  <description>arXiv cs.LG - To complete assignments provided by humans in natural language, robots must interpret commands, generate and answer relevant questions for scene understanding, and manipulate target objects. Real-world deployments often require multiple heterogeneous robots with different manipulation capabilities to handle different assignments cooperatively. Beyond the need for specialized manipulation skills, e</description>
</item>

<item>
  <title>PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling</title>
  <link>https://arxiv.org/abs/2602.06030v1</link>
  <guid>https://arxiv.org/abs/2602.06030v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:59:01 +0000</pubDate>
  <description>arXiv cs.LG - Large language model (LLM)-based multi-agent systems enable expressive agent reasoning but are expensive to scale and poorly calibrated for timestep-aligned state-transition simulation, while classical agent-based models (ABMs) offer interpretability but struggle to integrate rich individual-level signals and non-stationary behaviors. We propose PhysicsAgentABM, which shifts inference to behaviora</description>
</item>

<item>
  <title>Curiosity is Knowledge: Self-Consistent Learning and No-Regret Optimization with Active Inference</title>
  <link>https://arxiv.org/abs/2602.06029v1</link>
  <guid>https://arxiv.org/abs/2602.06029v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:58:32 +0000</pubDate>
  <description>arXiv cs.LG - Active inference (AIF) unifies exploration and exploitation by minimizing the Expected Free Energy (EFE), balancing epistemic value (information gain) and pragmatic value (task performance) through a curiosity coefficient. Yet it has been unclear when this balance yields both coherent learning and efficient decision-making: insufficient curiosity can drive myopic exploitation and prevent uncertain</description>
</item>

<item>
  <title>Learning Query-Aware Budget-Tier Routing for Runtime Agent Memory</title>
  <link>https://arxiv.org/abs/2602.06025v1</link>
  <guid>https://arxiv.org/abs/2602.06025v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:57:09 +0000</pubDate>
  <description>arXiv cs.AI - Memory is increasingly central to Large Language Model (LLM) agents operating beyond a single context window, yet most existing systems rely on offline, query-agnostic memory construction that can be inefficient and may discard query-critical information. Although runtime memory utilization is a natural alternative, prior work often incurs substantial overhead and offers limited explicit control o</description>
</item>

<item>
  <title>Learning Query-Aware Budget-Tier Routing for Runtime Agent Memory</title>
  <link>https://arxiv.org/abs/2602.06025v1</link>
  <guid>https://arxiv.org/abs/2602.06025v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:57:09 +0000</pubDate>
  <description>arXiv cs.LG - Memory is increasingly central to Large Language Model (LLM) agents operating beyond a single context window, yet most existing systems rely on offline, query-agnostic memory construction that can be inefficient and may discard query-critical information. Although runtime memory utilization is a natural alternative, prior work often incurs substantial overhead and offers limited explicit control o</description>
</item>

<item>
  <title>Learning Event-Based Shooter Models from Virtual Reality Experiments</title>
  <link>https://arxiv.org/abs/2602.06023v1</link>
  <guid>https://arxiv.org/abs/2602.06023v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:56:49 +0000</pubDate>
  <description>arXiv cs.AI - Virtual reality (VR) has emerged as a powerful tool for evaluating school security measures in high-risk scenarios such as school shootings, offering experimental control and high behavioral fidelity. However, assessing new interventions in VR requires recruiting new participant cohorts for each condition, making large-scale or iterative evaluation difficult. These limitations are especially restr</description>
</item>

<item>
  <title>Multi-Token Prediction via Self-Distillation</title>
  <link>https://arxiv.org/abs/2602.06019v1</link>
  <guid>https://arxiv.org/abs/2602.06019v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:54:48 +0000</pubDate>
  <description>arXiv cs.LG - Existing techniques for accelerating language model inference, such as speculative decoding, require training auxiliary speculator models and building and deploying complex inference pipelines. We consider a new approach for converting a pretrained autoregressive language model from a slow single next token prediction model into a fast standalone multi-token prediction model using a simple online </description>
</item>

</channel>
</rss>
