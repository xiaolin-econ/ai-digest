<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
<channel>
  <title>AI Research Digest</title>
  <link>https://xiaolin-econ.github.io/ai-digest/</link>
  <description>Curated AI research + releases</description>
  <lastBuildDate>Mon, 19 Jan 2026 06:26:06 +0000</lastBuildDate>
  <atom:link href="https://xiaolin-econ.github.io/ai-digest/rss.xml" rel="self" type="application/rss+xml" xmlns:atom="http://www.w3.org/2005/Atom"/>
  
<item>
  <title>AI Digest — Daily Summary</title>
  <link>https://xiaolin-econ.github.io/ai-digest/rss.xml</link>
  <guid>https://xiaolin-econ.github.io/ai-digest/rss.xml#summary</guid>
  <pubDate>Mon, 19 Jan 2026 06:26:06 +0000</pubDate>
  <description>We present a novel differentiable grid-based representation for efficiently solving differential equations (DEs). Widely used architectures for neural solvers, such as sinusoidal neural networks, are coordinate-based MLPs that are both computationally intensive and slow to train. Although grid-based alternatives for implicit representations (e.g., Instant-NGP and K-Planes) train faster by… Tool-Integrated Reasoning (TIR) empowers large language models (LLMs) to tackle complex tasks by interleaving reasoning steps with external tool interactions. However, existing reinforcement learning methods typically rely on outcome- or trajectory-level rewards, assigning uniform advantages to all steps within a trajectory. This coarse-grained credit assignment fails to distinguish effective……</description>
</item>

<item>
  <title>The Poisoned Apple Effect: Strategic Manipulation of Mediated Markets via Technology Expansion of AI Agents</title>
  <link>https://arxiv.org/abs/2601.11496v1</link>
  <guid>https://arxiv.org/abs/2601.11496v1</guid>
  <pubDate>Fri, 16 Jan 2026 18:18:03 +0000</pubDate>
  <description>arXiv cs.AI - The integration of AI agents into economic markets fundamentally alters the landscape of strategic interaction. We investigate the economic implications of expanding the set of available technologies in three canonical game-theoretic settings: bargaining (resource division), negotiation (asymmetric information trade), and persuasion (strategic information transmission). We find that simply increas</description>
</item>

<item>
  <title>BoxMind: Closed-loop AI strategy optimization for elite boxing validated in the 2024 Olympics</title>
  <link>https://arxiv.org/abs/2601.11492v1</link>
  <guid>https://arxiv.org/abs/2601.11492v1</guid>
  <pubDate>Fri, 16 Jan 2026 18:14:46 +0000</pubDate>
  <description>arXiv cs.AI - Competitive sports require sophisticated tactical analysis, yet combat disciplines like boxing remain underdeveloped in AI-driven analytics due to the complexity of action dynamics and the lack of structured tactical representations. To address this, we present BoxMind, a closed-loop AI expert system validated in elite boxing competition. By defining atomic punch events with precise temporal bound</description>
</item>

<item>
  <title>Health Facility Location in Ethiopia: Leveraging LLMs to Integrate Expert Knowledge into Algorithmic Planning</title>
  <link>https://arxiv.org/abs/2601.11479v1</link>
  <guid>https://arxiv.org/abs/2601.11479v1</guid>
  <pubDate>Fri, 16 Jan 2026 18:02:09 +0000</pubDate>
  <description>arXiv cs.AI - Ethiopia&apos;s Ministry of Health is upgrading health posts to improve access to essential services, particularly in rural areas. Limited resources, however, require careful prioritization of which facilities to upgrade to maximize population coverage while accounting for diverse expert and stakeholder preferences. In collaboration with the Ethiopian Public Health Institute and Ministry of Health, we </description>
</item>

<item>
  <title>Low-Rank Key Value Attention</title>
  <link>https://arxiv.org/abs/2601.11471v1</link>
  <guid>https://arxiv.org/abs/2601.11471v1</guid>
  <pubDate>Fri, 16 Jan 2026 17:56:40 +0000</pubDate>
  <description>arXiv cs.LG - Transformer pretraining is increasingly constrained by memory and compute requirements, with the key-value (KV) cache emerging as a dominant bottleneck during training and autoregressive decoding. We propose \textit{low-rank KV adaptation} (LRKV), a simple modification of multi-head attention that reduces KV cache memory by exploiting redundancy across attention heads while preserving full token-l</description>
</item>

<item>
  <title>Inter-patient ECG Arrhythmia Classification with LGNs and LUTNs</title>
  <link>https://arxiv.org/abs/2601.11433v1</link>
  <guid>https://arxiv.org/abs/2601.11433v1</guid>
  <pubDate>Fri, 16 Jan 2026 16:55:36 +0000</pubDate>
  <description>arXiv cs.LG - Deep Differentiable Logic Gate Networks (LGNs) and Lookup Table Networks (LUTNs) are demonstrated to be suitable for the automatic classification of electrocardiograms (ECGs) using the inter-patient paradigm. The methods are benchmarked using the MIT-BIH arrhythmia data set, achieving up to 94.28% accuracy and a $jκ$ index of 0.683 on a four-class classification problem. Our models use between 2.8</description>
</item>

<item>
  <title>The Great March 100: 100 Detail-oriented Tasks for Evaluating Embodied AI Agents</title>
  <link>https://arxiv.org/abs/2601.11421v1</link>
  <guid>https://arxiv.org/abs/2601.11421v1</guid>
  <pubDate>Fri, 16 Jan 2026 16:42:05 +0000</pubDate>
  <description>arXiv cs.AI - Recently, with the rapid development of robot learning and imitation learning, numerous datasets and methods have emerged. However, these datasets and their task designs often lack systematic consideration and principles. This raises important questions: Do the current datasets and task designs truly advance the capabilities of robotic agents? Do evaluations on a few common tasks accurately reflec</description>
</item>

<item>
  <title>Factored Value Functions for Graph-Based Multi-Agent Reinforcement Learning</title>
  <link>https://arxiv.org/abs/2601.11401v1</link>
  <guid>https://arxiv.org/abs/2601.11401v1</guid>
  <pubDate>Fri, 16 Jan 2026 16:11:50 +0000</pubDate>
  <description>arXiv cs.LG - Credit assignment is a core challenge in multi-agent reinforcement learning (MARL), especially in large-scale systems with structured, local interactions. Graph-based Markov decision processes (GMDPs) capture such settings via an influence graph, but standard critics are poorly aligned with this structure: global value functions provide weak per-agent learning signals, while existing local constru</description>
</item>

<item>
  <title>Evaluating LLM Behavior in Hiring: Implicit Weights, Fairness Across Groups, and Alignment with Human Preferences</title>
  <link>https://arxiv.org/abs/2601.11379v1</link>
  <guid>https://arxiv.org/abs/2601.11379v1</guid>
  <pubDate>Fri, 16 Jan 2026 15:38:03 +0000</pubDate>
  <description>arXiv cs.AI - General-purpose Large Language Models (LLMs) show significant potential in recruitment applications, where decisions require reasoning over unstructured text, balancing multiple criteria, and inferring fit and competence from indirect productivity signals. Yet, it is still uncertain how LLMs assign importance to each attribute and whether such assignments are in line with economic principles, recr</description>
</item>

<item>
  <title>Institutional AI: Governing LLM Collusion in Multi-Agent Cournot Markets via Public Governance Graphs</title>
  <link>https://arxiv.org/abs/2601.11369v1</link>
  <guid>https://arxiv.org/abs/2601.11369v1</guid>
  <pubDate>Fri, 16 Jan 2026 15:26:56 +0000</pubDate>
  <description>arXiv cs.AI - Multi-agent LLM ensembles can converge on coordinated, socially harmful equilibria. This paper advances an experimental framework for evaluating Institutional AI, our system-level approach to AI alignment that reframes alignment from preference engineering in agent-space to mechanism design in institution-space. Central to this approach is the governance graph, a public, immutable manifest that de</description>
</item>

<item>
  <title>AstroReason-Bench: Evaluating Unified Agentic Planning across Heterogeneous Space Planning Problems</title>
  <link>https://arxiv.org/abs/2601.11354v1</link>
  <guid>https://arxiv.org/abs/2601.11354v1</guid>
  <pubDate>Fri, 16 Jan 2026 15:02:41 +0000</pubDate>
  <description>arXiv cs.AI - Recent advances in agentic Large Language Models (LLMs) have positioned them as generalist planners capable of reasoning and acting across diverse tasks. However, existing agent benchmarks largely focus on symbolic or weakly grounded environments, leaving their performance in physics-constrained real-world domains underexplored. We introduce AstroReason-Bench, a comprehensive benchmark for evaluat</description>
</item>

<item>
  <title>Offline Reinforcement-Learning-Based Power Control for Application-Agnostic Energy Efficiency</title>
  <link>https://arxiv.org/abs/2601.11352v1</link>
  <guid>https://arxiv.org/abs/2601.11352v1</guid>
  <pubDate>Fri, 16 Jan 2026 15:00:17 +0000</pubDate>
  <description>arXiv cs.LG - Energy efficiency has become an integral aspect of modern computing infrastructure design, impacting the performance, cost, scalability, and durability of production systems. The incorporation of power actuation and sensing capabilities in CPU designs is indicative of this, enabling the deployment of system software that can actively monitor and adjust energy consumption and performance at runtime</description>
</item>

<item>
  <title>FEATHer: Fourier-Efficient Adaptive Temporal Hierarchy Forecaster for Time-Series Forecasting</title>
  <link>https://arxiv.org/abs/2601.11350v1</link>
  <guid>https://arxiv.org/abs/2601.11350v1</guid>
  <pubDate>Fri, 16 Jan 2026 14:57:41 +0000</pubDate>
  <description>arXiv cs.AI - Time-series forecasting is fundamental in industrial domains like manufacturing and smart factories. As systems evolve toward automation, models must operate on edge devices (e.g., PLCs, microcontrollers) with strict constraints on latency and memory, limiting parameters to a few thousand. Conventional deep architectures are often impractical here. We propose the Fourier-Efficient Adaptive Tempora</description>
</item>

<item>
  <title>How Much Would a Clinician Edit This Draft? Evaluating LLM Alignment for Patient Message Response Drafting</title>
  <link>https://arxiv.org/abs/2601.11344v1</link>
  <guid>https://arxiv.org/abs/2601.11344v1</guid>
  <pubDate>Fri, 16 Jan 2026 14:48:00 +0000</pubDate>
  <description>arXiv cs.AI - Large language models (LLMs) show promise in drafting responses to patient portal messages, yet their integration into clinical workflows raises various concerns, including whether they would actually save clinicians time and effort in their portal workload. We investigate LLM alignment with individual clinicians through a comprehensive evaluation of the patient message response drafting task. We </description>
</item>

<item>
  <title>DInf-Grid: A Neural Differential Equation Solver with Differentiable Feature Grids</title>
  <link>https://arxiv.org/abs/2601.10715v1</link>
  <guid>https://arxiv.org/abs/2601.10715v1</guid>
  <pubDate>Thu, 15 Jan 2026 18:59:57 +0000</pubDate>
  <description>arXiv cs.LG - We present a novel differentiable grid-based representation for efficiently solving differential equations (DEs). Widely used architectures for neural solvers, such as sinusoidal neural networks, are coordinate-based MLPs that are both computationally intensive and slow to train. Although grid-based alternatives for implicit representations (e.g., Instant-NGP and K-Planes) train faster by exploiti

AI summary: We present a novel differentiable grid-based representation for efficiently solving differential equations (DEs). Widely used architectures for neural solvers, such as sinusoidal neural networks, are coordinate-based MLPs that are both computationally intensive and slow to train. Although grid-based alternatives for implicit representations (e.g., Instant-NGP and K-Planes) train faster by…</description>
</item>

<item>
  <title>MatchTIR: Fine-Grained Supervision for Tool-Integrated Reasoning via Bipartite Matching</title>
  <link>https://arxiv.org/abs/2601.10712v1</link>
  <guid>https://arxiv.org/abs/2601.10712v1</guid>
  <pubDate>Thu, 15 Jan 2026 18:59:23 +0000</pubDate>
  <description>arXiv cs.AI - Tool-Integrated Reasoning (TIR) empowers large language models (LLMs) to tackle complex tasks by interleaving reasoning steps with external tool interactions. However, existing reinforcement learning methods typically rely on outcome- or trajectory-level rewards, assigning uniform advantages to all steps within a trajectory. This coarse-grained credit assignment fails to distinguish effective tool

AI summary: Tool-Integrated Reasoning (TIR) empowers large language models (LLMs) to tackle complex tasks by interleaving reasoning steps with external tool interactions. However, existing reinforcement learning methods typically rely on outcome- or trajectory-level rewards, assigning uniform advantages to all steps within a trajectory. This coarse-grained credit assignment fails to distinguish effective…</description>
</item>

<item>
  <title>High-accuracy and dimension-free sampling with diffusions</title>
  <link>https://arxiv.org/abs/2601.10708v1</link>
  <guid>https://arxiv.org/abs/2601.10708v1</guid>
  <pubDate>Thu, 15 Jan 2026 18:58:50 +0000</pubDate>
  <description>arXiv cs.LG - Diffusion models have shown remarkable empirical success in sampling from rich multi-modal distributions. Their inference relies on numerically solving a certain differential equation. This differential equation cannot be solved in closed form, and its resolution via discretization typically requires many small iterations to produce \emph{high-quality} samples.
  More precisely, prior works have s

AI summary: Diffusion models have shown remarkable empirical success in sampling from rich multi-modal distributions. Their inference relies on numerically solving a certain differential equation. This differential equation cannot be solved in closed form, and its resolution via discretization typically requires many small iterations to produce \emph{high-quality} samples. More precisely, prior works have…</description>
</item>

<item>
  <title>See Less, Drive Better: Generalizable End-to-End Autonomous Driving via Foundation Models Stochastic Patch Selection</title>
  <link>https://arxiv.org/abs/2601.10707v1</link>
  <guid>https://arxiv.org/abs/2601.10707v1</guid>
  <pubDate>Thu, 15 Jan 2026 18:58:33 +0000</pubDate>
  <description>arXiv cs.LG - Recent advances in end-to-end autonomous driving show that policies trained on patch-aligned features extracted from foundation models generalize better to Out-of-Distribution (OOD). We hypothesize that due to the self-attention mechanism, each patch feature implicitly embeds/contains information from all other patches, represented in a different way and intensity, making these descriptors highly 

AI summary: Recent advances in end-to-end autonomous driving show that policies trained on patch-aligned features extracted from foundation models generalize better to Out-of-Distribution (OOD). We hypothesize that due to the self-attention mechanism, each patch feature implicitly embeds/contains information from all other patches, represented in a different way and intensity, making these descriptors…</description>
</item>

<item>
  <title>Distributed Perceptron under Bounded Staleness, Partial Participation, and Noisy Communication</title>
  <link>https://arxiv.org/abs/2601.10705v1</link>
  <guid>https://arxiv.org/abs/2601.10705v1</guid>
  <pubDate>Thu, 15 Jan 2026 18:56:54 +0000</pubDate>
  <description>arXiv cs.LG - We study a semi-asynchronous client-server perceptron trained via iterative parameter mixing (IPM-style averaging): clients run local perceptron updates and a server forms a global model by aggregating the updates that arrive in each communication round. The setting captures three system effects in federated and distributed deployments: (i) stale updates due to delayed model delivery and delayed a

AI summary: We study a semi-asynchronous client-server perceptron trained via iterative parameter mixing (IPM-style averaging): clients run local perceptron updates and a server forms a global model by aggregating the updates that arrive in each communication round. The setting captures three system effects in federated and distributed deployments: (i) stale updates due to delayed model delivery and delayed…</description>
</item>

<item>
  <title>Grounding Agent Memory in Contextual Intent</title>
  <link>https://arxiv.org/abs/2601.10702v1</link>
  <guid>https://arxiv.org/abs/2601.10702v1</guid>
  <pubDate>Thu, 15 Jan 2026 18:55:13 +0000</pubDate>
  <description>arXiv cs.AI - Deploying large language models in long-horizon, goal-oriented interactions remains challenging because similar entities and facts recur under different latent goals and constraints, causing memory systems to retrieve context-mismatched evidence. We propose STITCH (Structured Intent Tracking in Contextual History), an agentic memory system that indexes each trajectory step with a structured retrie

AI summary: Deploying large language models in long-horizon, goal-oriented interactions remains challenging because similar entities and facts recur under different latent goals and constraints, causing memory systems to retrieve context-mismatched evidence. We propose STITCH (Structured Intent Tracking in Contextual History), an agentic memory system that indexes each trajectory step with a structured…</description>
</item>

<item>
  <title>Communication-Efficient and Privacy-Adaptable Mechanism -- a Federated Learning Scheme with Convergence Analysis</title>
  <link>https://arxiv.org/abs/2601.10701v1</link>
  <guid>https://arxiv.org/abs/2601.10701v1</guid>
  <pubDate>Thu, 15 Jan 2026 18:55:00 +0000</pubDate>
  <description>arXiv cs.LG - Federated learning enables multiple parties to jointly train learning models without sharing their own underlying data, offering a practical pathway to privacy-preserving collaboration under data-governance constraints. Continued study of federated learning is essential to address key challenges in it, including communication efficiency and privacy protection between parties. A recent line of work

AI summary: Federated learning enables multiple parties to jointly train learning models without sharing their own underlying data, offering a practical pathway to privacy-preserving collaboration under data-governance constraints. Continued study of federated learning is essential to address key challenges in it, including communication efficiency and privacy protection between parties. A recent line of…</description>
</item>

<item>
  <title>LIBERTy: A Causal Framework for Benchmarking Concept-Based Explanations of LLMs with Structural Counterfactuals</title>
  <link>https://arxiv.org/abs/2601.10700v1</link>
  <guid>https://arxiv.org/abs/2601.10700v1</guid>
  <pubDate>Thu, 15 Jan 2026 18:54:50 +0000</pubDate>
  <description>arXiv cs.AI - Concept-based explanations quantify how high-level concepts (e.g., gender or experience) influence model behavior, which is crucial for decision-makers in high-stakes domains. Recent work evaluates the faithfulness of such explanations by comparing them to reference causal effects estimated from counterfactuals. In practice, existing benchmarks rely on costly human-written counterfactuals that ser

AI summary: Concept-based explanations quantify how high-level concepts (e.g., gender or experience) influence model behavior, which is crucial for decision-makers in high-stakes domains. Recent work evaluates the faithfulness of such explanations by comparing them to reference causal effects estimated from counterfactuals. In practice, existing benchmarks rely on costly human-written counterfactuals that…</description>
</item>

<item>
  <title>The Impact of Generative AI on Architectural Conceptual Design: Performance, Creative Self-Efficacy and Cognitive Load</title>
  <link>https://arxiv.org/abs/2601.10696v1</link>
  <guid>https://arxiv.org/abs/2601.10696v1</guid>
  <pubDate>Thu, 15 Jan 2026 18:52:59 +0000</pubDate>
  <description>arXiv cs.AI - Our study examines how generative AI (GenAI) influences performance, creative self-efficacy, and cognitive load in architectural conceptual design tasks. Thirty-six student participants from Architectural Engineering and other disciplines completed a two-phase architectural design task, first independently and then with external tools (GenAI-assisted condition and control condition using an online

AI summary: Our study examines how generative AI (GenAI) influences performance, creative self-efficacy, and cognitive load in architectural conceptual design tasks. Thirty-six student participants from Architectural Engineering and other disciplines completed a two-phase architectural design task, first independently and then with external tools (GenAI-assisted condition and control condition using an…</description>
</item>

<item>
  <title>Data-driven stochastic reduced-order modeling of parametrized dynamical systems</title>
  <link>https://arxiv.org/abs/2601.10690v1</link>
  <guid>https://arxiv.org/abs/2601.10690v1</guid>
  <pubDate>Thu, 15 Jan 2026 18:50:18 +0000</pubDate>
  <description>arXiv cs.LG - Modeling complex dynamical systems under varying conditions is computationally intensive, often rendering high-fidelity simulations intractable. Although reduced-order models (ROMs) offer a promising solution, current methods often struggle with stochastic dynamics and fail to quantify prediction uncertainty, limiting their utility in robust decision-making contexts. To address these challenges, w

AI summary: Modeling complex dynamical systems under varying conditions is computationally intensive, often rendering high-fidelity simulations intractable. Although reduced-order models (ROMs) offer a promising solution, current methods often struggle with stochastic dynamics and fail to quantify prediction uncertainty, limiting their utility in robust decision-making contexts. To address these challenges,…</description>
</item>

<item>
  <title>On the origin of neural scaling laws: from random graphs to natural language</title>
  <link>https://arxiv.org/abs/2601.10684v1</link>
  <guid>https://arxiv.org/abs/2601.10684v1</guid>
  <pubDate>Thu, 15 Jan 2026 18:46:09 +0000</pubDate>
  <description>arXiv cs.AI - Scaling laws have played a major role in the modern AI revolution, providing practitioners predictive power over how the model performance will improve with increasing data, compute, and number of model parameters. This has spurred an intense interest in the origin of neural scaling laws, with a common suggestion being that they arise from power law structure already present in the data. In this p

AI summary: Scaling laws have played a major role in the modern AI revolution, providing practitioners predictive power over how the model performance will improve with increasing data, compute, and number of model parameters. This has spurred an intense interest in the origin of neural scaling laws, with a common suggestion being that they arise from power law structure already present in the data. In this…</description>
</item>

<item>
  <title>On the origin of neural scaling laws: from random graphs to natural language</title>
  <link>https://arxiv.org/abs/2601.10684v1</link>
  <guid>https://arxiv.org/abs/2601.10684v1</guid>
  <pubDate>Thu, 15 Jan 2026 18:46:09 +0000</pubDate>
  <description>arXiv cs.LG - Scaling laws have played a major role in the modern AI revolution, providing practitioners predictive power over how the model performance will improve with increasing data, compute, and number of model parameters. This has spurred an intense interest in the origin of neural scaling laws, with a common suggestion being that they arise from power law structure already present in the data. In this p

AI summary: Scaling laws have played a major role in the modern AI revolution, providing practitioners predictive power over how the model performance will improve with increasing data, compute, and number of model parameters. This has spurred an intense interest in the origin of neural scaling laws, with a common suggestion being that they arise from power law structure already present in the data. In this…</description>
</item>

<item>
  <title>Structure and Diversity Aware Context Bubble Construction for Enterprise Retrieval Augmented Systems</title>
  <link>https://arxiv.org/abs/2601.10681v1</link>
  <guid>https://arxiv.org/abs/2601.10681v1</guid>
  <pubDate>Thu, 15 Jan 2026 18:43:19 +0000</pubDate>
  <description>arXiv cs.AI - Large language model (LLM) contexts are typically constructed using retrieval-augmented generation (RAG), which involves ranking and selecting the top-k passages. The approach causes fragmentation in information graphs in document structures, over-retrieval, and duplication of content alongside insufficient query context, including 2nd and 3rd order facets. In this paper, a structure-informed and 

AI summary: Large language model (LLM) contexts are typically constructed using retrieval-augmented generation (RAG), which involves ranking and selecting the top-k passages. The approach causes fragmentation in information graphs in document structures, over-retrieval, and duplication of content alongside insufficient query context, including 2nd and 3rd order facets. In this paper, a structure-informed…</description>
</item>

<item>
  <title>Are Your Reasoning Models Reasoning or Guessing? A Mechanistic Analysis of Hierarchical Reasoning Models</title>
  <link>https://arxiv.org/abs/2601.10679v1</link>
  <guid>https://arxiv.org/abs/2601.10679v1</guid>
  <pubDate>Thu, 15 Jan 2026 18:42:50 +0000</pubDate>
  <description>arXiv cs.AI - Hierarchical reasoning model (HRM) achieves extraordinary performance on various reasoning tasks, significantly outperforming large language model-based reasoners. To understand the strengths and potential failure modes of HRM, we conduct a mechanistic study on its reasoning patterns and find three surprising facts: (a) Failure of extremely simple puzzles, e.g., HRM can fail on a puzzle with only 

AI summary: Hierarchical reasoning model (HRM) achieves extraordinary performance on various reasoning tasks, significantly outperforming large language model-based reasoners. To understand the strengths and potential failure modes of HRM, we conduct a mechanistic study on its reasoning patterns and find three surprising facts: (a) Failure of extremely simple puzzles, e.g., HRM can fail on a puzzle with…</description>
</item>

<item>
  <title>Are Your Reasoning Models Reasoning or Guessing? A Mechanistic Analysis of Hierarchical Reasoning Models</title>
  <link>https://arxiv.org/abs/2601.10679v1</link>
  <guid>https://arxiv.org/abs/2601.10679v1</guid>
  <pubDate>Thu, 15 Jan 2026 18:42:50 +0000</pubDate>
  <description>arXiv cs.LG - Hierarchical reasoning model (HRM) achieves extraordinary performance on various reasoning tasks, significantly outperforming large language model-based reasoners. To understand the strengths and potential failure modes of HRM, we conduct a mechanistic study on its reasoning patterns and find three surprising facts: (a) Failure of extremely simple puzzles, e.g., HRM can fail on a puzzle with only 

AI summary: Hierarchical reasoning model (HRM) achieves extraordinary performance on various reasoning tasks, significantly outperforming large language model-based reasoners. To understand the strengths and potential failure modes of HRM, we conduct a mechanistic study on its reasoning patterns and find three surprising facts: (a) Failure of extremely simple puzzles, e.g., HRM can fail on a puzzle with…</description>
</item>

<item>
  <title>Single-Stage Huffman Encoder for ML Compression</title>
  <link>https://arxiv.org/abs/2601.10673v1</link>
  <guid>https://arxiv.org/abs/2601.10673v1</guid>
  <pubDate>Thu, 15 Jan 2026 18:37:56 +0000</pubDate>
  <description>arXiv cs.LG - Training and serving Large Language Models (LLMs) require partitioning data across multiple accelerators, where collective operations are frequently bottlenecked by network bandwidth. Lossless compression using Huffman codes is an effective way to alleviate the issue, however, its three-stage design requiring on-the-fly frequency analysis, codebook generation and transmission of codebook along wit

AI summary: Training and serving Large Language Models (LLMs) require partitioning data across multiple accelerators, where collective operations are frequently bottlenecked by network bandwidth. Lossless compression using Huffman codes is an effective way to alleviate the issue, however, its three-stage design requiring on-the-fly frequency analysis, codebook generation and transmission of codebook along…</description>
</item>

<item>
  <title>PACEvolve: Enabling Long-Horizon Progress-Aware Consistent Evolution</title>
  <link>https://arxiv.org/abs/2601.10657v1</link>
  <guid>https://arxiv.org/abs/2601.10657v1</guid>
  <pubDate>Thu, 15 Jan 2026 18:25:23 +0000</pubDate>
  <description>arXiv cs.LG - Large Language Models (LLMs) have emerged as powerful operators for evolutionary search, yet the design of efficient search scaffolds remains ad hoc. While promising, current LLM-in-the-loop systems lack a systematic approach to managing the evolutionary process. We identify three distinct failure modes: Context Pollution, where experiment history biases future candidate generation; Mode Collapse,

AI summary: Large Language Models (LLMs) have emerged as powerful operators for evolutionary search, yet the design of efficient search scaffolds remains ad hoc. While promising, current LLM-in-the-loop systems lack a systematic approach to managing the evolutionary process. We identify three distinct failure modes: Context Pollution, where experiment history biases future candidate generation; Mode…</description>
</item>

<item>
  <title>Multi-Property Synthesis</title>
  <link>https://arxiv.org/abs/2601.10651v1</link>
  <guid>https://arxiv.org/abs/2601.10651v1</guid>
  <pubDate>Thu, 15 Jan 2026 18:18:33 +0000</pubDate>
  <description>arXiv cs.AI - We study LTLf synthesis with multiple properties, where satisfying all properties may be impossible. Instead of enumerating subsets of properties, we compute in one fixed-point computation the relation between product-game states and the goal sets that are realizable from them, and we synthesize strategies achieving maximal realizable sets. We develop a fully symbolic algorithm that introduces Boo

AI summary: We study LTLf synthesis with multiple properties, where satisfying all properties may be impossible. Instead of enumerating subsets of properties, we compute in one fixed-point computation the relation between product-game states and the goal sets that are realizable from them, and we synthesize strategies achieving maximal realizable sets. We develop a fully symbolic algorithm that introduces…</description>
</item>

<item>
  <title>Adjusted Similarity Measures and a Violation of Expectations</title>
  <link>https://arxiv.org/abs/2601.10641v1</link>
  <guid>https://arxiv.org/abs/2601.10641v1</guid>
  <pubDate>Thu, 15 Jan 2026 18:01:26 +0000</pubDate>
  <description>arXiv cs.LG - Adjusted similarity measures, such as Cohen&apos;s kappa for inter-rater reliability and the adjusted Rand index used to compare clustering algorithms, are a vital tool for comparing discrete labellings. These measures are intended to have the property of 0 expectation under a null distribution and maximum value 1 under maximal similarity to aid in interpretation. Measures are frequently adjusted with 

AI summary: Adjusted similarity measures, such as Cohen&apos;s kappa for inter-rater reliability and the adjusted Rand index used to compare clustering algorithms, are a vital tool for comparing discrete labellings. These measures are intended to have the property of 0 expectation under a null distribution and maximum value 1 under maximal similarity to aid in interpretation. Measures are frequently adjusted…</description>
</item>

<item>
  <title>STEM: Scaling Transformers with Embedding Modules</title>
  <link>https://arxiv.org/abs/2601.10639v1</link>
  <guid>https://arxiv.org/abs/2601.10639v1</guid>
  <pubDate>Thu, 15 Jan 2026 18:00:27 +0000</pubDate>
  <description>arXiv cs.LG - Fine-grained sparsity promises higher parametric capacity without proportional per-token compute, but often suffers from training instability, load balancing, and communication overhead. We introduce STEM (Scaling Transformers with Embedding Modules), a static, token-indexed approach that replaces the FFN up-projection with a layer-local embedding lookup while keeping the gate and down-projection 

AI summary: Fine-grained sparsity promises higher parametric capacity without proportional per-token compute, but often suffers from training instability, load balancing, and communication overhead. We introduce STEM (Scaling Transformers with Embedding Modules), a static, token-indexed approach that replaces the FFN up-projection with a layer-local embedding lookup while keeping the gate and…</description>
</item>

<item>
  <title>Classification Imbalance as Transfer Learning</title>
  <link>https://arxiv.org/abs/2601.10630v1</link>
  <guid>https://arxiv.org/abs/2601.10630v1</guid>
  <pubDate>Thu, 15 Jan 2026 17:49:36 +0000</pubDate>
  <description>arXiv cs.LG - Classification imbalance arises when one class is much rarer than the other. We frame this setting as transfer learning under label (prior) shift between an imbalanced source distribution induced by the observed data and a balanced target distribution under which performance is evaluated. Within this framework, we study a family of oversampling procedures that augment the training data by generati

AI summary: Classification imbalance arises when one class is much rarer than the other. We frame this setting as transfer learning under label (prior) shift between an imbalanced source distribution induced by the observed data and a balanced target distribution under which performance is evaluated. Within this framework, we study a family of oversampling procedures that augment the training data by…</description>
</item>

<item>
  <title>Parametric RDT approach to computational gap of symmetric binary perceptron</title>
  <link>https://arxiv.org/abs/2601.10628v1</link>
  <guid>https://arxiv.org/abs/2601.10628v1</guid>
  <pubDate>Thu, 15 Jan 2026 17:48:58 +0000</pubDate>
  <description>arXiv cs.LG - We study potential presence of statistical-computational gaps (SCG) in symmetric binary perceptrons (SBP) via a parametric utilization of \emph{fully lifted random duality theory} (fl-RDT) [96]. A structural change from decreasingly to arbitrarily ordered $c$-sequence (a key fl-RDT parametric component) is observed on the second lifting level and associated with \emph{satisfiability} ($α_c$) -- \e

AI summary: We study potential presence of statistical-computational gaps (SCG) in symmetric binary perceptrons (SBP) via a parametric utilization of \emph{fully lifted random duality theory} (fl-RDT) [96]. A structural change from decreasingly to arbitrarily ordered $c$-sequence (a key fl-RDT parametric component) is observed on the second lifting level and associated with \emph{satisfiability} ($α_c$) --…</description>
</item>

<item>
  <title>Molmo2: Open Weights and Data for Vision-Language Models with Video Understanding and Grounding</title>
  <link>https://arxiv.org/abs/2601.10611v1</link>
  <guid>https://arxiv.org/abs/2601.10611v1</guid>
  <pubDate>Thu, 15 Jan 2026 17:27:44 +0000</pubDate>
  <description>arXiv cs.AI - Today&apos;s strongest video-language models (VLMs) remain proprietary. The strongest open-weight models either rely on synthetic data from proprietary VLMs, effectively distilling from them, or do not disclose their training data or recipe. As a result, the open-source community lacks the foundations needed to improve on the state-of-the-art video (and image) language models. Crucially, many downstrea

AI summary: Today&apos;s strongest video-language models (VLMs) remain proprietary. The strongest open-weight models either rely on synthetic data from proprietary VLMs, effectively distilling from them, or do not disclose their training data or recipe. As a result, the open-source community lacks the foundations needed to improve on the state-of-the-art video (and image) language models. Crucially, many…</description>
</item>

<item>
  <title>Procedural Fairness in Multi-Agent Bandits</title>
  <link>https://arxiv.org/abs/2601.10600v1</link>
  <guid>https://arxiv.org/abs/2601.10600v1</guid>
  <pubDate>Thu, 15 Jan 2026 17:11:51 +0000</pubDate>
  <description>arXiv cs.AI - In the context of multi-agent multi-armed bandits (MA-MAB), fairness is often reduced to outcomes: maximizing welfare, reducing inequality, or balancing utilities. However, evidence in psychology, economics, and Rawlsian theory suggests that fairness is also about process and who gets a say in the decisions being made. We introduce a new fairness objective, procedural fairness, which provides equa

AI summary: In the context of multi-agent multi-armed bandits (MA-MAB), fairness is often reduced to outcomes: maximizing welfare, reducing inequality, or balancing utilities. However, evidence in psychology, economics, and Rawlsian theory suggests that fairness is also about process and who gets a say in the decisions being made. We introduce a new fairness objective, procedural fairness, which provides…</description>
</item>

<item>
  <title>Procedural Fairness in Multi-Agent Bandits</title>
  <link>https://arxiv.org/abs/2601.10600v1</link>
  <guid>https://arxiv.org/abs/2601.10600v1</guid>
  <pubDate>Thu, 15 Jan 2026 17:11:51 +0000</pubDate>
  <description>arXiv cs.LG - In the context of multi-agent multi-armed bandits (MA-MAB), fairness is often reduced to outcomes: maximizing welfare, reducing inequality, or balancing utilities. However, evidence in psychology, economics, and Rawlsian theory suggests that fairness is also about process and who gets a say in the decisions being made. We introduce a new fairness objective, procedural fairness, which provides equa

AI summary: In the context of multi-agent multi-armed bandits (MA-MAB), fairness is often reduced to outcomes: maximizing welfare, reducing inequality, or balancing utilities. However, evidence in psychology, economics, and Rawlsian theory suggests that fairness is also about process and who gets a say in the decisions being made. We introduce a new fairness objective, procedural fairness, which provides…</description>
</item>

<item>
  <title>ProbFM: Probabilistic Time Series Foundation Model with Uncertainty Decomposition</title>
  <link>https://arxiv.org/abs/2601.10591v1</link>
  <guid>https://arxiv.org/abs/2601.10591v1</guid>
  <pubDate>Thu, 15 Jan 2026 17:02:06 +0000</pubDate>
  <description>arXiv cs.AI - Time Series Foundation Models (TSFMs) have emerged as a promising approach for zero-shot financial forecasting, demonstrating strong transferability and data efficiency gains. However, their adoption in financial applications is hindered by fundamental limitations in uncertainty quantification: current approaches either rely on restrictive distributional assumptions, conflate different sources of 

AI summary: Time Series Foundation Models (TSFMs) have emerged as a promising approach for zero-shot financial forecasting, demonstrating strong transferability and data efficiency gains. However, their adoption in financial applications is hindered by fundamental limitations in uncertainty quantification: current approaches either rely on restrictive distributional assumptions, conflate different sources…</description>
</item>

<item>
  <title>ProbFM: Probabilistic Time Series Foundation Model with Uncertainty Decomposition</title>
  <link>https://arxiv.org/abs/2601.10591v1</link>
  <guid>https://arxiv.org/abs/2601.10591v1</guid>
  <pubDate>Thu, 15 Jan 2026 17:02:06 +0000</pubDate>
  <description>arXiv cs.LG - Time Series Foundation Models (TSFMs) have emerged as a promising approach for zero-shot financial forecasting, demonstrating strong transferability and data efficiency gains. However, their adoption in financial applications is hindered by fundamental limitations in uncertainty quantification: current approaches either rely on restrictive distributional assumptions, conflate different sources of 

AI summary: Time Series Foundation Models (TSFMs) have emerged as a promising approach for zero-shot financial forecasting, demonstrating strong transferability and data efficiency gains. However, their adoption in financial applications is hindered by fundamental limitations in uncertainty quantification: current approaches either rely on restrictive distributional assumptions, conflate different sources…</description>
</item>

<item>
  <title>Searching for Quantum Effects in the Brain: A Bell-Type Test for Nonclassical Latent Representations in Autoencoders</title>
  <link>https://arxiv.org/abs/2601.10588v1</link>
  <guid>https://arxiv.org/abs/2601.10588v1</guid>
  <pubDate>Thu, 15 Jan 2026 16:59:40 +0000</pubDate>
  <description>arXiv cs.LG - Whether neural information processing is entirely classical or involves quantum-mechanical elements remains an open question. Here we propose a model-agnostic, information-theoretic test of nonclassicality that bypasses microscopic assumptions and instead probes the structure of neural representations themselves. Using autoencoders as a transparent model system, we introduce a Bell-type consistenc

AI summary: Whether neural information processing is entirely classical or involves quantum-mechanical elements remains an open question. Here we propose a model-agnostic, information-theoretic test of nonclassicality that bypasses microscopic assumptions and instead probes the structure of neural representations themselves. Using autoencoders as a transparent model system, we introduce a Bell-type…</description>
</item>

<item>
  <title>Adversarial Evasion Attacks on Computer Vision using SHAP Values</title>
  <link>https://arxiv.org/abs/2601.10587v1</link>
  <guid>https://arxiv.org/abs/2601.10587v1</guid>
  <pubDate>Thu, 15 Jan 2026 16:58:55 +0000</pubDate>
  <description>arXiv cs.AI - The paper introduces a white-box attack on computer vision models using SHAP values. It demonstrates how adversarial evasion attacks can compromise the performance of deep learning models by reducing output confidence or inducing misclassifications. Such attacks are particularly insidious as they can deceive the perception of an algorithm while eluding human perception due to their imperceptibilit

AI summary: The paper introduces a white-box attack on computer vision models using SHAP values. It demonstrates how adversarial evasion attacks can compromise the performance of deep learning models by reducing output confidence or inducing misclassifications. Such attacks are particularly insidious as they can deceive the perception of an algorithm while eluding human perception due to their…</description>
</item>

<item>
  <title>Combinatorial Optimization Augmented Machine Learning</title>
  <link>https://arxiv.org/abs/2601.10583v1</link>
  <guid>https://arxiv.org/abs/2601.10583v1</guid>
  <pubDate>Thu, 15 Jan 2026 16:55:19 +0000</pubDate>
  <description>arXiv cs.LG - Combinatorial optimization augmented machine learning (COAML) has recently emerged as a powerful paradigm for integrating predictive models with combinatorial decision-making. By embedding combinatorial optimization oracles into learning pipelines, COAML enables the construction of policies that are both data-driven and feasibility-preserving, bridging the traditions of machine learning, operation

AI summary: Combinatorial optimization augmented machine learning (COAML) has recently emerged as a powerful paradigm for integrating predictive models with combinatorial decision-making. By embedding combinatorial optimization oracles into learning pipelines, COAML enables the construction of policies that are both data-driven and feasibility-preserving, bridging the traditions of machine learning,…</description>
</item>

<item>
  <title>From Single to Multi-Agent Reasoning: Advancing GeneGPT for Genomics QA</title>
  <link>https://arxiv.org/abs/2601.10581v1</link>
  <guid>https://arxiv.org/abs/2601.10581v1</guid>
  <pubDate>Thu, 15 Jan 2026 16:54:11 +0000</pubDate>
  <description>arXiv cs.AI - Comprehending genomic information is essential for biomedical research, yet extracting data from complex distributed databases remains challenging. Large language models (LLMs) offer potential for genomic Question Answering (QA) but face limitations due to restricted access to domain-specific databases. GeneGPT is the current state-of-the-art system that enhances LLMs by utilizing specialized API 

AI summary: Comprehending genomic information is essential for biomedical research, yet extracting data from complex distributed databases remains challenging. Large language models (LLMs) offer potential for genomic Question Answering (QA) but face limitations due to restricted access to domain-specific databases. GeneGPT is the current state-of-the-art system that enhances LLMs by utilizing specialized…</description>
</item>

<item>
  <title>Generative AI collective behavior needs an interactionist paradigm</title>
  <link>https://arxiv.org/abs/2601.10567v1</link>
  <guid>https://arxiv.org/abs/2601.10567v1</guid>
  <pubDate>Thu, 15 Jan 2026 16:29:23 +0000</pubDate>
  <description>arXiv cs.AI - In this article, we argue that understanding the collective behavior of agents based on large language models (LLMs) is an essential area of inquiry, with important implications in terms of risks and benefits, impacting us as a society at many levels. We claim that the distinctive nature of LLMs--namely, their initialization with extensive pre-trained knowledge and implicit social priors, together

AI summary: In this article, we argue that understanding the collective behavior of agents based on large language models (LLMs) is an essential area of inquiry, with important implications in terms of risks and benefits, impacting us as a society at many levels. We claim that the distinctive nature of LLMs--namely, their initialization with extensive pre-trained knowledge and implicit social priors,…</description>
</item>

<item>
  <title>Generative AI collective behavior needs an interactionist paradigm</title>
  <link>https://arxiv.org/abs/2601.10567v1</link>
  <guid>https://arxiv.org/abs/2601.10567v1</guid>
  <pubDate>Thu, 15 Jan 2026 16:29:23 +0000</pubDate>
  <description>arXiv cs.LG - In this article, we argue that understanding the collective behavior of agents based on large language models (LLMs) is an essential area of inquiry, with important implications in terms of risks and benefits, impacting us as a society at many levels. We claim that the distinctive nature of LLMs--namely, their initialization with extensive pre-trained knowledge and implicit social priors, together

AI summary: In this article, we argue that understanding the collective behavior of agents based on large language models (LLMs) is an essential area of inquiry, with important implications in terms of risks and benefits, impacting us as a society at many levels. We claim that the distinctive nature of LLMs--namely, their initialization with extensive pre-trained knowledge and implicit social priors,…</description>
</item>

<item>
  <title>Representation-Aware Unlearning via Activation Signatures: From Suppression to Knowledge-Signature Erasure</title>
  <link>https://arxiv.org/abs/2601.10566v1</link>
  <guid>https://arxiv.org/abs/2601.10566v1</guid>
  <pubDate>Thu, 15 Jan 2026 16:28:14 +0000</pubDate>
  <description>arXiv cs.LG - Selective knowledge erasure from LLMs is critical for GDPR compliance and model safety, yet current unlearning methods conflate behavioral suppression with true knowledge removal, allowing latent capabilities to persist beneath surface-level refusals. In this work, we address this challenge by introducing Knowledge Immunization Framework (KIF), a representation-aware architecture that distinguishe

AI summary: Selective knowledge erasure from LLMs is critical for GDPR compliance and model safety, yet current unlearning methods conflate behavioral suppression with true knowledge removal, allowing latent capabilities to persist beneath surface-level refusals. In this work, we address this challenge by introducing Knowledge Immunization Framework (KIF), a representation-aware architecture that…</description>
</item>

<item>
  <title>Kolmogorov Arnold Networks and Multi-Layer Perceptrons: A Paradigm Shift in Neural Modelling</title>
  <link>https://arxiv.org/abs/2601.10563v1</link>
  <guid>https://arxiv.org/abs/2601.10563v1</guid>
  <pubDate>Thu, 15 Jan 2026 16:26:49 +0000</pubDate>
  <description>arXiv cs.LG - The research undertakes a comprehensive comparative analysis of Kolmogorov-Arnold Networks (KAN) and Multi-Layer Perceptrons (MLP), highlighting their effectiveness in solving essential computational challenges like nonlinear function approximation, time-series prediction, and multivariate classification. Rooted in Kolmogorov&apos;s representation theorem, KANs utilize adaptive spline-based activation 

AI summary: The research undertakes a comprehensive comparative analysis of Kolmogorov-Arnold Networks (KAN) and Multi-Layer Perceptrons (MLP), highlighting their effectiveness in solving essential computational challenges like nonlinear function approximation, time-series prediction, and multivariate classification. Rooted in Kolmogorov&apos;s representation theorem, KANs utilize adaptive spline-based…</description>
</item>

<item>
  <title>Process-Guided Concept Bottleneck Model</title>
  <link>https://arxiv.org/abs/2601.10562v1</link>
  <guid>https://arxiv.org/abs/2601.10562v1</guid>
  <pubDate>Thu, 15 Jan 2026 16:25:55 +0000</pubDate>
  <description>arXiv cs.AI - Concept Bottleneck Models (CBMs) improve the explainability of black-box Deep Learning (DL) by introducing intermediate semantic concepts. However, standard CBMs often overlook domain-specific relationships and causal mechanisms, and their dependence on complete concept labels limits applicability in scientific domains where supervision is sparse but processes are well defined. To address this, we

AI summary: Concept Bottleneck Models (CBMs) improve the explainability of black-box Deep Learning (DL) by introducing intermediate semantic concepts. However, standard CBMs often overlook domain-specific relationships and causal mechanisms, and their dependence on complete concept labels limits applicability in scientific domains where supervision is sparse but processes are well defined. To address this,…</description>
</item>

<item>
  <title>Process-Guided Concept Bottleneck Model</title>
  <link>https://arxiv.org/abs/2601.10562v1</link>
  <guid>https://arxiv.org/abs/2601.10562v1</guid>
  <pubDate>Thu, 15 Jan 2026 16:25:55 +0000</pubDate>
  <description>arXiv cs.LG - Concept Bottleneck Models (CBMs) improve the explainability of black-box Deep Learning (DL) by introducing intermediate semantic concepts. However, standard CBMs often overlook domain-specific relationships and causal mechanisms, and their dependence on complete concept labels limits applicability in scientific domains where supervision is sparse but processes are well defined. To address this, we

AI summary: Concept Bottleneck Models (CBMs) improve the explainability of black-box Deep Learning (DL) by introducing intermediate semantic concepts. However, standard CBMs often overlook domain-specific relationships and causal mechanisms, and their dependence on complete concept labels limits applicability in scientific domains where supervision is sparse but processes are well defined. To address this,…</description>
</item>

</channel>
</rss>
