<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
<channel>
  <title>AI Research Digest</title>
  <link>https://xiaolin-econ.github.io/ai-digest/</link>
  <description>Curated AI research + releases</description>
  <lastBuildDate>Mon, 02 Feb 2026 06:52:31 +0000</lastBuildDate>
  <atom:link href="https://xiaolin-econ.github.io/ai-digest/rss.xml" rel="self" type="application/rss+xml" xmlns:atom="http://www.w3.org/2005/Atom"/>
  
<item>
  <title>AI Digest — Daily Summary</title>
  <link>https://xiaolin-econ.github.io/ai-digest/rss.xml</link>
  <guid>https://xiaolin-econ.github.io/ai-digest/rss.xml#summary</guid>
  <pubDate>Mon, 02 Feb 2026 06:52:31 +0000</pubDate>
  <description>Shared autonomy systems require principled methods for inferring user intent and determining appropriate assistance levels. This is a central challenge in human-robot interaction, where systems must be successful while being mindful of user agency. Previous approaches relied on static blending ratios or separated goal inference from assistance arbitration, leading to suboptimal performance in unstructured environments. We introduce BRACE (Bayesian Reinforcement Assistance with Context Encoding), a novel framework that fine-tunes Bayesian intent inference and context-adaptive assistance through an architecture enabling end-to-end gradient flow between intent inference and assistance arbitration. Our pipeline conditions collaborative control policies on environmental context and complete…</description>
</item>

<item>
  <title>End-to-end Optimization of Belief and Policy Learning in Shared Autonomy Paradigms</title>
  <link>https://arxiv.org/abs/2601.23285v1</link>
  <guid>https://arxiv.org/abs/2601.23285v1</guid>
  <pubDate>Fri, 30 Jan 2026 18:59:16 +0000</pubDate>
  <description>arXiv cs.AI - Shared autonomy systems require principled methods for inferring user intent and determining appropriate assistance levels. This is a central challenge in human-robot interaction, where systems must be successful while being mindful of user agency. Previous approaches relied on static blending ratios or separated goal inference from assistance arbitration, leading to suboptimal performance in unst</description>
</item>

<item>
  <title>End-to-end Optimization of Belief and Policy Learning in Shared Autonomy Paradigms</title>
  <link>https://arxiv.org/abs/2601.23285v1</link>
  <guid>https://arxiv.org/abs/2601.23285v1</guid>
  <pubDate>Fri, 30 Jan 2026 18:59:16 +0000</pubDate>
  <description>arXiv cs.LG - Shared autonomy systems require principled methods for inferring user intent and determining appropriate assistance levels. This is a central challenge in human-robot interaction, where systems must be successful while being mindful of user agency. Previous approaches relied on static blending ratios or separated goal inference from assistance arbitration, leading to suboptimal performance in unst</description>
</item>

<item>
  <title>FOCUS: DLLMs Know How to Tame Their Compute Bound</title>
  <link>https://arxiv.org/abs/2601.23278v1</link>
  <guid>https://arxiv.org/abs/2601.23278v1</guid>
  <pubDate>Fri, 30 Jan 2026 18:52:06 +0000</pubDate>
  <description>arXiv cs.LG - Diffusion Large Language Models (DLLMs) offer a compelling alternative to Auto-Regressive models, but their deployment is constrained by high decoding cost. In this work, we identify a key inefficiency in DLLM decoding: while computation is parallelized over token blocks, only a small subset of tokens is decodable at each diffusion step, causing most compute to be wasted on non-decodable tokens. W</description>
</item>

<item>
  <title>Denoising the Deep Sky: Physics-Based CCD Noise Formation for Astronomical Imaging</title>
  <link>https://arxiv.org/abs/2601.23276v1</link>
  <guid>https://arxiv.org/abs/2601.23276v1</guid>
  <pubDate>Fri, 30 Jan 2026 18:47:54 +0000</pubDate>
  <description>arXiv cs.LG - Astronomical imaging remains noise-limited under practical observing constraints, while standard calibration pipelines mainly remove structured artifacts and leave stochastic noise largely unresolved. Learning-based denoising is promising, yet progress is hindered by scarce paired training data and the need for physically interpretable and reproducible models in scientific workflows. We propose a </description>
</item>

<item>
  <title>IRL-DAL: Safe and Adaptive Trajectory Planning for Autonomous Driving via Energy-Guided Diffusion Models</title>
  <link>https://arxiv.org/abs/2601.23266v1</link>
  <guid>https://arxiv.org/abs/2601.23266v1</guid>
  <pubDate>Fri, 30 Jan 2026 18:34:10 +0000</pubDate>
  <description>arXiv cs.AI - This paper proposes a novel inverse reinforcement learning framework using a diffusion-based adaptive lookahead planner (IRL-DAL) for autonomous vehicles. Training begins with imitation from an expert finite state machine (FSM) controller to provide a stable initialization. Environment terms are combined with an IRL discriminator signal to align with expert goals. Reinforcement learning (RL) is th</description>
</item>

<item>
  <title>Now You Hear Me: Audio Narrative Attacks Against Large Audio-Language Models</title>
  <link>https://arxiv.org/abs/2601.23255v1</link>
  <guid>https://arxiv.org/abs/2601.23255v1</guid>
  <pubDate>Fri, 30 Jan 2026 18:23:02 +0000</pubDate>
  <description>arXiv cs.AI - Large audio-language models increasingly operate on raw speech inputs, enabling more seamless integration across domains such as voice assistants, education, and clinical triage. This transition, however, introduces a distinct class of vulnerabilities that remain largely uncharacterized. We examine the security implications of this modality shift by designing a text-to-audio jailbreak that embeds </description>
</item>

<item>
  <title>ShotFinder: Imagination-Driven Open-Domain Video Shot Retrieval via Web Search</title>
  <link>https://arxiv.org/abs/2601.23232v1</link>
  <guid>https://arxiv.org/abs/2601.23232v1</guid>
  <pubDate>Fri, 30 Jan 2026 18:01:17 +0000</pubDate>
  <description>arXiv cs.AI - In recent years, large language models (LLMs) have made rapid progress in information retrieval, yet existing research has mainly focused on text or static multimodal settings. Open-domain video shot retrieval, which involves richer temporal structure and more complex semantics, still lacks systematic benchmarks and analysis. To fill this gap, we introduce ShotFinder, a benchmark that formalizes e</description>
</item>

<item>
  <title>Scaling Multiagent Systems with Process Rewards</title>
  <link>https://arxiv.org/abs/2601.23228v1</link>
  <guid>https://arxiv.org/abs/2601.23228v1</guid>
  <pubDate>Fri, 30 Jan 2026 17:55:27 +0000</pubDate>
  <description>arXiv cs.AI - While multiagent systems have shown promise for tackling complex tasks via specialization, finetuning multiple agents simultaneously faces two key challenges: (1) credit assignment across agents, and (2) sample efficiency of expensive multiagent rollouts. In this work, we propose finetuning multiagent systems with per-action process rewards from AI feedback (MAPPA) to address both. Through assigni</description>
</item>

<item>
  <title>MonoScale: Scaling Multi-Agent System with Monotonic Improvement</title>
  <link>https://arxiv.org/abs/2601.23219v1</link>
  <guid>https://arxiv.org/abs/2601.23219v1</guid>
  <pubDate>Fri, 30 Jan 2026 17:44:49 +0000</pubDate>
  <description>arXiv cs.AI - In recent years, LLM-based multi-agent systems (MAS) have advanced rapidly, using a router to decompose tasks and delegate subtasks to specialized agents. A natural way to expand capability is to scale up the agent pool by continually integrating new functional agents or tool interfaces, but naive expansion can trigger performance collapse when the router cold-starts on newly added, heterogeneous,</description>
</item>

<item>
  <title>Tackling air quality with SAPIENS</title>
  <link>https://arxiv.org/abs/2601.23215v1</link>
  <guid>https://arxiv.org/abs/2601.23215v1</guid>
  <pubDate>Fri, 30 Jan 2026 17:41:38 +0000</pubDate>
  <description>arXiv cs.LG - Air pollution is a chronic problem in large cities worldwide and awareness is rising as the long-term health implications become clearer. Vehicular traffic has been identified as a major contributor to poor air quality. In a lot of cities the publicly available air quality measurements and forecasts are coarse-grained both in space and time. However, in general, real-time traffic intensity data is</description>
</item>

<item>
  <title>High-quality generation of dynamic game content via small language models: A proof of concept</title>
  <link>https://arxiv.org/abs/2601.23206v1</link>
  <guid>https://arxiv.org/abs/2601.23206v1</guid>
  <pubDate>Fri, 30 Jan 2026 17:30:59 +0000</pubDate>
  <description>arXiv cs.AI - Large language models (LLMs) offer promise for dynamic game content generation, but they face critical barriers, including narrative incoherence and high operational costs. Due to their large size, they are often accessed in the cloud, limiting their application in offline games. Many of these practical issues are solved by pivoting to small language models (SLMs), but existing studies using SLMs </description>
</item>

<item>
  <title>Ensuring Semantics in Weights of Implicit Neural Representations through the Implicit Function Theorem</title>
  <link>https://arxiv.org/abs/2601.23181v1</link>
  <guid>https://arxiv.org/abs/2601.23181v1</guid>
  <pubDate>Fri, 30 Jan 2026 17:05:37 +0000</pubDate>
  <description>arXiv cs.LG - Weight Space Learning (WSL), which frames neural network weights as a data modality, is an emerging field with potential for tasks like meta-learning or transfer learning. Particularly, Implicit Neural Representations (INRs) provide a convenient testbed, where each set of weights determines the corresponding individual data sample as a mapping from coordinates to contextual values. So far, a preci</description>
</item>

<item>
  <title>TriSpec: Ternary Speculative Decoding via Lightweight Proxy Verification</title>
  <link>https://arxiv.org/abs/2601.23180v1</link>
  <guid>https://arxiv.org/abs/2601.23180v1</guid>
  <pubDate>Fri, 30 Jan 2026 17:04:18 +0000</pubDate>
  <description>arXiv cs.LG - Inference efficiency in Large Language Models (LLMs) is fundamentally limited by their serial, autoregressive generation, especially as reasoning becomes a key capability and response sequences grow longer. Speculative decoding (SD) offers a powerful solution, providing significant speed-ups through its lightweight drafting and parallel verification mechanism. While existing work has nearly satura</description>
</item>

<item>
  <title>Beyond Fixed Frames: Dynamic Character-Aligned Speech Tokenization</title>
  <link>https://arxiv.org/abs/2601.23174v1</link>
  <guid>https://arxiv.org/abs/2601.23174v1</guid>
  <pubDate>Fri, 30 Jan 2026 16:58:40 +0000</pubDate>
  <description>arXiv cs.AI - Neural audio codecs are at the core of modern conversational speech technologies, converting continuous speech into sequences of discrete tokens that can be processed by LLMs. However, existing codecs typically operate at fixed frame rates, allocating tokens uniformly in time and producing unnecessarily long sequences. In this work, we introduce DyCAST, a Dynamic Character-Aligned Speech Tokenizer</description>
</item>

<item>
  <title>Beyond Fixed Frames: Dynamic Character-Aligned Speech Tokenization</title>
  <link>https://arxiv.org/abs/2601.23174v1</link>
  <guid>https://arxiv.org/abs/2601.23174v1</guid>
  <pubDate>Fri, 30 Jan 2026 16:58:40 +0000</pubDate>
  <description>arXiv cs.LG - Neural audio codecs are at the core of modern conversational speech technologies, converting continuous speech into sequences of discrete tokens that can be processed by LLMs. However, existing codecs typically operate at fixed frame rates, allocating tokens uniformly in time and producing unnecessarily long sequences. In this work, we introduce DyCAST, a Dynamic Character-Aligned Speech Tokenizer</description>
</item>

<item>
  <title>RedSage: A Cybersecurity Generalist LLM</title>
  <link>https://arxiv.org/abs/2601.22159v1</link>
  <guid>https://arxiv.org/abs/2601.22159v1</guid>
  <pubDate>Thu, 29 Jan 2026 18:59:57 +0000</pubDate>
  <description>arXiv cs.AI - Cybersecurity operations demand assistant LLMs that support diverse workflows without exposing sensitive data. Existing solutions either rely on proprietary APIs with privacy risks or on open models lacking domain adaptation. To bridge this gap, we curate 11.8B tokens of cybersecurity-focused continual pretraining data via large-scale web filtering and manual collection of high-quality resources, </description>
</item>

<item>
  <title>Hybrid Linear Attention Done Right: Efficient Distillation and Effective Architectures for Extremely Long Contexts</title>
  <link>https://arxiv.org/abs/2601.22156v1</link>
  <guid>https://arxiv.org/abs/2601.22156v1</guid>
  <pubDate>Thu, 29 Jan 2026 18:59:53 +0000</pubDate>
  <description>arXiv cs.AI - Hybrid Transformer architectures, which combine softmax attention blocks and recurrent neural networks (RNNs), have shown a desirable performance-throughput tradeoff for long-context modeling, but their adoption and studies are hindered by the prohibitive cost of large-scale pre-training from scratch. Some recent studies have shown that pre-trained softmax attention blocks can be converted into RN</description>
</item>

<item>
  <title>Hybrid Linear Attention Done Right: Efficient Distillation and Effective Architectures for Extremely Long Contexts</title>
  <link>https://arxiv.org/abs/2601.22156v1</link>
  <guid>https://arxiv.org/abs/2601.22156v1</guid>
  <pubDate>Thu, 29 Jan 2026 18:59:53 +0000</pubDate>
  <description>arXiv cs.LG - Hybrid Transformer architectures, which combine softmax attention blocks and recurrent neural networks (RNNs), have shown a desirable performance-throughput tradeoff for long-context modeling, but their adoption and studies are hindered by the prohibitive cost of large-scale pre-training from scratch. Some recent studies have shown that pre-trained softmax attention blocks can be converted into RN</description>
</item>

<item>
  <title>Exploring Reasoning Reward Model for Agents</title>
  <link>https://arxiv.org/abs/2601.22154v1</link>
  <guid>https://arxiv.org/abs/2601.22154v1</guid>
  <pubDate>Thu, 29 Jan 2026 18:59:52 +0000</pubDate>
  <description>arXiv cs.AI - Agentic Reinforcement Learning (Agentic RL) has achieved notable success in enabling agents to perform complex reasoning and tool use. However, most methods still relies on sparse outcome-based reward for training. Such feedback fails to differentiate intermediate reasoning quality, leading to suboptimal training results. In this paper, we introduce Agent Reasoning Reward Model (Agent-RRM), a mult</description>
</item>

<item>
  <title>DynaWeb: Model-Based Reinforcement Learning of Web Agents</title>
  <link>https://arxiv.org/abs/2601.22149v1</link>
  <guid>https://arxiv.org/abs/2601.22149v1</guid>
  <pubDate>Thu, 29 Jan 2026 18:59:07 +0000</pubDate>
  <description>arXiv cs.AI - The development of autonomous web agents, powered by Large Language Models (LLMs) and reinforcement learning (RL), represents a significant step towards general-purpose AI assistants. However, training these agents is severely hampered by the challenges of interacting with the live internet, which is inefficient, costly, and fraught with risks. Model-based reinforcement learning (MBRL) offers a pr</description>
</item>

<item>
  <title>StepShield: When, Not Whether to Intervene on Rogue Agents</title>
  <link>https://arxiv.org/abs/2601.22136v1</link>
  <guid>https://arxiv.org/abs/2601.22136v1</guid>
  <pubDate>Thu, 29 Jan 2026 18:55:46 +0000</pubDate>
  <description>arXiv cs.AI - Existing agent safety benchmarks report binary accuracy, conflating early intervention with post-mortem analysis. A detector that flags a violation at step 8 enables intervention; one that reports it at step 48 provides only forensic value. This distinction is critical, yet current benchmarks cannot measure it. We introduce StepShield, the first benchmark to evaluate when violations are detected, </description>
</item>

<item>
  <title>StepShield: When, Not Whether to Intervene on Rogue Agents</title>
  <link>https://arxiv.org/abs/2601.22136v1</link>
  <guid>https://arxiv.org/abs/2601.22136v1</guid>
  <pubDate>Thu, 29 Jan 2026 18:55:46 +0000</pubDate>
  <description>arXiv cs.LG - Existing agent safety benchmarks report binary accuracy, conflating early intervention with post-mortem analysis. A detector that flags a violation at step 8 enables intervention; one that reports it at step 48 provides only forensic value. This distinction is critical, yet current benchmarks cannot measure it. We introduce StepShield, the first benchmark to evaluate when violations are detected, </description>
</item>

<item>
  <title>Pay for Hints, Not Answers: LLM Shepherding for Cost-Efficient Inference</title>
  <link>https://arxiv.org/abs/2601.22132v1</link>
  <guid>https://arxiv.org/abs/2601.22132v1</guid>
  <pubDate>Thu, 29 Jan 2026 18:52:54 +0000</pubDate>
  <description>arXiv cs.LG - Large Language Models (LLMs) deliver state-of-the-art performance on complex reasoning tasks, but their inference costs limit deployment at scale. Small Language Models (SLMs) offer dramatic cost savings yet lag substantially in accuracy. Existing approaches - routing and cascading - treat the LLM as an all-or-nothing resource: either the query bypasses the LLM entirely, or the LLM generates a com</description>
</item>

<item>
  <title>World of Workflows: a Benchmark for Bringing World Models to Enterprise Systems</title>
  <link>https://arxiv.org/abs/2601.22130v1</link>
  <guid>https://arxiv.org/abs/2601.22130v1</guid>
  <pubDate>Thu, 29 Jan 2026 18:51:54 +0000</pubDate>
  <description>arXiv cs.AI - Frontier large language models (LLMs) excel as autonomous agents in many domains, yet they remain untested in complex enterprise systems where hidden workflows create cascading effects across interconnected databases. Existing enterprise benchmarks evaluate surface-level agentic task completion similar to general consumer benchmarks, ignoring true challenges in enterprises, such as limited observa</description>
</item>

<item>
  <title>SWE-Replay: Efficient Test-Time Scaling for Software Engineering Agents</title>
  <link>https://arxiv.org/abs/2601.22129v1</link>
  <guid>https://arxiv.org/abs/2601.22129v1</guid>
  <pubDate>Thu, 29 Jan 2026 18:50:29 +0000</pubDate>
  <description>arXiv cs.AI - Test-time scaling has been widely adopted to enhance the capabilities of Large Language Model (LLM) agents in software engineering (SWE) tasks. However, the standard approach of repeatedly sampling trajectories from scratch is computationally expensive. While recent methods have attempted to mitigate costs using specialized value agents, they can suffer from model miscalibration and fail to genera</description>
</item>

<item>
  <title>SWE-Replay: Efficient Test-Time Scaling for Software Engineering Agents</title>
  <link>https://arxiv.org/abs/2601.22129v1</link>
  <guid>https://arxiv.org/abs/2601.22129v1</guid>
  <pubDate>Thu, 29 Jan 2026 18:50:29 +0000</pubDate>
  <description>arXiv cs.LG - Test-time scaling has been widely adopted to enhance the capabilities of Large Language Model (LLM) agents in software engineering (SWE) tasks. However, the standard approach of repeatedly sampling trajectories from scratch is computationally expensive. While recent methods have attempted to mitigate costs using specialized value agents, they can suffer from model miscalibration and fail to genera</description>
</item>

<item>
  <title>Vision-DeepResearch: Incentivizing DeepResearch Capability in Multimodal Large Language Models</title>
  <link>https://arxiv.org/abs/2601.22060v1</link>
  <guid>https://arxiv.org/abs/2601.22060v1</guid>
  <pubDate>Thu, 29 Jan 2026 17:58:40 +0000</pubDate>
  <description>arXiv cs.AI - Multimodal large language models (MLLMs) have achieved remarkable success across a broad range of vision tasks. However, constrained by the capacity of their internal world knowledge, prior work has proposed augmenting MLLMs by ``reasoning-then-tool-call&apos;&apos; for visual and textual search engines to obtain substantial gains on tasks requiring extensive factual information. However, these approaches t</description>
</item>

<item>
  <title>SIA: Symbolic Interpretability for Anticipatory Deep Reinforcement Learning in Network Control</title>
  <link>https://arxiv.org/abs/2601.22044v1</link>
  <guid>https://arxiv.org/abs/2601.22044v1</guid>
  <pubDate>Thu, 29 Jan 2026 17:46:46 +0000</pubDate>
  <description>arXiv cs.AI - Deep reinforcement learning (DRL) promises adaptive control for future mobile networks but conventional agents remain reactive: they act on past and current measurements and cannot leverage short-term forecasts of exogenous KPIs such as bandwidth. Augmenting agents with predictions can overcome this temporal myopia, yet uptake in networking is scarce because forecast-aware agents act as closed-box</description>
</item>

<item>
  <title>Learning to Communicate Across Modalities: Perceptual Heterogeneity in Multi-Agent Systems</title>
  <link>https://arxiv.org/abs/2601.22041v1</link>
  <guid>https://arxiv.org/abs/2601.22041v1</guid>
  <pubDate>Thu, 29 Jan 2026 17:45:41 +0000</pubDate>
  <description>arXiv cs.AI - Emergent communication offers insight into how agents develop shared structured representations, yet most research assumes homogeneous modalities or aligned representational spaces, overlooking the perceptual heterogeneity of real-world settings. We study a heterogeneous multi-step binary communication game where agents differ in modality and lack perceptual grounding. Despite perceptual misalignm</description>
</item>

<item>
  <title>Learning to Communicate Across Modalities: Perceptual Heterogeneity in Multi-Agent Systems</title>
  <link>https://arxiv.org/abs/2601.22041v1</link>
  <guid>https://arxiv.org/abs/2601.22041v1</guid>
  <pubDate>Thu, 29 Jan 2026 17:45:41 +0000</pubDate>
  <description>arXiv cs.LG - Emergent communication offers insight into how agents develop shared structured representations, yet most research assumes homogeneous modalities or aligned representational spaces, overlooking the perceptual heterogeneity of real-world settings. We study a heterogeneous multi-step binary communication game where agents differ in modality and lack perceptual grounding. Despite perceptual misalignm</description>
</item>

<item>
  <title>Optimizing Agentic Workflows using Meta-tools</title>
  <link>https://arxiv.org/abs/2601.22037v1</link>
  <guid>https://arxiv.org/abs/2601.22037v1</guid>
  <pubDate>Thu, 29 Jan 2026 17:43:08 +0000</pubDate>
  <description>arXiv cs.AI - Agentic AI enables LLM to dynamically reason, plan, and interact with tools to solve complex tasks. However, agentic workflows often require many iterative reasoning steps and tool invocations, leading to significant operational expense, end-to-end latency and failures due to hallucinations. This work introduces Agent Workflow Optimization (AWO), a framework that identifies and optimizes redundant</description>
</item>

<item>
  <title>Deep Researcher with Sequential Plan Reflection and Candidates Crossover (Deep Researcher Reflect Evolve)</title>
  <link>https://arxiv.org/abs/2601.20843v1</link>
  <guid>https://arxiv.org/abs/2601.20843v1</guid>
  <pubDate>Wed, 28 Jan 2026 18:45:39 +0000</pubDate>
  <description>arXiv cs.AI - This paper introduces a novel Deep Researcher architecture designed to generate detailed research reports on complex PhD level topics by addressing the inherent limitations of the Parallel Scaling paradigm. Our system utilizes two key innovations: Sequential Research Plan Refinement via Reflection and a Candidates Crossover algorithm. The sequential refinement process is demonstrated as an efficie</description>
</item>

<item>
  <title>MemCtrl: Using MLLMs as Active Memory Controllers on Embodied Agents</title>
  <link>https://arxiv.org/abs/2601.20831v1</link>
  <guid>https://arxiv.org/abs/2601.20831v1</guid>
  <pubDate>Wed, 28 Jan 2026 18:31:17 +0000</pubDate>
  <description>arXiv cs.AI - Foundation models rely on in-context learning for personalized decision making. The limited size of this context window necessitates memory compression and retrieval systems like RAG. These systems however often treat memory as large offline storage spaces, which is unfavorable for embodied agents that are expected to operate under strict memory and compute constraints, online. In this work, we pr</description>
</item>

<item>
  <title>Demystifying Prediction Powered Inference</title>
  <link>https://arxiv.org/abs/2601.20819v1</link>
  <guid>https://arxiv.org/abs/2601.20819v1</guid>
  <pubDate>Wed, 28 Jan 2026 18:16:02 +0000</pubDate>
  <description>arXiv cs.LG - Machine learning predictions are increasingly used to supplement incomplete or costly-to-measure outcomes in fields such as biomedical research, environmental science, and social science. However, treating predictions as ground truth introduces bias while ignoring them wastes valuable information. Prediction-Powered Inference (PPI) offers a principled framework that leverages predictions from larg</description>
</item>

<item>
  <title>SERA: Soft-Verified Efficient Repository Agents</title>
  <link>https://arxiv.org/abs/2601.20789v1</link>
  <guid>https://arxiv.org/abs/2601.20789v1</guid>
  <pubDate>Wed, 28 Jan 2026 17:27:08 +0000</pubDate>
  <description>arXiv cs.LG - Open-weight coding agents should hold a fundamental advantage over closed-source systems: they can be specialized to private codebases, encoding repository-specific information directly in their weights. Yet the cost and complexity of training has kept this advantage theoretical. We show it is now practical. We present Soft-Verified Efficient Repository Agents (SERA), an efficient method for train</description>
</item>

<item>
  <title>COMET-SG1: Lightweight Autoregressive Regressor for Edge and Embedded AI</title>
  <link>https://arxiv.org/abs/2601.20772v1</link>
  <guid>https://arxiv.org/abs/2601.20772v1</guid>
  <pubDate>Wed, 28 Jan 2026 16:59:56 +0000</pubDate>
  <description>arXiv cs.LG - COMET-SG1 is a lightweight, stability-oriented autoregressive regression model designed for time-series prediction on edge and embedded AI systems. Unlike recurrent neural networks or transformer-based sequence models, COMET-SG1 operates through linear behavior-space encoding, memory-anchored transition estimation, and deterministic state updates. This structure prioritizes bounded long-horizon be</description>
</item>

<item>
  <title>Li-ViP3D++: Query-Gated Deformable Camera-LiDAR Fusion for End-to-End Perception and Trajectory Prediction</title>
  <link>https://arxiv.org/abs/2601.20720v1</link>
  <guid>https://arxiv.org/abs/2601.20720v1</guid>
  <pubDate>Wed, 28 Jan 2026 15:53:32 +0000</pubDate>
  <description>arXiv cs.AI - End-to-end perception and trajectory prediction from raw sensor data is one of the key capabilities for autonomous driving. Modular pipelines restrict information flow and can amplify upstream errors. Recent query-based, fully differentiable perception-and-prediction (PnP) models mitigate these issues, yet the complementarity of cameras and LiDAR in the query-space has not been sufficiently explor</description>
</item>

<item>
  <title>Adapting the Behavior of Reinforcement Learning Agents to Changing Action Spaces and Reward Functions</title>
  <link>https://arxiv.org/abs/2601.20714v1</link>
  <guid>https://arxiv.org/abs/2601.20714v1</guid>
  <pubDate>Wed, 28 Jan 2026 15:46:51 +0000</pubDate>
  <description>arXiv cs.AI - Reinforcement Learning (RL) agents often struggle in real-world applications where environmental conditions are non-stationary, particularly when reward functions shift or the available action space expands. This paper introduces MORPHIN, a self-adaptive Q-learning framework that enables on-the-fly adaptation without full retraining. By integrating concept drift detection with dynamic adjustments </description>
</item>

<item>
  <title>SONIC: Spectral Oriented Neural Invariant Convolutions</title>
  <link>https://arxiv.org/abs/2601.19884v1</link>
  <guid>https://arxiv.org/abs/2601.19884v1</guid>
  <pubDate>Tue, 27 Jan 2026 18:51:11 +0000</pubDate>
  <description>arXiv cs.LG - Convolutional Neural Networks (CNNs) rely on fixed-size kernels scanning local patches, which limits their ability to capture global context or long-range dependencies without very deep architectures. Vision Transformers (ViTs), in turn, provide global connectivity but lack spatial inductive bias, depend on explicit positional encodings, and remain tied to the initial patch size. Bridging these li</description>
</item>

<item>
  <title>Unsupervised Learning of Efficient Exploration: Pre-training Adaptive Policies via Self-Imposed Goals</title>
  <link>https://arxiv.org/abs/2601.19810v1</link>
  <guid>https://arxiv.org/abs/2601.19810v1</guid>
  <pubDate>Tue, 27 Jan 2026 17:10:29 +0000</pubDate>
  <description>arXiv cs.AI - Unsupervised pre-training can equip reinforcement learning agents with prior knowledge and accelerate learning in downstream tasks. A promising direction, grounded in human development, investigates agents that learn by setting and pursuing their own goals. The core challenge lies in how to effectively generate, select, and learn from such goals. Our focus is on broad distributions of downstream t</description>
</item>

<item>
  <title>Unsupervised Learning of Efficient Exploration: Pre-training Adaptive Policies via Self-Imposed Goals</title>
  <link>https://arxiv.org/abs/2601.19810v1</link>
  <guid>https://arxiv.org/abs/2601.19810v1</guid>
  <pubDate>Tue, 27 Jan 2026 17:10:29 +0000</pubDate>
  <description>arXiv cs.LG - Unsupervised pre-training can equip reinforcement learning agents with prior knowledge and accelerate learning in downstream tasks. A promising direction, grounded in human development, investigates agents that learn by setting and pursuing their own goals. The core challenge lies in how to effectively generate, select, and learn from such goals. Our focus is on broad distributions of downstream t</description>
</item>

<item>
  <title>Component-Aware Pruning Framework for Neural Network Controllers via Gradient-Based Importance Estimation</title>
  <link>https://arxiv.org/abs/2601.19794v1</link>
  <guid>https://arxiv.org/abs/2601.19794v1</guid>
  <pubDate>Tue, 27 Jan 2026 16:53:19 +0000</pubDate>
  <description>arXiv cs.LG - The transition from monolithic to multi-component neural architectures in advanced neural network controllers poses substantial challenges due to the high computational complexity of the latter. Conventional model compression techniques for complexity reduction, such as structured pruning based on norm-based metrics to estimate the relative importance of distinct parameter groups, often fail to ca</description>
</item>

<item>
  <title>CASTER: Breaking the Cost-Performance Barrier in Multi-Agent Orchestration via Context-Aware Strategy for Task Efficient Routing</title>
  <link>https://arxiv.org/abs/2601.19793v1</link>
  <guid>https://arxiv.org/abs/2601.19793v1</guid>
  <pubDate>Tue, 27 Jan 2026 16:52:47 +0000</pubDate>
  <description>arXiv cs.AI - Graph-based Multi-Agent Systems (MAS) enable complex cyclic workflows but suffer from inefficient static model allocation, where deploying strong models uniformly wastes computation on trivial sub-tasks. We propose CASTER (Context-Aware Strategy for Task Efficient Routing), a lightweight router for dynamic model selection in graph-based MAS. CASTER employs a Dual-Signal Router that combines semant</description>
</item>

<item>
  <title>LVLMs and Humans Ground Differently in Referential Communication</title>
  <link>https://arxiv.org/abs/2601.19792v1</link>
  <guid>https://arxiv.org/abs/2601.19792v1</guid>
  <pubDate>Tue, 27 Jan 2026 16:52:20 +0000</pubDate>
  <description>arXiv cs.AI - For generative AI agents to partner effectively with human users, the ability to accurately predict human intent is critical. But this ability to collaborate remains limited by a critical deficit: an inability to model common ground. Here, we present a referential communication experiment with a factorial design involving director-matcher pairs (human-human, human-AI, AI-human, and AI-AI) that int</description>
</item>

<item>
  <title>Reimagining Peer Review Process Through Multi-Agent Mechanism Design</title>
  <link>https://arxiv.org/abs/2601.19778v1</link>
  <guid>https://arxiv.org/abs/2601.19778v1</guid>
  <pubDate>Tue, 27 Jan 2026 16:43:11 +0000</pubDate>
  <description>arXiv cs.AI - The software engineering research community faces a systemic crisis: peer review is failing under growing submissions, misaligned incentives, and reviewer fatigue. Community surveys reveal that researchers perceive the process as &quot;broken.&quot; This position paper argues that these dysfunctions are mechanism design failures amenable to computational solutions. We propose modeling the research community</description>
</item>

<item>
  <title>Agentic Design Patterns: A System-Theoretic Framework</title>
  <link>https://arxiv.org/abs/2601.19752v1</link>
  <guid>https://arxiv.org/abs/2601.19752v1</guid>
  <pubDate>Tue, 27 Jan 2026 16:14:08 +0000</pubDate>
  <description>arXiv cs.AI - With the development of foundation model (FM), agentic AI systems are getting more attention, yet their inherent issues like hallucination and poor reasoning, coupled with the frequent ad-hoc nature of system design, lead to unreliable and brittle applications. Existing efforts to characterise agentic design patterns often lack a rigorous systems-theoretic foundation, resulting in high-level or co</description>
</item>

<item>
  <title>Veri-Sure: A Contract-Aware Multi-Agent Framework with Temporal Tracing and Formal Verification for Correct RTL Code Generation</title>
  <link>https://arxiv.org/abs/2601.19747v1</link>
  <guid>https://arxiv.org/abs/2601.19747v1</guid>
  <pubDate>Tue, 27 Jan 2026 16:10:23 +0000</pubDate>
  <description>arXiv cs.AI - In the rapidly evolving field of Electronic Design Automation (EDA), the deployment of Large Language Models (LLMs) for Register-Transfer Level (RTL) design has emerged as a promising direction. However, silicon-grade correctness remains bottlenecked by: (i) limited test coverage and reliability of simulation-centric evaluation, (ii) regressions and repair hallucinations introduced by iterative de</description>
</item>

<item>
  <title>Quantum Circuit Pre-Synthesis: Learning Local Edits to Reduce $T$-count</title>
  <link>https://arxiv.org/abs/2601.19738v1</link>
  <guid>https://arxiv.org/abs/2601.19738v1</guid>
  <pubDate>Tue, 27 Jan 2026 15:58:05 +0000</pubDate>
  <description>arXiv cs.AI - Compiling quantum circuits into Clifford+$T$ gates is a central task for fault-tolerant quantum computing using stabilizer codes. In the near term, $T$ gates will dominate the cost of fault tolerant implementations, and any reduction in the number of such expensive gates could mean the difference between being able to run a circuit or not. While exact synthesis is exponentially hard in the number </description>
</item>

<item>
  <title>Quantum Circuit Pre-Synthesis: Learning Local Edits to Reduce $T$-count</title>
  <link>https://arxiv.org/abs/2601.19738v1</link>
  <guid>https://arxiv.org/abs/2601.19738v1</guid>
  <pubDate>Tue, 27 Jan 2026 15:58:05 +0000</pubDate>
  <description>arXiv cs.LG - Compiling quantum circuits into Clifford+$T$ gates is a central task for fault-tolerant quantum computing using stabilizer codes. In the near term, $T$ gates will dominate the cost of fault tolerant implementations, and any reduction in the number of such expensive gates could mean the difference between being able to run a circuit or not. While exact synthesis is exponentially hard in the number </description>
</item>

<item>
  <title>ctELM: Decoding and Manipulating Embeddings of Clinical Trials with Embedding Language Models</title>
  <link>https://arxiv.org/abs/2601.18796v1</link>
  <guid>https://arxiv.org/abs/2601.18796v1</guid>
  <pubDate>Mon, 26 Jan 2026 18:58:46 +0000</pubDate>
  <description>arXiv cs.AI - Text embeddings have become an essential part of a variety of language applications. However, methods for interpreting, exploring and reversing embedding spaces are limited, reducing transparency and precluding potentially valuable generative use cases. In this work, we align Large Language Models to embeddings of clinical trials using the recently reported Embedding Language Model (ELM) method. W</description>
</item>

</channel>
</rss>
