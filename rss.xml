<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0">
<channel>
  <title>AI Research Digest</title>
  <link>https://xiaolin-econ.github.io/ai-digest/</link>
  <description>Curated AI research + releases</description>
  <lastBuildDate>Tue, 10 Feb 2026 18:54:13 +0000</lastBuildDate>
  <atom:link href="https://xiaolin-econ.github.io/ai-digest/rss.xml" rel="self" type="application/rss+xml" xmlns:atom="http://www.w3.org/2005/Atom"/>
  
<item>
  <title>AI Digest — Daily Summary</title>
  <link>https://xiaolin-econ.github.io/ai-digest/rss.xml</link>
  <guid>https://xiaolin-econ.github.io/ai-digest/rss.xml#summary</guid>
  <pubDate>Tue, 10 Feb 2026 18:54:13 +0000</pubDate>
  <description>Out of distribution (OOD) robustness in autonomous driving is often reduced to a single number, hiding what breaks a policy. We decompose environments along five axes: scene (rural/urban), season, weather, time (day/night), and agent mix; and measure performance under controlled $k$-factor perturbations ($k \in \{0,1,2,3\}$). Using closed loop control in VISTA, we benchmark FC, CNN, and ViT policies, train compact ViT heads on frozen foundation-model (FM) features, and vary ID support in scale, diversity, and temporal context. (1) ViT policies are markedly more OOD-robust than comparably sized CNN/FC, and FM features yield state-of-the-art success at a latency cost. (2) Naive temporal inputs (multi-frame) do not beat the best single-frame baseline. (3) The largest single factor drops are…</description>
</item>

<item>
  <title>Robustness Is a Function, Not a Number: A Factorized Comprehensive Study of OOD Robustness in Vision-Based Driving</title>
  <link>https://arxiv.org/abs/2602.09018v1</link>
  <guid>https://arxiv.org/abs/2602.09018v1</guid>
  <pubDate>Mon, 09 Feb 2026 18:59:03 +0000</pubDate>
  <description>arXiv cs.AI - Out of distribution (OOD) robustness in autonomous driving is often reduced to a single number, hiding what breaks a policy. We decompose environments along five axes: scene (rural/urban), season, weather, time (day/night), and agent mix; and measure performance under controlled $k$-factor perturbations ($k \in \{0,1,2,3\}$). Using closed loop control in VISTA, we benchmark FC, CNN, and ViT polici</description>
</item>

<item>
  <title>Robustness Is a Function, Not a Number: A Factorized Comprehensive Study of OOD Robustness in Vision-Based Driving</title>
  <link>https://arxiv.org/abs/2602.09018v1</link>
  <guid>https://arxiv.org/abs/2602.09018v1</guid>
  <pubDate>Mon, 09 Feb 2026 18:59:03 +0000</pubDate>
  <description>arXiv cs.LG - Out of distribution (OOD) robustness in autonomous driving is often reduced to a single number, hiding what breaks a policy. We decompose environments along five axes: scene (rural/urban), season, weather, time (day/night), and agent mix; and measure performance under controlled $k$-factor perturbations ($k \in \{0,1,2,3\}$). Using closed loop control in VISTA, we benchmark FC, CNN, and ViT polici</description>
</item>

<item>
  <title>Next-Gen CAPTCHAs: Leveraging the Cognitive Gap for Scalable and Diverse GUI-Agent Defense</title>
  <link>https://arxiv.org/abs/2602.09012v1</link>
  <guid>https://arxiv.org/abs/2602.09012v1</guid>
  <pubDate>Mon, 09 Feb 2026 18:55:33 +0000</pubDate>
  <description>arXiv cs.AI - The rapid evolution of GUI-enabled agents has rendered traditional CAPTCHAs obsolete. While previous benchmarks like OpenCaptchaWorld established a baseline for evaluating multimodal agents, recent advancements in reasoning-heavy models, such as Gemini3-Pro-High and GPT-5.2-Xhigh have effectively collapsed this security barrier, achieving pass rates as high as 90% on complex logic puzzles like &quot;Bi</description>
</item>

<item>
  <title>Next-Gen CAPTCHAs: Leveraging the Cognitive Gap for Scalable and Diverse GUI-Agent Defense</title>
  <link>https://arxiv.org/abs/2602.09012v1</link>
  <guid>https://arxiv.org/abs/2602.09012v1</guid>
  <pubDate>Mon, 09 Feb 2026 18:55:33 +0000</pubDate>
  <description>arXiv cs.LG - The rapid evolution of GUI-enabled agents has rendered traditional CAPTCHAs obsolete. While previous benchmarks like OpenCaptchaWorld established a baseline for evaluating multimodal agents, recent advancements in reasoning-heavy models, such as Gemini3-Pro-High and GPT-5.2-Xhigh have effectively collapsed this security barrier, achieving pass rates as high as 90% on complex logic puzzles like &quot;Bi</description>
</item>

<item>
  <title>From Obstacles to Etiquette: Robot Social Navigation with VLM-Informed Path Selection</title>
  <link>https://arxiv.org/abs/2602.09002v1</link>
  <guid>https://arxiv.org/abs/2602.09002v1</guid>
  <pubDate>Mon, 09 Feb 2026 18:46:12 +0000</pubDate>
  <description>arXiv cs.AI - Navigating socially in human environments requires more than satisfying geometric constraints, as collision-free paths may still interfere with ongoing activities or conflict with social norms. Addressing this challenge calls for analyzing interactions between agents and incorporating common-sense reasoning into planning. This paper presents a social robot navigation framework that integrates geom</description>
</item>

<item>
  <title>InternAgent-1.5: A Unified Agentic Framework for Long-Horizon Autonomous Scientific Discovery</title>
  <link>https://arxiv.org/abs/2602.08990v1</link>
  <guid>https://arxiv.org/abs/2602.08990v1</guid>
  <pubDate>Mon, 09 Feb 2026 18:36:06 +0000</pubDate>
  <description>arXiv cs.AI - We introduce InternAgent-1.5, a unified system designed for end-to-end scientific discovery across computational and empirical domains. The system is built on a structured architecture composed of three coordinated subsystems for generation, verification, and evolution. These subsystems are supported by foundational capabilities for deep research, solution optimization, and long horizon memory. Th</description>
</item>

<item>
  <title>StretchTime: Adaptive Time Series Forecasting via Symplectic Attention</title>
  <link>https://arxiv.org/abs/2602.08983v1</link>
  <guid>https://arxiv.org/abs/2602.08983v1</guid>
  <pubDate>Mon, 09 Feb 2026 18:29:25 +0000</pubDate>
  <description>arXiv cs.AI - Transformer architectures have established strong baselines in time series forecasting, yet they typically rely on positional encodings that assume uniform, index-based temporal progression. However, real-world systems, from shifting financial cycles to elastic biological rhythms, frequently exhibit &quot;time-warped&quot; dynamics where the effective flow of time decouples from the sampling index. In this </description>
</item>

<item>
  <title>StretchTime: Adaptive Time Series Forecasting via Symplectic Attention</title>
  <link>https://arxiv.org/abs/2602.08983v1</link>
  <guid>https://arxiv.org/abs/2602.08983v1</guid>
  <pubDate>Mon, 09 Feb 2026 18:29:25 +0000</pubDate>
  <description>arXiv cs.LG - Transformer architectures have established strong baselines in time series forecasting, yet they typically rely on positional encodings that assume uniform, index-based temporal progression. However, real-world systems, from shifting financial cycles to elastic biological rhythms, frequently exhibit &quot;time-warped&quot; dynamics where the effective flow of time decouples from the sampling index. In this </description>
</item>

<item>
  <title>stable-worldmodel-v1: Reproducible World Modeling Research and Evaluation</title>
  <link>https://arxiv.org/abs/2602.08968v1</link>
  <guid>https://arxiv.org/abs/2602.08968v1</guid>
  <pubDate>Mon, 09 Feb 2026 18:04:22 +0000</pubDate>
  <description>arXiv cs.AI - World Models have emerged as a powerful paradigm for learning compact, predictive representations of environment dynamics, enabling agents to reason, plan, and generalize beyond direct experience. Despite recent interest in World Models, most available implementations remain publication-specific, severely limiting their reusability, increasing the risk of bugs, and reducing evaluation standardizat</description>
</item>

<item>
  <title>Learning to Coordinate via Quantum Entanglement in Multi-Agent Reinforcement Learning</title>
  <link>https://arxiv.org/abs/2602.08965v1</link>
  <guid>https://arxiv.org/abs/2602.08965v1</guid>
  <pubDate>Mon, 09 Feb 2026 18:01:40 +0000</pubDate>
  <description>arXiv cs.LG - The inability to communicate poses a major challenge to coordination in multi-agent reinforcement learning (MARL). Prior work has explored correlating local policies via shared randomness, sometimes in the form of a correlation device, as a mechanism to assist in decentralized decision-making. In contrast, this work introduces the first framework for training MARL agents to exploit shared quantum </description>
</item>

<item>
  <title>A Behavioural and Representational Evaluation of Goal-Directedness in Language Model Agents</title>
  <link>https://arxiv.org/abs/2602.08964v1</link>
  <guid>https://arxiv.org/abs/2602.08964v1</guid>
  <pubDate>Mon, 09 Feb 2026 18:00:28 +0000</pubDate>
  <description>arXiv cs.AI - Understanding an agent&apos;s goals helps explain and predict its behaviour, yet there is no established methodology for reliably attributing goals to agentic systems. We propose a framework for evaluating goal-directedness that integrates behavioural evaluation with interpretability-based analyses of models&apos; internal representations. As a case study, we examine an LLM agent navigating a 2D grid world </description>
</item>

<item>
  <title>A Behavioural and Representational Evaluation of Goal-Directedness in Language Model Agents</title>
  <link>https://arxiv.org/abs/2602.08964v1</link>
  <guid>https://arxiv.org/abs/2602.08964v1</guid>
  <pubDate>Mon, 09 Feb 2026 18:00:28 +0000</pubDate>
  <description>arXiv cs.LG - Understanding an agent&apos;s goals helps explain and predict its behaviour, yet there is no established methodology for reliably attributing goals to agentic systems. We propose a framework for evaluating goal-directedness that integrates behavioural evaluation with interpretability-based analyses of models&apos; internal representations. As a case study, we examine an LLM agent navigating a 2D grid world </description>
</item>

<item>
  <title>Digital Twin and Agentic AI for Wild Fire Disaster Management: Intelligent Virtual Situation Room</title>
  <link>https://arxiv.org/abs/2602.08949v1</link>
  <guid>https://arxiv.org/abs/2602.08949v1</guid>
  <pubDate>Mon, 09 Feb 2026 17:44:52 +0000</pubDate>
  <description>arXiv cs.AI - According to the United Nations, wildfire frequency and intensity are projected to increase by approximately 14% by 2030 and 30% by 2050 due to global warming, posing critical threats to life, infrastructure, and ecosystems. Conventional disaster management frameworks rely on static simulations and passive data acquisition, hindering their ability to adapt to arbitrarily evolving wildfire episodes</description>
</item>

<item>
  <title>CoRefine: Confidence-Guided Self-Refinement for Adaptive Test-Time Compute</title>
  <link>https://arxiv.org/abs/2602.08948v1</link>
  <guid>https://arxiv.org/abs/2602.08948v1</guid>
  <pubDate>Mon, 09 Feb 2026 17:44:41 +0000</pubDate>
  <description>arXiv cs.AI - Large Language Models (LLMs) often rely on test-time scaling via parallel decoding (for example, 512 samples) to boost reasoning accuracy, but this incurs substantial compute. We introduce CoRefine, a confidence-guided self-refinement method that achieves competitive accuracy using a fraction of the tokens via a lightweight 211k-parameter Conv1D controller atop a frozen LLM. The controller consume</description>
</item>

<item>
  <title>pixelLOG: Logging of Online Gameplay for Cognitive Research</title>
  <link>https://arxiv.org/abs/2602.08941v1</link>
  <guid>https://arxiv.org/abs/2602.08941v1</guid>
  <pubDate>Mon, 09 Feb 2026 17:38:55 +0000</pubDate>
  <description>arXiv cs.AI - Traditional cognitive assessments often rely on isolated, output-focused measurements that may fail to capture the complexity of human cognition in naturalistic settings. We present pixelLOG, a high-performance data collection framework for Spigot-based Minecraft servers designed specifically for process-based cognitive research. Unlike existing frameworks tailored only for artificial intelligence</description>
</item>

<item>
  <title>AMS-HD: Hyperdimensional Computing for Real-Time and Energy-Efficient Acute Mountain Sickness Detection</title>
  <link>https://arxiv.org/abs/2602.08916v1</link>
  <guid>https://arxiv.org/abs/2602.08916v1</guid>
  <pubDate>Mon, 09 Feb 2026 17:16:13 +0000</pubDate>
  <description>arXiv cs.LG - Altitude sickness is a potentially life-threatening condition that impacts many individuals traveling to elevated altitudes. Timely detection is critical as symptoms can escalate rapidly. Early recognition enables simple interventions such as descent, oxygen, or medication, and prompt treatment can save lives by significantly lowering the risk of severe complications. Although conventional machine</description>
</item>

<item>
  <title>Gesturing Toward Abstraction: Multimodal Convention Formation in Collaborative Physical Tasks</title>
  <link>https://arxiv.org/abs/2602.08914v1</link>
  <guid>https://arxiv.org/abs/2602.08914v1</guid>
  <pubDate>Mon, 09 Feb 2026 17:13:34 +0000</pubDate>
  <description>arXiv cs.AI - A quintessential feature of human intelligence is the ability to create ad hoc conventions over time to achieve shared goals efficiently. We investigate how communication strategies evolve through repeated collaboration as people coordinate on shared procedural abstractions. To this end, we conducted an online unimodal study (n = 98) using natural language to probe abstraction hierarchies. In a fo</description>
</item>

<item>
  <title>Improving Credit Card Fraud Detection with an Optimized Explainable Boosting Machine</title>
  <link>https://arxiv.org/abs/2602.06955v1</link>
  <guid>https://arxiv.org/abs/2602.06955v1</guid>
  <pubDate>Fri, 06 Feb 2026 18:56:17 +0000</pubDate>
  <description>arXiv cs.LG - Addressing class imbalance is a central challenge in credit card fraud detection, as it directly impacts predictive reliability in real-world financial systems. To overcome this, the study proposes an enhanced workflow based on the Explainable Boosting Machine (EBM)-a transparent, state-of-the-art implementation of the GA2M algorithm-optimized through systematic hyperparameter tuning, feature sele</description>
</item>

<item>
  <title>DreamDojo: A Generalist Robot World Model from Large-Scale Human Videos</title>
  <link>https://arxiv.org/abs/2602.06949v1</link>
  <guid>https://arxiv.org/abs/2602.06949v1</guid>
  <pubDate>Fri, 06 Feb 2026 18:49:43 +0000</pubDate>
  <description>arXiv cs.AI - Being able to simulate the outcomes of actions in varied environments will revolutionize the development of generalist agents at scale. However, modeling these world dynamics, especially for dexterous robotics tasks, poses significant challenges due to limited data coverage and scarce action labels. As an endeavor towards this end, we introduce DreamDojo, a foundation world model that learns diver</description>
</item>

<item>
  <title>DreamDojo: A Generalist Robot World Model from Large-Scale Human Videos</title>
  <link>https://arxiv.org/abs/2602.06949v1</link>
  <guid>https://arxiv.org/abs/2602.06949v1</guid>
  <pubDate>Fri, 06 Feb 2026 18:49:43 +0000</pubDate>
  <description>arXiv cs.LG - Being able to simulate the outcomes of actions in varied environments will revolutionize the development of generalist agents at scale. However, modeling these world dynamics, especially for dexterous robotics tasks, poses significant challenges due to limited data coverage and scarce action labels. As an endeavor towards this end, we introduce DreamDojo, a foundation world model that learns diver</description>
</item>

<item>
  <title>Agentic Uncertainty Reveals Agentic Overconfidence</title>
  <link>https://arxiv.org/abs/2602.06948v1</link>
  <guid>https://arxiv.org/abs/2602.06948v1</guid>
  <pubDate>Fri, 06 Feb 2026 18:49:35 +0000</pubDate>
  <description>arXiv cs.AI - Can AI agents predict whether they will succeed at a task? We study agentic uncertainty by eliciting success probability estimates before, during, and after task execution. All results exhibit agentic overconfidence: some agents that succeed only 22% of the time predict 77% success. Counterintuitively, pre-execution assessment with strictly less information tends to yield better discrimination tha</description>
</item>

<item>
  <title>Agentic Uncertainty Reveals Agentic Overconfidence</title>
  <link>https://arxiv.org/abs/2602.06948v1</link>
  <guid>https://arxiv.org/abs/2602.06948v1</guid>
  <pubDate>Fri, 06 Feb 2026 18:49:35 +0000</pubDate>
  <description>arXiv cs.LG - Can AI agents predict whether they will succeed at a task? We study agentic uncertainty by eliciting success probability estimates before, during, and after task execution. All results exhibit agentic overconfidence: some agents that succeed only 22% of the time predict 77% success. Counterintuitively, pre-execution assessment with strictly less information tends to yield better discrimination tha</description>
</item>

<item>
  <title>Reciprocal Latent Fields for Precomputed Sound Propagation</title>
  <link>https://arxiv.org/abs/2602.06937v1</link>
  <guid>https://arxiv.org/abs/2602.06937v1</guid>
  <pubDate>Fri, 06 Feb 2026 18:31:11 +0000</pubDate>
  <description>arXiv cs.LG - Realistic sound propagation is essential for immersion in a virtual scene, yet physically accurate wave-based simulations remain computationally prohibitive for real-time applications. Wave coding methods address this limitation by precomputing and compressing impulse responses of a given scene into a set of scalar acoustic parameters, which can reach unmanageable sizes in large environments with </description>
</item>

<item>
  <title>Implementing Grassroots Logic Programs with Multiagent Transition Systems and AI</title>
  <link>https://arxiv.org/abs/2602.06934v1</link>
  <guid>https://arxiv.org/abs/2602.06934v1</guid>
  <pubDate>Fri, 06 Feb 2026 18:30:11 +0000</pubDate>
  <description>arXiv cs.AI - Grassroots Logic Programs (GLP) is a concurrent logic programming language with variables partitioned into paired \emph{readers} and \emph{writers}, conjuring both linear logic and futures/promises: an assignment is produced at most once via the sole occurrence of a writer (promise) and consumed at most once via the sole occurrence of its paired reader (future), and may contain additional readers </description>
</item>

<item>
  <title>When RL Meets Adaptive Speculative Training: A Unified Training-Serving System</title>
  <link>https://arxiv.org/abs/2602.06932v1</link>
  <guid>https://arxiv.org/abs/2602.06932v1</guid>
  <pubDate>Fri, 06 Feb 2026 18:28:54 +0000</pubDate>
  <description>arXiv cs.LG - Speculative decoding can significantly accelerate LLM serving, yet most deployments today disentangle speculator training from serving, treating speculator training as a standalone offline modeling problem. We show that this decoupled formulation introduces substantial deployment and adaptation lag: (1) high time-to-serve, since a speculator must be trained offline for a considerable period before</description>
</item>

<item>
  <title>From Kepler to Newton: Inductive Biases Guide Learned World Models in Transformers</title>
  <link>https://arxiv.org/abs/2602.06923v1</link>
  <guid>https://arxiv.org/abs/2602.06923v1</guid>
  <pubDate>Fri, 06 Feb 2026 18:17:37 +0000</pubDate>
  <description>arXiv cs.AI - Can general-purpose AI architectures go beyond prediction to discover the physical laws governing the universe? True intelligence relies on &quot;world models&quot; -- causal abstractions that allow an agent to not only predict future states but understand the underlying governing dynamics. While previous &quot;AI Physicist&quot; approaches have successfully recovered such laws, they typically rely on strong, domain-</description>
</item>

<item>
  <title>From Kepler to Newton: Inductive Biases Guide Learned World Models in Transformers</title>
  <link>https://arxiv.org/abs/2602.06923v1</link>
  <guid>https://arxiv.org/abs/2602.06923v1</guid>
  <pubDate>Fri, 06 Feb 2026 18:17:37 +0000</pubDate>
  <description>arXiv cs.LG - Can general-purpose AI architectures go beyond prediction to discover the physical laws governing the universe? True intelligence relies on &quot;world models&quot; -- causal abstractions that allow an agent to not only predict future states but understand the underlying governing dynamics. While previous &quot;AI Physicist&quot; approaches have successfully recovered such laws, they typically rely on strong, domain-</description>
</item>

<item>
  <title>TraceCoder: A Trace-Driven Multi-Agent Framework for Automated Debugging of LLM-Generated Code</title>
  <link>https://arxiv.org/abs/2602.06875v1</link>
  <guid>https://arxiv.org/abs/2602.06875v1</guid>
  <pubDate>Fri, 06 Feb 2026 16:59:48 +0000</pubDate>
  <description>arXiv cs.AI - Large Language Models (LLMs) often generate code with subtle but critical bugs, especially for complex tasks. Existing automated repair methods typically rely on superficial pass/fail signals, offering limited visibility into program behavior and hindering precise error localization. In addition, without a way to learn from prior failures, repair processes often fall into repetitive and inefficien</description>
</item>

<item>
  <title>AIRS-Bench: a Suite of Tasks for Frontier AI Research Science Agents</title>
  <link>https://arxiv.org/abs/2602.06855v1</link>
  <guid>https://arxiv.org/abs/2602.06855v1</guid>
  <pubDate>Fri, 06 Feb 2026 16:45:02 +0000</pubDate>
  <description>arXiv cs.AI - LLM agents hold significant promise for advancing scientific research. To accelerate this progress, we introduce AIRS-Bench (the AI Research Science Benchmark), a suite of 20 tasks sourced from state-of-the-art machine learning papers. These tasks span diverse domains, including language modeling, mathematics, bioinformatics, and time series forecasting. AIRS-Bench tasks assess agentic capabilitie</description>
</item>

<item>
  <title>From Features to Actions: Explainability in Traditional and Agentic AI Systems</title>
  <link>https://arxiv.org/abs/2602.06841v1</link>
  <guid>https://arxiv.org/abs/2602.06841v1</guid>
  <pubDate>Fri, 06 Feb 2026 16:34:29 +0000</pubDate>
  <description>arXiv cs.AI - Over the last decade, explainable AI has primarily focused on interpreting individual model predictions, producing post-hoc explanations that relate inputs to outputs under a fixed decision structure. Recent advances in large language models (LLMs) have enabled agentic AI systems whose behaviour unfolds over multi-step trajectories. In these settings, success and failure are determined by sequence</description>
</item>

<item>
  <title>LLM Active Alignment: A Nash Equilibrium Perspective</title>
  <link>https://arxiv.org/abs/2602.06836v1</link>
  <guid>https://arxiv.org/abs/2602.06836v1</guid>
  <pubDate>Fri, 06 Feb 2026 16:26:03 +0000</pubDate>
  <description>arXiv cs.AI - We develop a game-theoretic framework for predicting and steering the behavior of populations of large language models (LLMs) through Nash equilibrium (NE) analysis. To avoid the intractability of equilibrium computation in open-ended text spaces, we model each agent&apos;s action as a mixture over human subpopulations. Agents choose actively and strategically which groups to align with, yielding an in</description>
</item>

<item>
  <title>DyTopo: Dynamic Topology Routing for Multi-Agent Reasoning via Semantic Matching</title>
  <link>https://arxiv.org/abs/2602.06039v1</link>
  <guid>https://arxiv.org/abs/2602.06039v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:59:51 +0000</pubDate>
  <description>arXiv cs.AI - Multi-agent systems built from prompted large language models can improve multi-round reasoning, yet most existing pipelines rely on fixed, trajectory-wide communication patterns that are poorly matched to the stage-dependent needs of iterative problem solving. We introduce DyTopo, a manager-guided multi-agent framework that reconstructs a sparse directed communication graph at each round. Conditi</description>
</item>

<item>
  <title>CommCP: Efficient Multi-Agent Coordination via LLM-Based Communication with Conformal Prediction</title>
  <link>https://arxiv.org/abs/2602.06038v1</link>
  <guid>https://arxiv.org/abs/2602.06038v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:59:45 +0000</pubDate>
  <description>arXiv cs.AI - To complete assignments provided by humans in natural language, robots must interpret commands, generate and answer relevant questions for scene understanding, and manipulate target objects. Real-world deployments often require multiple heterogeneous robots with different manipulation capabilities to handle different assignments cooperatively. Beyond the need for specialized manipulation skills, e</description>
</item>

<item>
  <title>CommCP: Efficient Multi-Agent Coordination via LLM-Based Communication with Conformal Prediction</title>
  <link>https://arxiv.org/abs/2602.06038v1</link>
  <guid>https://arxiv.org/abs/2602.06038v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:59:45 +0000</pubDate>
  <description>arXiv cs.LG - To complete assignments provided by humans in natural language, robots must interpret commands, generate and answer relevant questions for scene understanding, and manipulate target objects. Real-world deployments often require multiple heterogeneous robots with different manipulation capabilities to handle different assignments cooperatively. Beyond the need for specialized manipulation skills, e</description>
</item>

<item>
  <title>PhysicsAgentABM: Physics-Guided Generative Agent-Based Modeling</title>
  <link>https://arxiv.org/abs/2602.06030v1</link>
  <guid>https://arxiv.org/abs/2602.06030v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:59:01 +0000</pubDate>
  <description>arXiv cs.LG - Large language model (LLM)-based multi-agent systems enable expressive agent reasoning but are expensive to scale and poorly calibrated for timestep-aligned state-transition simulation, while classical agent-based models (ABMs) offer interpretability but struggle to integrate rich individual-level signals and non-stationary behaviors. We propose PhysicsAgentABM, which shifts inference to behaviora</description>
</item>

<item>
  <title>Curiosity is Knowledge: Self-Consistent Learning and No-Regret Optimization with Active Inference</title>
  <link>https://arxiv.org/abs/2602.06029v1</link>
  <guid>https://arxiv.org/abs/2602.06029v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:58:32 +0000</pubDate>
  <description>arXiv cs.LG - Active inference (AIF) unifies exploration and exploitation by minimizing the Expected Free Energy (EFE), balancing epistemic value (information gain) and pragmatic value (task performance) through a curiosity coefficient. Yet it has been unclear when this balance yields both coherent learning and efficient decision-making: insufficient curiosity can drive myopic exploitation and prevent uncertain</description>
</item>

<item>
  <title>Learning Query-Aware Budget-Tier Routing for Runtime Agent Memory</title>
  <link>https://arxiv.org/abs/2602.06025v1</link>
  <guid>https://arxiv.org/abs/2602.06025v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:57:09 +0000</pubDate>
  <description>arXiv cs.AI - Memory is increasingly central to Large Language Model (LLM) agents operating beyond a single context window, yet most existing systems rely on offline, query-agnostic memory construction that can be inefficient and may discard query-critical information. Although runtime memory utilization is a natural alternative, prior work often incurs substantial overhead and offers limited explicit control o</description>
</item>

<item>
  <title>Learning Query-Aware Budget-Tier Routing for Runtime Agent Memory</title>
  <link>https://arxiv.org/abs/2602.06025v1</link>
  <guid>https://arxiv.org/abs/2602.06025v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:57:09 +0000</pubDate>
  <description>arXiv cs.LG - Memory is increasingly central to Large Language Model (LLM) agents operating beyond a single context window, yet most existing systems rely on offline, query-agnostic memory construction that can be inefficient and may discard query-critical information. Although runtime memory utilization is a natural alternative, prior work often incurs substantial overhead and offers limited explicit control o</description>
</item>

<item>
  <title>Learning Event-Based Shooter Models from Virtual Reality Experiments</title>
  <link>https://arxiv.org/abs/2602.06023v1</link>
  <guid>https://arxiv.org/abs/2602.06023v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:56:49 +0000</pubDate>
  <description>arXiv cs.AI - Virtual reality (VR) has emerged as a powerful tool for evaluating school security measures in high-risk scenarios such as school shootings, offering experimental control and high behavioral fidelity. However, assessing new interventions in VR requires recruiting new participant cohorts for each condition, making large-scale or iterative evaluation difficult. These limitations are especially restr</description>
</item>

<item>
  <title>Multi-Token Prediction via Self-Distillation</title>
  <link>https://arxiv.org/abs/2602.06019v1</link>
  <guid>https://arxiv.org/abs/2602.06019v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:54:48 +0000</pubDate>
  <description>arXiv cs.LG - Existing techniques for accelerating language model inference, such as speculative decoding, require training auxiliary speculator models and building and deploying complex inference pipelines. We consider a new approach for converting a pretrained autoregressive language model from a slow single next token prediction model into a fast standalone multi-token prediction model using a simple online </description>
</item>

<item>
  <title>AgenticPay: A Multi-Agent LLM Negotiation System for Buyer-Seller Transactions</title>
  <link>https://arxiv.org/abs/2602.06008v1</link>
  <guid>https://arxiv.org/abs/2602.06008v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:50:36 +0000</pubDate>
  <description>arXiv cs.AI - Large language model (LLM)-based agents are increasingly expected to negotiate, coordinate, and transact autonomously, yet existing benchmarks lack principled settings for evaluating language-mediated economic interaction among multiple agents. We introduce AgenticPay, a benchmark and simulation framework for multi-agent buyer-seller negotiation driven by natural language. AgenticPay models market</description>
</item>

<item>
  <title>AgenticPay: A Multi-Agent LLM Negotiation System for Buyer-Seller Transactions</title>
  <link>https://arxiv.org/abs/2602.06008v1</link>
  <guid>https://arxiv.org/abs/2602.06008v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:50:36 +0000</pubDate>
  <description>arXiv cs.LG - Large language model (LLM)-based agents are increasingly expected to negotiate, coordinate, and transact autonomously, yet existing benchmarks lack principled settings for evaluating language-mediated economic interaction among multiple agents. We introduce AgenticPay, a benchmark and simulation framework for multi-agent buyer-seller negotiation driven by natural language. AgenticPay models market</description>
</item>

<item>
  <title>Layer-wise LoRA fine-tuning: a similarity metric approach</title>
  <link>https://arxiv.org/abs/2602.05988v1</link>
  <guid>https://arxiv.org/abs/2602.05988v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:38:53 +0000</pubDate>
  <description>arXiv cs.LG - Pre-training Large Language Models (LLMs) on web-scale datasets becomes fundamental for advancing general-purpose AI. In contrast, enhancing their predictive performance on downstream tasks typically involves adapting their knowledge through fine-tuning. Parameter-efficient fine-tuning techniques, such as Low-Rank Adaptation (LoRA), aim to reduce the computational cost of this process by freezing </description>
</item>

<item>
  <title>Learning to Share: Selective Memory for Efficient Parallel Agentic Systems</title>
  <link>https://arxiv.org/abs/2602.05965v1</link>
  <guid>https://arxiv.org/abs/2602.05965v1</guid>
  <pubDate>Thu, 05 Feb 2026 18:20:21 +0000</pubDate>
  <description>arXiv cs.AI - Agentic systems solve complex tasks by coordinating multiple agents that iteratively reason, invoke tools, and exchange intermediate results. To improve robustness and solution quality, recent approaches deploy multiple agent teams running in parallel to explore diverse reasoning trajectories. However, parallel execution comes at a significant computational cost: when different teams independently</description>
</item>

<item>
  <title>Compound Deception in Elite Peer Review: A Failure Mode Taxonomy of 100 Fabricated Citations at NeurIPS 2025</title>
  <link>https://arxiv.org/abs/2602.05930v1</link>
  <guid>https://arxiv.org/abs/2602.05930v1</guid>
  <pubDate>Thu, 05 Feb 2026 17:43:35 +0000</pubDate>
  <description>arXiv cs.AI - Large language models (LLMs) are increasingly used in academic writing workflows, yet they frequently hallucinate by generating citations to sources that do not exist. This study analyzes 100 AI-generated hallucinated citations that appeared in papers accepted by the 2025 Conference on Neural Information Processing Systems (NeurIPS), one of the world&apos;s most prestigious AI conferences. Despite revi</description>
</item>

<item>
  <title>Quantum Reinforcement Learning with Transformers for the Capacitated Vehicle Routing Problem</title>
  <link>https://arxiv.org/abs/2602.05920v1</link>
  <guid>https://arxiv.org/abs/2602.05920v1</guid>
  <pubDate>Thu, 05 Feb 2026 17:32:14 +0000</pubDate>
  <description>arXiv cs.AI - This paper addresses the Capacitated Vehicle Routing Problem (CVRP) by comparing classical and quantum Reinforcement Learning (RL) approaches. An Advantage Actor-Critic (A2C) agent is implemented in classical, full quantum, and hybrid variants, integrating transformer architectures to capture the relationships between vehicles, clients, and the depot through self- and cross-attention mechanisms. T</description>
</item>

<item>
  <title>Parity, Sensitivity, and Transformers</title>
  <link>https://arxiv.org/abs/2602.05896v1</link>
  <guid>https://arxiv.org/abs/2602.05896v1</guid>
  <pubDate>Thu, 05 Feb 2026 17:14:33 +0000</pubDate>
  <description>arXiv cs.AI - The transformer architecture is almost a decade old. Despite that, we still have a limited understanding of what this architecture can or cannot compute. For instance, can a 1-layer transformer solve PARITY -- or more generally -- which kinds of transformers can do it? Known constructions for PARITY have at least 2 layers and employ impractical features: either a length-dependent positional encodi</description>
</item>

<item>
  <title>Metric Hedonic Games on the Line</title>
  <link>https://arxiv.org/abs/2602.05888v1</link>
  <guid>https://arxiv.org/abs/2602.05888v1</guid>
  <pubDate>Thu, 05 Feb 2026 17:05:08 +0000</pubDate>
  <description>arXiv cs.AI - Hedonic games are fundamental models for investigating the formation of coalitions among a set of strategic agents, where every agent has a certain utility for every possible coalition of agents it can be part of. To avoid the intractability of defining exponentially many utilities for all possible coalitions, many variants with succinct representations of the agents&apos; utility functions have been d</description>
</item>

<item>
  <title>CRoSS: A Continual Robotic Simulation Suite for Scalable Reinforcement Learning with High Task Diversity and Realistic Physics Simulation</title>
  <link>https://arxiv.org/abs/2602.04868v1</link>
  <guid>https://arxiv.org/abs/2602.04868v1</guid>
  <pubDate>Wed, 04 Feb 2026 18:54:26 +0000</pubDate>
  <description>arXiv cs.AI - Continual reinforcement learning (CRL) requires agents to learn from a sequence of tasks without forgetting previously acquired policies. In this work, we introduce a novel benchmark suite for CRL based on realistically simulated robots in the Gazebo simulator. Our Continual Robotic Simulation Suite (CRoSS) benchmarks rely on two robotic platforms: a two-wheeled differential-drive robot with lidar</description>
</item>

<item>
  <title>CRoSS: A Continual Robotic Simulation Suite for Scalable Reinforcement Learning with High Task Diversity and Realistic Physics Simulation</title>
  <link>https://arxiv.org/abs/2602.04868v1</link>
  <guid>https://arxiv.org/abs/2602.04868v1</guid>
  <pubDate>Wed, 04 Feb 2026 18:54:26 +0000</pubDate>
  <description>arXiv cs.LG - Continual reinforcement learning (CRL) requires agents to learn from a sequence of tasks without forgetting previously acquired policies. In this work, we introduce a novel benchmark suite for CRL based on realistically simulated robots in the Gazebo simulator. Our Continual Robotic Simulation Suite (CRoSS) benchmarks rely on two robotic platforms: a two-wheeled differential-drive robot with lidar</description>
</item>

</channel>
</rss>
